

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Random Sample Images of Dataset &#8212; Deep Truth</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'Code_Implementation/5.2DL-FINAL-PROJECT';</script>
    <link rel="canonical" href="/Deep-Truth/Code_Implementation/5.2DL-FINAL-PROJECT.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="prev" title="Automated ASL Fingerspelling Recognition for Educational Platforms Using YOLOv8 Frame Classification and Letter Sequence Reconstruction" href="../Week_5/final_report.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="Deep Truth - Home"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="Deep Truth - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Deep Truth Portfolio
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Week 1 Project Proposal</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../Week_1/project_proposal.html">Automated ASL Fingerspelling Recognition for Educational Platforms Using CNN Frame Classification and Letter Sequence Reconstruction</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Week 2 Data Collection</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../Week_2/data_collection.html">Data Collection and Preprocessing</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Week 3 Model Design and Initial Experiments</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../Week_3/model_design.html">Model Design and Initial Experiments</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Week 4 Results and Discussion</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../Week_4/results_discussions.html">Results and Discussion</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Week 5 Final Report</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../Week_5/final_report.html">Automated ASL Fingerspelling Recognition for Educational Platforms Using YOLOv8 Frame Classification and Letter Sequence Reconstruction</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Code Implementation</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Random Sample Images of Dataset</a></li>



</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/Danecash/Deep-Truth" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/Danecash/Deep-Truth/issues/new?title=Issue%20on%20page%20%2FCode_Implementation/5.2DL-FINAL-PROJECT.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/Code_Implementation/5.2DL-FINAL-PROJECT.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Random Sample Images of Dataset</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Random Sample Images of Dataset</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#modeling">Modeling</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#yolov8">YOLOv8</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#yolov8-n-nano">YOLOv8-n (Nano)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#yolov8-s-small">YOLOv8-s (Small)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#results">Results</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">YOLOv8-n (Nano)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">YOLOv8-s (Small)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#yolov8-model-performance-comparison">YOLOv8 Model Performance Comparison</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#video-testing">Video Testing</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#functions">Functions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#testing">Testing</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dog">Dog</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#hello">Hello</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camera">Camera</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#travel">Travel</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#forest">Forest</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="n">ultralytics</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>^C
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Note: you may need to restart the kernel to use updated packages.
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Collecting ultralytics
  Downloading ultralytics-8.3.237-py3-none-any.whl.metadata (37 kB)
Collecting numpy&gt;=1.23.0 (from ultralytics)
  Using cached numpy-2.3.5-cp312-cp312-win_amd64.whl.metadata (60 kB)
Collecting matplotlib&gt;=3.3.0 (from ultralytics)
  Downloading matplotlib-3.10.8-cp312-cp312-win_amd64.whl.metadata (52 kB)
     ---------------------------------------- 0.0/52.8 kB ? eta -:--:--
     ---------------------------------------- 52.8/52.8 kB 2.8 MB/s eta 0:00:00
Collecting opencv-python&gt;=4.6.0 (from ultralytics)
  Using cached opencv_python-4.12.0.88-cp37-abi3-win_amd64.whl.metadata (19 kB)
Collecting pillow&gt;=7.1.2 (from ultralytics)
  Using cached pillow-12.0.0-cp312-cp312-win_amd64.whl.metadata (9.0 kB)
Requirement already satisfied: pyyaml&gt;=5.3.1 in c:\users\ccdan\onedrive\documents\deep truth\my-jupyter-book\venv\lib\site-packages (from ultralytics) (6.0.3)
Requirement already satisfied: requests&gt;=2.23.0 in c:\users\ccdan\onedrive\documents\deep truth\my-jupyter-book\venv\lib\site-packages (from ultralytics) (2.32.5)
Collecting scipy&gt;=1.4.1 (from ultralytics)
  Using cached scipy-1.16.3-cp312-cp312-win_amd64.whl.metadata (60 kB)
Collecting torch&gt;=1.8.0 (from ultralytics)
  Using cached torch-2.9.1-cp312-cp312-win_amd64.whl.metadata (30 kB)
Collecting torchvision&gt;=0.9.0 (from ultralytics)
  Downloading torchvision-0.24.1-cp312-cp312-win_amd64.whl.metadata (5.9 kB)
Requirement already satisfied: psutil&gt;=5.8.0 in c:\users\ccdan\onedrive\documents\deep truth\my-jupyter-book\venv\lib\site-packages (from ultralytics) (7.1.3)
Collecting polars&gt;=0.20.0 (from ultralytics)
  Downloading polars-1.36.1-py3-none-any.whl.metadata (10 kB)
Collecting ultralytics-thop&gt;=2.0.18 (from ultralytics)
  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)
Collecting contourpy&gt;=1.0.1 (from matplotlib&gt;=3.3.0-&gt;ultralytics)
  Using cached contourpy-1.3.3-cp312-cp312-win_amd64.whl.metadata (5.5 kB)
Collecting cycler&gt;=0.10 (from matplotlib&gt;=3.3.0-&gt;ultralytics)
  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)
Collecting fonttools&gt;=4.22.0 (from matplotlib&gt;=3.3.0-&gt;ultralytics)
  Downloading fonttools-4.61.1-cp312-cp312-win_amd64.whl.metadata (116 kB)
     ---------------------------------------- 0.0/116.4 kB ? eta -:--:--
     ---------------------------------------- 0.0/116.4 kB ? eta -:--:--
     ---------------------------------------- 0.0/116.4 kB ? eta -:--:--
     ---------------------------------------- 0.0/116.4 kB ? eta -:--:--
     ---------------------------------------- 0.0/116.4 kB ? eta -:--:--
     --- ------------------------------------ 10.2/116.4 kB ? eta -:--:--
     --- ------------------------------------ 10.2/116.4 kB ? eta -:--:--
     --- ------------------------------------ 10.2/116.4 kB ? eta -:--:--
     --- ------------------------------------ 10.2/116.4 kB ? eta -:--:--
     --- ------------------------------------ 10.2/116.4 kB ? eta -:--:--
     --- ------------------------------------ 10.2/116.4 kB ? eta -:--:--
     --- ------------------------------------ 10.2/116.4 kB ? eta -:--:--
     --- ------------------------------------ 10.2/116.4 kB ? eta -:--:--
     --- ------------------------------------ 10.2/116.4 kB ? eta -:--:--
     ---------- --------------------------- 30.7/116.4 kB 50.4 kB/s eta 0:00:02
     ---------- --------------------------- 30.7/116.4 kB 50.4 kB/s eta 0:00:02
     ---------- --------------------------- 30.7/116.4 kB 50.4 kB/s eta 0:00:02
     ---------- --------------------------- 30.7/116.4 kB 50.4 kB/s eta 0:00:02
     ---------- --------------------------- 30.7/116.4 kB 50.4 kB/s eta 0:00:02
     ---------- --------------------------- 30.7/116.4 kB 50.4 kB/s eta 0:00:02
     ---------- --------------------------- 30.7/116.4 kB 50.4 kB/s eta 0:00:02
     ---------- --------------------------- 30.7/116.4 kB 50.4 kB/s eta 0:00:02
     ---------- --------------------------- 30.7/116.4 kB 50.4 kB/s eta 0:00:02
     ---------- --------------------------- 30.7/116.4 kB 50.4 kB/s eta 0:00:02
     ---------- --------------------------- 30.7/116.4 kB 50.4 kB/s eta 0:00:02
     ---------- --------------------------- 30.7/116.4 kB 50.4 kB/s eta 0:00:02
     ---------- --------------------------- 30.7/116.4 kB 50.4 kB/s eta 0:00:02
     ------------- ------------------------ 41.0/116.4 kB 30.2 kB/s eta 0:00:03
     ------------- ------------------------ 41.0/116.4 kB 30.2 kB/s eta 0:00:03
     ------------- ------------------------ 41.0/116.4 kB 30.2 kB/s eta 0:00:03
     ------------- ------------------------ 41.0/116.4 kB 30.2 kB/s eta 0:00:03
     ------------- ------------------------ 41.0/116.4 kB 30.2 kB/s eta 0:00:03
     ------------- ------------------------ 41.0/116.4 kB 30.2 kB/s eta 0:00:03
     ------------- ------------------------ 41.0/116.4 kB 30.2 kB/s eta 0:00:03
     ------------- ------------------------ 41.0/116.4 kB 30.2 kB/s eta 0:00:03
     ------------- ------------------------ 41.0/116.4 kB 30.2 kB/s eta 0:00:03
     ------------- ------------------------ 41.0/116.4 kB 30.2 kB/s eta 0:00:03
     ------------- ------------------------ 41.0/116.4 kB 30.2 kB/s eta 0:00:03
     ------------- ------------------------ 41.0/116.4 kB 30.2 kB/s eta 0:00:03
     ------------- ------------------------ 41.0/116.4 kB 30.2 kB/s eta 0:00:03
     ------------- ------------------------ 41.0/116.4 kB 30.2 kB/s eta 0:00:03
     ------------- ------------------------ 41.0/116.4 kB 30.2 kB/s eta 0:00:03
     ------------- ------------------------ 41.0/116.4 kB 30.2 kB/s eta 0:00:03
     ------------- ------------------------ 41.0/116.4 kB 30.2 kB/s eta 0:00:03
     -------------------- ----------------- 61.4/116.4 kB 27.8 kB/s eta 0:00:02
     -------------------- ----------------- 61.4/116.4 kB 27.8 kB/s eta 0:00:02
     -------------------- ----------------- 61.4/116.4 kB 27.8 kB/s eta 0:00:02
     -------------------- ----------------- 61.4/116.4 kB 27.8 kB/s eta 0:00:02
     -------------------- ----------------- 61.4/116.4 kB 27.8 kB/s eta 0:00:02
     -------------------- ----------------- 61.4/116.4 kB 27.8 kB/s eta 0:00:02
     -------------------- ----------------- 61.4/116.4 kB 27.8 kB/s eta 0:00:02
     -------------------- ----------------- 61.4/116.4 kB 27.8 kB/s eta 0:00:02
     -------------------- ----------------- 61.4/116.4 kB 27.8 kB/s eta 0:00:02
     -------------------- ----------------- 61.4/116.4 kB 27.8 kB/s eta 0:00:02
     -------------------- ----------------- 61.4/116.4 kB 27.8 kB/s eta 0:00:02
     -------------------- ----------------- 61.4/116.4 kB 27.8 kB/s eta 0:00:02
     -------------------- ----------------- 61.4/116.4 kB 27.8 kB/s eta 0:00:02
     -------------------- ----------------- 61.4/116.4 kB 27.8 kB/s eta 0:00:02
     -------------------- ----------------- 61.4/116.4 kB 27.8 kB/s eta 0:00:02
     -------------------- ----------------- 61.4/116.4 kB 27.8 kB/s eta 0:00:02
     -------------------- ----------------- 61.4/116.4 kB 27.8 kB/s eta 0:00:02
     -------------------- ----------------- 61.4/116.4 kB 27.8 kB/s eta 0:00:02
     ----------------------- -------------- 71.7/116.4 kB 23.1 kB/s eta 0:00:02
     ----------------------- -------------- 71.7/116.4 kB 23.1 kB/s eta 0:00:02
     ----------------------- -------------- 71.7/116.4 kB 23.1 kB/s eta 0:00:02
     ----------------------- -------------- 71.7/116.4 kB 23.1 kB/s eta 0:00:02
     ----------------------- -------------- 71.7/116.4 kB 23.1 kB/s eta 0:00:02
     ----------------------- -------------- 71.7/116.4 kB 23.1 kB/s eta 0:00:02
     ----------------------- -------------- 71.7/116.4 kB 23.1 kB/s eta 0:00:02
     ----------------------- -------------- 71.7/116.4 kB 23.1 kB/s eta 0:00:02
     ----------------------- -------------- 71.7/116.4 kB 23.1 kB/s eta 0:00:02
     ----------------------- -------------- 71.7/116.4 kB 23.1 kB/s eta 0:00:02
     ----------------------- -------------- 71.7/116.4 kB 23.1 kB/s eta 0:00:02
     ----------------------- -------------- 71.7/116.4 kB 23.1 kB/s eta 0:00:02
     ----------------------- -------------- 71.7/116.4 kB 23.1 kB/s eta 0:00:02
     ------------------------------ ------- 92.2/116.4 kB 25.0 kB/s eta 0:00:01
     ------------------------------ ------- 92.2/116.4 kB 25.0 kB/s eta 0:00:01
     ------------------------------ ------- 92.2/116.4 kB 25.0 kB/s eta 0:00:01
     ------------------------------ ------- 92.2/116.4 kB 25.0 kB/s eta 0:00:01
     ------------------------------ ------- 92.2/116.4 kB 25.0 kB/s eta 0:00:01
     ------------------------------ ------- 92.2/116.4 kB 25.0 kB/s eta 0:00:01
     ------------------------------ ------- 92.2/116.4 kB 25.0 kB/s eta 0:00:01
     ------------------------------ ------- 92.2/116.4 kB 25.0 kB/s eta 0:00:01
     -------------------------------- ---- 102.4/116.4 kB 25.3 kB/s eta 0:00:01
     -------------------------------- ---- 102.4/116.4 kB 25.3 kB/s eta 0:00:01
     -------------------------------- ---- 102.4/116.4 kB 25.3 kB/s eta 0:00:01
     -------------------------------- ---- 102.4/116.4 kB 25.3 kB/s eta 0:00:01
     -------------------------------- ---- 102.4/116.4 kB 25.3 kB/s eta 0:00:01
     -------------------------------- ---- 102.4/116.4 kB 25.3 kB/s eta 0:00:01
     -------------------------------- ---- 102.4/116.4 kB 25.3 kB/s eta 0:00:01
     -------------------------------- ---- 102.4/116.4 kB 25.3 kB/s eta 0:00:01
     -------------------------------- ---- 102.4/116.4 kB 25.3 kB/s eta 0:00:01
     -------------------------------- ---- 102.4/116.4 kB 25.3 kB/s eta 0:00:01
     ------------------------------------- 116.4/116.4 kB 25.6 kB/s eta 0:00:00
Collecting kiwisolver&gt;=1.3.1 (from matplotlib&gt;=3.3.0-&gt;ultralytics)
  Using cached kiwisolver-1.4.9-cp312-cp312-win_amd64.whl.metadata (6.4 kB)
Requirement already satisfied: packaging&gt;=20.0 in c:\users\ccdan\onedrive\documents\deep truth\my-jupyter-book\venv\lib\site-packages (from matplotlib&gt;=3.3.0-&gt;ultralytics) (25.0)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">uninstall</span> <span class="n">numpy</span> <span class="o">-</span><span class="n">y</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pip</span> <span class="n">install</span> <span class="s2">&quot;numpy&lt;2&quot;</span>
</pre></div>
</div>
</div>
</div>
<section class="tex2jax_ignore mathjax_ignore" id="random-sample-images-of-dataset">
<h1>Random Sample Images of Dataset<a class="headerlink" href="#random-sample-images-of-dataset" title="Permalink to this heading">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">random</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">yaml</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.patches</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">patches</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">PIL</span><span class="w"> </span><span class="kn">import</span> <span class="n">Image</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">IPython.display</span><span class="w"> </span><span class="kn">import</span> <span class="n">display</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">show_yolo_images</span><span class="p">(</span><span class="n">train_path</span><span class="p">,</span> <span class="n">yaml_path</span><span class="p">,</span> <span class="n">num_images</span><span class="o">=</span><span class="mi">4</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Display random images from YOLOv8 dataset with their bounding boxes and class names</span>
<span class="sd">    </span>
<span class="sd">    Args:</span>
<span class="sd">        train_path: Path to your train folder (contains &#39;images&#39; and &#39;labels&#39; subfolders)</span>
<span class="sd">        yaml_path: Path to your data.yaml file</span>
<span class="sd">        num_images: Number of random images to display</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Paths to images and labels</span>
    <span class="n">images_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">train_path</span><span class="p">,</span> <span class="s1">&#39;images&#39;</span><span class="p">)</span>
    <span class="n">labels_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">train_path</span><span class="p">,</span> <span class="s1">&#39;labels&#39;</span><span class="p">)</span>
    
    <span class="c1"># Load class names from yaml</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">yaml_path</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">yaml</span><span class="o">.</span><span class="n">safe_load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
        <span class="n">class_names</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;names&#39;</span><span class="p">]</span>
        
        <span class="c1"># Handle both list and dict formats</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">class_names</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="n">class_names</span> <span class="o">=</span> <span class="n">class_names</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">class_names</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span> <span class="n">name</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">name</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">class_names</span><span class="p">)}</span>
    
    <span class="c1"># Get all image files</span>
    <span class="n">image_files</span> <span class="o">=</span> <span class="p">[</span><span class="n">f</span> <span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">images_path</span><span class="p">)</span> <span class="k">if</span> <span class="n">f</span><span class="o">.</span><span class="n">endswith</span><span class="p">((</span><span class="s1">&#39;.jpg&#39;</span><span class="p">,</span> <span class="s1">&#39;.jpeg&#39;</span><span class="p">,</span> <span class="s1">&#39;.png&#39;</span><span class="p">))]</span>
    
    <span class="c1"># Select random images</span>
    <span class="n">selected_images</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">image_files</span><span class="p">,</span> <span class="nb">min</span><span class="p">(</span><span class="n">num_images</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">image_files</span><span class="p">)))</span>
    
    <span class="c1"># Create subplots</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">15</span><span class="p">))</span>
    <span class="n">axes</span> <span class="o">=</span> <span class="n">axes</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    
    <span class="c1"># Colors for different classes</span>
    <span class="n">colors</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">tab20</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">20</span><span class="p">))</span>
    
    <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">img_file</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">selected_images</span><span class="p">):</span>
        <span class="c1"># Load image</span>
        <span class="n">img_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">images_path</span><span class="p">,</span> <span class="n">img_file</span><span class="p">)</span>
        <span class="n">img</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">img_path</span><span class="p">)</span>
        <span class="n">width</span><span class="p">,</span> <span class="n">height</span> <span class="o">=</span> <span class="n">img</span><span class="o">.</span><span class="n">size</span>
        
        <span class="c1"># Load corresponding label</span>
        <span class="n">label_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">splitext</span><span class="p">(</span><span class="n">img_file</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="s1">&#39;.txt&#39;</span>
        <span class="n">label_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">labels_path</span><span class="p">,</span> <span class="n">label_file</span><span class="p">)</span>
        
        <span class="c1"># Display image</span>
        <span class="n">axes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
        <span class="n">axes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
        <span class="n">axes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">img_file</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
        
        <span class="c1"># Read and draw bounding boxes</span>
        <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">label_path</span><span class="p">):</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">label_path</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">f</span><span class="p">:</span>
                    <span class="c1"># YOLO format: class_id center_x center_y width height (normalized)</span>
                    <span class="n">parts</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
                    <span class="n">class_id</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">parts</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
                    <span class="n">x_center</span><span class="p">,</span> <span class="n">y_center</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">h</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="n">parts</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">5</span><span class="p">])</span>
                    
                    <span class="c1"># Convert from normalized to pixel coordinates</span>
                    <span class="n">x_center</span> <span class="o">*=</span> <span class="n">width</span>
                    <span class="n">y_center</span> <span class="o">*=</span> <span class="n">height</span>
                    <span class="n">w</span> <span class="o">*=</span> <span class="n">width</span>
                    <span class="n">h</span> <span class="o">*=</span> <span class="n">height</span>
                    
                    <span class="c1"># Convert center format to corner format</span>
                    <span class="n">x1</span> <span class="o">=</span> <span class="n">x_center</span> <span class="o">-</span> <span class="n">w</span><span class="o">/</span><span class="mi">2</span>
                    <span class="n">y1</span> <span class="o">=</span> <span class="n">y_center</span> <span class="o">-</span> <span class="n">h</span><span class="o">/</span><span class="mi">2</span>
                    
                    <span class="c1"># Draw rectangle</span>
                    <span class="n">rect</span> <span class="o">=</span> <span class="n">patches</span><span class="o">.</span><span class="n">Rectangle</span><span class="p">(</span>
                        <span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">y1</span><span class="p">),</span> <span class="n">w</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span>
                        <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                        <span class="n">edgecolor</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">class_id</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="n">colors</span><span class="p">)],</span>
                        <span class="n">facecolor</span><span class="o">=</span><span class="s1">&#39;none&#39;</span>
                    <span class="p">)</span>
                    <span class="n">axes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">add_patch</span><span class="p">(</span><span class="n">rect</span><span class="p">)</span>
                    
                    <span class="c1"># Add class label with name</span>
                    <span class="n">class_name</span> <span class="o">=</span> <span class="n">class_names</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">class_id</span><span class="p">,</span> <span class="sa">f</span><span class="s1">&#39;Class </span><span class="si">{</span><span class="n">class_id</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
                    <span class="n">axes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">text</span><span class="p">(</span>
                        <span class="n">x1</span><span class="p">,</span> <span class="n">y1</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span>
                        <span class="n">class_name</span><span class="p">,</span>
                        <span class="n">color</span><span class="o">=</span><span class="s1">&#39;white&#39;</span><span class="p">,</span>
                        <span class="n">fontsize</span><span class="o">=</span><span class="mi">9</span><span class="p">,</span>
                        <span class="n">weight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">,</span>
                        <span class="n">bbox</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">facecolor</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">class_id</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="n">colors</span><span class="p">)],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
                    <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">axes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">text</span><span class="p">(</span>
                <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="s1">&#39;No labels found&#39;</span><span class="p">,</span>
                <span class="n">transform</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">transAxes</span><span class="p">,</span>
                <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">va</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span>
                <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span>
            <span class="p">)</span>
    
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>  
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_path</span> <span class="o">=</span> <span class="s1">&#39;data/train&#39;</span>
<span class="n">yaml_path</span> <span class="o">=</span> <span class="s1">&#39;data/data.yaml&#39;</span>  

<span class="n">show_yolo_images</span><span class="p">(</span><span class="n">train_path</span><span class="p">,</span> <span class="n">yaml_path</span><span class="p">,</span> <span class="n">num_images</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/f1b6a33dcd22505210a21403d0c8c11be4b4cf5bdbfc6a94827940ff7f2474e7.png" src="../_images/f1b6a33dcd22505210a21403d0c8c11be4b4cf5bdbfc6a94827940ff7f2474e7.png" />
</div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="modeling">
<h1>Modeling<a class="headerlink" href="#modeling" title="Permalink to this heading">#</a></h1>
<section id="yolov8">
<h2>YOLOv8<a class="headerlink" href="#yolov8" title="Permalink to this heading">#</a></h2>
<section id="yolov8-n-nano">
<h3>YOLOv8-n (Nano)<a class="headerlink" href="#yolov8-n-nano" title="Permalink to this heading">#</a></h3>
<p>YOLOv8-n is an ultra-lightweight version of YOLOv8, designed for speed and efficiency. It has very few parameters, allowing for fast training and inference. As a baseline model, it provides a reference point for evaluating the performance gains of larger YOLOv8 variants on the same dataset. While fast, its accuracy is lower than larger models.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ultralytics</span><span class="w"> </span><span class="kn">import</span> <span class="n">YOLO</span>

<span class="c1"># Load the smallest YOLOv8 model (baseline)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">YOLO</span><span class="p">(</span><span class="s2">&quot;yolov8n.pt&quot;</span><span class="p">)</span>

<span class="c1"># Train</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span>
    <span class="n">data</span><span class="o">=</span><span class="s2">&quot;data/data.yaml&quot;</span><span class="p">,</span>  
    <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">imgsz</span><span class="o">=</span><span class="mi">640</span><span class="p">,</span>
    <span class="n">batch</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;yolo8n_baseline&quot;</span>  
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to &#39;yolov8n.pt&#39;: 100% ━━━━━━━━━━━━ 6.2MB 3.1MB/s 2.0s.0s&lt;0.1s3.1ss
New https://pypi.org/project/ultralytics/8.3.233 available  Update with &#39;pip install -U ultralytics&#39;
Ultralytics 8.3.232  Python-3.12.4 torch-2.2.2+cpu CPU (AMD Ryzen 5 PRO 4650G with Radeon Graphics)
<span class=" -Color -Color-Bold -Color-Bold-Blue">engine\trainer: </span>agnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=data/data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=10, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolo8n_baseline, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\Users\Usher\Desktop\DL FINAL PROJECT\yolo\runs\detect\yolo8n_baseline, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None
Downloading https://ultralytics.com/assets/Arial.ttf to &#39;C:\Users\Usher\AppData\Roaming\Ultralytics\Arial.ttf&#39;: 100% ━━━━━━━━━━━━ 755.1KB 1.2MB/s 0.6s/s 0.6s&lt;0.3s
Overriding model.yaml nc=80 with nc=26

                   from  n    params  module                                       arguments                     
  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 
  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                
  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             
  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                
  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             
  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               
  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           
  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              
  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           
  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 
 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, &#39;nearest&#39;]          
 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           
 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 
 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, &#39;nearest&#39;]          
 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           
 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  
 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                
 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           
 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 
 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              
 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           
 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 
 22        [15, 18, 21]  1    756382  ultralytics.nn.modules.head.Detect           [26, [64, 128, 256]]          
Model summary: 129 layers, 3,015,918 parameters, 3,015,902 gradients, 8.2 GFLOPs

Transferred 319/355 items from pretrained weights
Freezing layer &#39;model.22.dfl.conv.weight&#39;
<span class=" -Color -Color-Bold -Color-Bold-Blue">train: </span>Fast image access  (ping: 31.367.9 ms, read: 7.42.1 MB/s, size: 14.4 KB)
<span class=" -Color -Color-Bold -Color-Bold-Blue">train: </span>Scanning C:\Users\Usher\Desktop\DL FINAL PROJECT\yolo\data\train\labels.cache... 1512 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 1512/1512 1.2Mit/s 0.0s
<span class=" -Color -Color-Bold -Color-Bold-Blue">val: </span>Fast image access  (ping: 0.50.3 ms, read: 17.35.8 MB/s, size: 17.7 KB)
<span class=" -Color -Color-Bold -Color-Bold-Blue">val: </span>Scanning C:\Users\Usher\Desktop\DL FINAL PROJECT\yolo\data\valid\labels.cache... 144 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 144/144 281.8Kit/s 0.0s
Plotting labels to C:\Users\Usher\Desktop\DL FINAL PROJECT\yolo\runs\detect\yolo8n_baseline\labels.jpg... 
<span class=" -Color -Color-Bold -Color-Bold-Blue">optimizer:</span> &#39;optimizer=auto&#39; found, ignoring &#39;lr0=0.01&#39; and &#39;momentum=0.937&#39; and determining best &#39;optimizer&#39;, &#39;lr0&#39; and &#39;momentum&#39; automatically... 
<span class=" -Color -Color-Bold -Color-Bold-Blue">optimizer:</span> AdamW(lr=0.000333, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)
Image sizes 640 train, 640 val
Using 0 dataloader workers
Logging results to <span class=" -Color -Color-Bold">C:\Users\Usher\Desktop\DL FINAL PROJECT\yolo\runs\detect\yolo8n_baseline</span>
Starting training for 10 epochs...
Closing dataloader mosaic

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
       1/10         0G     0.8753      4.711      1.486          8        640: 100% ━━━━━━━━━━━━ 95/95 4.9s/it 7:483.7ss
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.3s/it 16.5s4.8ss
                   all        144        144     0.0301      0.949      0.225      0.167

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
       2/10         0G     0.6643      3.657       1.25          8        640: 100% ━━━━━━━━━━━━ 95/95 4.8s/it 7:363.7ss
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.2s/it 16.2s4.7ss
                   all        144        144      0.473      0.487      0.505      0.391

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
       3/10         0G     0.6477      2.957      1.203          8        640: 100% ━━━━━━━━━━━━ 95/95 4.8s/it 7:373.7ss
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.2s/it 16.1s4.7ss
                   all        144        144      0.464      0.646      0.636      0.511

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
       4/10         0G     0.6168      2.427      1.165          8        640: 100% ━━━━━━━━━━━━ 95/95 4.9s/it 7:423.7ss
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.2s/it 16.2s4.8ss
                   all        144        144      0.585      0.759      0.759      0.569

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
       5/10         0G     0.5665      2.009      1.112          8        640: 100% ━━━━━━━━━━━━ 95/95 4.8s/it 7:383.7ss
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.3s/it 16.6s4.9ss
                   all        144        144      0.677      0.792      0.857      0.692

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
       6/10         0G     0.5355      1.718      1.081          8        640: 100% ━━━━━━━━━━━━ 95/95 4.8s/it 7:353.7ss
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.2s/it 16.1s4.7ss
                   all        144        144      0.738      0.778      0.846      0.685

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
       7/10         0G     0.5174      1.521      1.053          8        640: 100% ━━━━━━━━━━━━ 95/95 4.8s/it 7:363.6ss
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.2s/it 16.1s4.7ss
                   all        144        144      0.816      0.827      0.898      0.702

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
       8/10         0G     0.4989       1.39      1.032          8        640: 100% ━━━━━━━━━━━━ 95/95 4.9s/it 7:423.8ss
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.4s/it 17.0s5.0ss
                   all        144        144      0.862      0.824      0.923      0.718

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
       9/10         0G     0.4878       1.29       1.02          8        640: 100% ━━━━━━━━━━━━ 95/95 4.9s/it 7:453.7ss
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.3s/it 16.7s4.9ss
                   all        144        144      0.867      0.845      0.932      0.758

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
      10/10         0G     0.4585      1.213      1.001          8        640: 100% ━━━━━━━━━━━━ 95/95 4.9s/it 7:463.7ss
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 3.3s/it 16.3s4.8ss
                   all        144        144       0.87      0.865      0.933      0.762

10 epochs completed in 1.326 hours.
Optimizer stripped from C:\Users\Usher\Desktop\DL FINAL PROJECT\yolo\runs\detect\yolo8n_baseline\weights\last.pt, 6.3MB
Optimizer stripped from C:\Users\Usher\Desktop\DL FINAL PROJECT\yolo\runs\detect\yolo8n_baseline\weights\best.pt, 6.3MB

Validating C:\Users\Usher\Desktop\DL FINAL PROJECT\yolo\runs\detect\yolo8n_baseline\weights\best.pt...
Ultralytics 8.3.232  Python-3.12.4 torch-2.2.2+cpu CPU (AMD Ryzen 5 PRO 4650G with Radeon Graphics)
Model summary (fused): 72 layers, 3,010,718 parameters, 0 gradients, 8.1 GFLOPs
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 2.7s/it 13.3s4.0s
                   all        144        144      0.869      0.865      0.934      0.763
                     A          5          5      0.747        0.8       0.92      0.748
                     B          9          9          1      0.805      0.984      0.797
                     C          3          3      0.878          1      0.995      0.807
                     D          6          6      0.971          1      0.995      0.841
                     E          4          4      0.824          1      0.995      0.846
                     F          8          8      0.952          1      0.995      0.822
                     G          5          5      0.867          1      0.995      0.846
                     H          9          9      0.995          1      0.995      0.785
                     I          2          2      0.757        0.5      0.535       0.43
                     J          8          8          1      0.804      0.995      0.687
                     K          6          6      0.905      0.667      0.863      0.783
                     L          4          4      0.759      0.794      0.945      0.792
                     M          8          8      0.952      0.875      0.931      0.772
                     N          4          4      0.755      0.774      0.945      0.781
                     O          7          7          1       0.92      0.995       0.76
                     P          7          7      0.987      0.857      0.902      0.722
                     Q          4          4      0.745          1      0.995      0.806
                     R          7          7          1      0.751      0.995      0.793
                     S          4          4      0.901          1      0.995      0.821
                     T          6          6          1      0.812      0.872      0.735
                     U          7          7      0.772          1      0.964      0.811
                     V          5          5      0.592        0.6      0.615      0.502
                     W          3          3      0.813          1      0.995      0.808
                     X          1          1       0.43          1      0.995      0.895
                     Y          8          8          1      0.635      0.889      0.644
                     Z          4          4          1        0.9      0.995      0.797
Speed: 2.4ms preprocess, 83.1ms inference, 0.0ms loss, 0.6ms postprocess per image
Results saved to <span class=" -Color -Color-Bold">C:\Users\Usher\Desktop\DL FINAL PROJECT\yolo\runs\detect\yolo8n_baseline</span>
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>ultralytics.utils.metrics.DetMetrics object with attributes:

ap_class_index: array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25])
box: ultralytics.utils.metrics.Metric object
confusion_matrix: &lt;ultralytics.utils.metrics.ConfusionMatrix object at 0x000002BF007CA4E0&gt;
curves: [&#39;Precision-Recall(B)&#39;, &#39;F1-Confidence(B)&#39;, &#39;Precision-Confidence(B)&#39;, &#39;Recall-Confidence(B)&#39;]
curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,
          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,
          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,
          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,
          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,
           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,
           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,
           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,
           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,
           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,
           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,
           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,
           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,
           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,
           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,
           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,
           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,
           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,
           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,
           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,
           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,
            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,
           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,
           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,
           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,
            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,
           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,
           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,
           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,
            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,
           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,
           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,
           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,
           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,
           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,
           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,
           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,
           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,
           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,
           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,
           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,
           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1, ...,       0.625,       0.625,           0],
       [          1,           1,           1, ...,         0.9,         0.9,           0],
       [          1,           1,           1, ...,           1,           1,           0],
       ...,
       [          1,           1,           1, ...,           1,           1,           0],
       [          1,           1,           1, ...,     0.44444,     0.44444,           0],
       [          1,           1,           1, ...,           1,           1,           0]]), &#39;Recall&#39;, &#39;Precision&#39;], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,
          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,
          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,
          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,
          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,
           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,
           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,
           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,
           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,
           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,
           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,
           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,
           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,
           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,
           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,
           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,
           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,
           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,
           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,
           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,
           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,
            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,
           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,
           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,
           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,
            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,
           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,
           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,
           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,
            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,
           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,
           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,
           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,
           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,
           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,
           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,
           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,
           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,
           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,
           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,
           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,
           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[   0.064935,    0.064935,     0.10901, ...,           0,           0,           0],
       [    0.20455,     0.20455,     0.33513, ...,           0,           0,           0],
       [     0.0375,      0.0375,     0.07489, ...,           0,           0,           0],
       ...,
       [   0.022472,    0.022472,    0.036378, ...,           0,           0,           0],
       [    0.15534,     0.15534,     0.29877, ...,           0,           0,           0],
       [   0.096386,    0.096386,     0.27914, ...,           0,           0,           0]]), &#39;Confidence&#39;, &#39;F1&#39;], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,
          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,
          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,
          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,
          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,
           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,
           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,
           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,
           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,
           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,
           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,
           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,
           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,
           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,
           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,
           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,
           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,
           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,
           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,
           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,
           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,
            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,
           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,
           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,
           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,
            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,
           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,
           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,
           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,
            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,
           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,
           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,
           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,
           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,
           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,
           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,
           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,
           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,
           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,
           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,
           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,
           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[   0.033557,    0.033557,    0.057647, ...,           1,           1,           1],
       [    0.11392,     0.11392,     0.20129, ...,           1,           1,           1],
       [   0.019108,    0.019108,    0.038902, ...,           1,           1,           1],
       ...,
       [   0.011364,    0.011364,    0.018526, ...,           1,           1,           1],
       [   0.084211,    0.084211,     0.17562, ...,           1,           1,           1],
       [   0.050633,    0.050633,     0.16221, ...,           1,           1,           1]]), &#39;Confidence&#39;, &#39;Precision&#39;], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,
          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,
          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,
          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,
          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,
           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,
           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,
           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,
           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,
           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,
           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,
           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,
           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,
           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,
           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,
           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,
           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,
           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,
           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,
           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,
           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,
            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,
           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,
           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,
           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,
            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,
           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,
           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,
           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,
            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,
           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,
           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,
           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,
           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,
           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,
           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,
           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,
           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,
           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,
           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,
           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,
           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1, ...,           0,           0,           0],
       [          1,           1,           1, ...,           0,           0,           0],
       [          1,           1,           1, ...,           0,           0,           0],
       ...,
       [          1,           1,           1, ...,           0,           0,           0],
       [          1,           1,           1, ...,           0,           0,           0],
       [          1,           1,           1, ...,           0,           0,           0]]), &#39;Confidence&#39;, &#39;Recall&#39;]]
fitness: 0.7627286227705897
keys: [&#39;metrics/precision(B)&#39;, &#39;metrics/recall(B)&#39;, &#39;metrics/mAP50(B)&#39;, &#39;metrics/mAP50-95(B)&#39;]
maps: array([    0.74803,     0.79707,     0.80738,     0.84112,     0.84591,     0.82159,     0.84611,     0.78451,     0.43024,     0.68699,     0.78349,     0.79154,     0.77171,     0.78094,     0.76029,     0.72231,     0.80614,     0.79264,     0.82124,     0.73492,     0.81101,     0.50187,     0.80754,      0.8955,
           0.64407,     0.79679])
names: {0: &#39;A&#39;, 1: &#39;B&#39;, 2: &#39;C&#39;, 3: &#39;D&#39;, 4: &#39;E&#39;, 5: &#39;F&#39;, 6: &#39;G&#39;, 7: &#39;H&#39;, 8: &#39;I&#39;, 9: &#39;J&#39;, 10: &#39;K&#39;, 11: &#39;L&#39;, 12: &#39;M&#39;, 13: &#39;N&#39;, 14: &#39;O&#39;, 15: &#39;P&#39;, 16: &#39;Q&#39;, 17: &#39;R&#39;, 18: &#39;S&#39;, 19: &#39;T&#39;, 20: &#39;U&#39;, 21: &#39;V&#39;, 22: &#39;W&#39;, 23: &#39;X&#39;, 24: &#39;Y&#39;, 25: &#39;Z&#39;}
nt_per_class: array([5, 9, 3, 6, 4, 8, 5, 9, 2, 8, 6, 4, 8, 4, 7, 7, 4, 7, 4, 6, 7, 5, 3, 1, 8, 4], dtype=int64)
nt_per_image: array([5, 9, 3, 6, 4, 8, 5, 9, 2, 8, 6, 4, 8, 4, 7, 7, 4, 7, 4, 6, 7, 5, 3, 1, 8, 4], dtype=int64)
results_dict: {&#39;metrics/precision(B)&#39;: 0.8693218068559824, &#39;metrics/recall(B)&#39;: 0.8651601971836327, &#39;metrics/mAP50(B)&#39;: 0.9344253973778861, &#39;metrics/mAP50-95(B)&#39;: 0.7627286227705897, &#39;fitness&#39;: 0.7627286227705897}
save_dir: WindowsPath(&#39;C:/Users/Usher/Desktop/DL FINAL PROJECT/yolo/runs/detect/yolo8n_baseline&#39;)
speed: {&#39;preprocess&#39;: 2.4186437499906788, &#39;inference&#39;: 83.12695347223098, &#39;loss&#39;: 3.680555791005544e-05, &#39;postprocess&#39;: 0.5918472222169334}
stats: {&#39;tp&#39;: [], &#39;conf&#39;: [], &#39;pred_cls&#39;: [], &#39;target_cls&#39;: [], &#39;target_img&#39;: []}
task: &#39;detect&#39;
</pre></div>
</div>
</div>
</div>
</section>
<section id="yolov8-s-small">
<h3>YOLOv8-s (Small)<a class="headerlink" href="#yolov8-s-small" title="Permalink to this heading">#</a></h3>
<p>YOLOv8-s is a larger, more capable version of YOLOv8 that balances speed and detection performance. With more layers and parameters than the nano model, it captures richer features and achieves higher accuracy on the same dataset. YOLOv8-s serves as the main model to benchmark against the YOLOv8-n baseline, showing the benefits of increased model capacity.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ultralytics</span><span class="w"> </span><span class="kn">import</span> <span class="n">YOLO</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">YOLO</span><span class="p">(</span><span class="s2">&quot;yolov8s.pt&quot;</span><span class="p">)</span>  

<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span>
    <span class="n">data</span><span class="o">=</span><span class="s2">&quot;data/data.yaml&quot;</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">imgsz</span><span class="o">=</span><span class="mi">640</span><span class="p">,</span>
    <span class="n">batch</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
    <span class="n">name</span><span class="o">=</span><span class="s2">&quot;yolo_model&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Creating new Ultralytics Settings v0.0.6 file  
View Ultralytics Settings with &#39;yolo settings&#39; or at &#39;C:\Users\Usher\AppData\Roaming\Ultralytics\settings.json&#39;
Update Settings with &#39;yolo settings key=value&#39;, i.e. &#39;yolo settings runs_dir=path/to/dir&#39;. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.
Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8s.pt to &#39;yolov8s.pt&#39;: 100% ━━━━━━━━━━━━ 21.5MB 768.5KB/s 28.7s.7s&lt;0.0s9s6s
Ultralytics 8.3.232  Python-3.12.4 torch-2.2.2+cpu CPU (AMD Ryzen 5 PRO 4650G with Radeon Graphics)
<span class=" -Color -Color-Bold -Color-Bold-Blue">engine\trainer: </span>agnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=data/data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=10, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolo_model, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\Users\Usher\Desktop\DL FINAL PROJECT\yolo\runs\detect\yolo_model, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None
Overriding model.yaml nc=80 with nc=26

                   from  n    params  module                                       arguments                     
  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 
  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                
  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             
  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               
  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           
  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              
  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           
  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              
  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           
  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 
 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, &#39;nearest&#39;]          
 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           
 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 
 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, &#39;nearest&#39;]          
 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           
 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 
 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              
 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           
 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 
 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              
 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           
 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 
 22        [15, 18, 21]  1   2126110  ultralytics.nn.modules.head.Detect           [26, [128, 256, 512]]         
Model summary: 129 layers, 11,145,662 parameters, 11,145,646 gradients, 28.7 GFLOPs

Transferred 349/355 items from pretrained weights
Freezing layer &#39;model.22.dfl.conv.weight&#39;
<span class=" -Color -Color-Bold -Color-Bold-Blue">train: </span>Fast image access  (ping: 0.10.0 ms, read: 109.938.5 MB/s, size: 14.4 KB)
<span class=" -Color -Color-Bold -Color-Bold-Blue">train: </span>Scanning C:\Users\Usher\Desktop\DL FINAL PROJECT\yolo\data\train\labels... 1512 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 1512/1512 1.8Kit/s 0.9s0.1s
<span class=" -Color -Color-Bold -Color-Bold-Blue">train: </span>New cache created: C:\Users\Usher\Desktop\DL FINAL PROJECT\yolo\data\train\labels.cache
<span class=" -Color -Color-Bold -Color-Bold-Blue">val: </span>Fast image access  (ping: 0.10.0 ms, read: 177.034.7 MB/s, size: 17.7 KB)
<span class=" -Color -Color-Bold -Color-Bold-Blue">val: </span>Scanning C:\Users\Usher\Desktop\DL FINAL PROJECT\yolo\data\valid\labels... 144 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 144/144 1.7Kit/s 0.1s
<span class=" -Color -Color-Bold -Color-Bold-Blue">val: </span>New cache created: C:\Users\Usher\Desktop\DL FINAL PROJECT\yolo\data\valid\labels.cache
Plotting labels to C:\Users\Usher\Desktop\DL FINAL PROJECT\yolo\runs\detect\yolo_model\labels.jpg... 
<span class=" -Color -Color-Bold -Color-Bold-Blue">optimizer:</span> &#39;optimizer=auto&#39; found, ignoring &#39;lr0=0.01&#39; and &#39;momentum=0.937&#39; and determining best &#39;optimizer&#39;, &#39;lr0&#39; and &#39;momentum&#39; automatically... 
<span class=" -Color -Color-Bold -Color-Bold-Blue">optimizer:</span> AdamW(lr=0.000333, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)
Image sizes 640 train, 640 val
Using 0 dataloader workers
Logging results to <span class=" -Color -Color-Bold">C:\Users\Usher\Desktop\DL FINAL PROJECT\yolo\runs\detect\yolo_model</span>
Starting training for 10 epochs...
Closing dataloader mosaic

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
       1/10         0G     0.9363       5.53      1.538          8        640: 100% ━━━━━━━━━━━━ 95/95 11.5s/it 18:12.6s7s
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 8.0s/it 39.9s&lt;11.8s
                   all        144        144       0.41      0.663      0.541      0.418

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
       2/10         0G     0.6445      2.261      1.196          8        640: 100% ━━━━━━━━━━━━ 95/95 11.5s/it 18:14.7s8s
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.9s/it 39.3s&lt;11.6s
                   all        144        144      0.698      0.619      0.749      0.581

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
       3/10         0G     0.6133      1.527      1.142          8        640: 100% ━━━━━━━━━━━━ 95/95 11.4s/it 18:04.5s7s
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.7s/it 38.6s&lt;11.3s
                   all        144        144      0.509      0.748      0.758       0.62

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
       4/10         0G     0.6015      1.138      1.133          8        640: 100% ━━━━━━━━━━━━ 95/95 11.5s/it 18:11.6s9s
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.6s/it 38.1s&lt;11.2s
                   all        144        144      0.785       0.72      0.876      0.667

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
       5/10         0G     0.5689       0.85      1.102          8        640: 100% ━━━━━━━━━━━━ 95/95 11.3s/it 17:56.4s7s
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.6s/it 38.0s&lt;11.1s
                   all        144        144      0.872      0.818      0.911      0.729

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
       6/10         0G     0.5383     0.6856      1.069          8        640: 100% ━━━━━━━━━━━━ 95/95 11.4s/it 18:05.6s7s
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.6s/it 37.8s&lt;11.1s
                   all        144        144      0.902      0.795      0.918      0.745

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
       7/10         0G     0.5119      0.591      1.038          8        640: 100% ━━━━━━━━━━━━ 95/95 11.5s/it 18:12.4s6s
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.6s/it 38.1s&lt;11.1s
                   all        144        144       0.89      0.843      0.934      0.719

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
       8/10         0G     0.4962     0.4925      1.026          8        640: 100% ━━━━━━━━━━━━ 95/95 11.8s/it 18:37.2s4s
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.7s/it 38.5s&lt;11.2s
                   all        144        144      0.868      0.908      0.956      0.755

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
       9/10         0G     0.4713     0.4327      1.007          8        640: 100% ━━━━━━━━━━━━ 95/95 12.0s/it 18:60.9s1s
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 8.0s/it 40.1s&lt;11.8s
                   all        144        144      0.912      0.876      0.946      0.764

      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size
      10/10         0G     0.4464     0.3876     0.9846          8        640: 100% ━━━━━━━━━━━━ 95/95 12.0s/it 19:03.6s1s
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 7.6s/it 38.1s&lt;11.2s
                   all        144        144      0.942      0.868      0.961      0.778

10 epochs completed in 3.168 hours.
Optimizer stripped from C:\Users\Usher\Desktop\DL FINAL PROJECT\yolo\runs\detect\yolo_model\weights\last.pt, 22.5MB
Optimizer stripped from C:\Users\Usher\Desktop\DL FINAL PROJECT\yolo\runs\detect\yolo_model\weights\best.pt, 22.5MB

Validating C:\Users\Usher\Desktop\DL FINAL PROJECT\yolo\runs\detect\yolo_model\weights\best.pt...
Ultralytics 8.3.232  Python-3.12.4 torch-2.2.2+cpu CPU (AMD Ryzen 5 PRO 4650G with Radeon Graphics)
Model summary (fused): 72 layers, 11,135,646 parameters, 0 gradients, 28.5 GFLOPs
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 5/5 6.3s/it 31.7s9.3s5s
                   all        144        144      0.942      0.868      0.961      0.778
                     A          5          5      0.885        0.8      0.938      0.781
                     B          9          9          1      0.698      0.995      0.791
                     C          3          3          1      0.818      0.995      0.786
                     D          6          6      0.846      0.923      0.972      0.848
                     E          4          4      0.937          1      0.995       0.83
                     F          8          8      0.993          1      0.995      0.829
                     G          5          5      0.968          1      0.995      0.837
                     H          9          9      0.988          1      0.995      0.769
                     I          2          2       0.79        0.5      0.572      0.458
                     J          8          8       0.99          1      0.995      0.685
                     K          6          6          1      0.699      0.955      0.805
                     L          4          4      0.946       0.75      0.945      0.789
                     M          8          8          1       0.69      0.995      0.803
                     N          4          4      0.777          1      0.995      0.797
                     O          7          7      0.976          1      0.995      0.754
                     P          7          7          1      0.857      0.916      0.736
                     Q          4          4          1      0.975      0.995      0.807
                     R          7          7          1      0.788      0.995      0.813
                     S          4          4      0.959          1      0.995      0.796
                     T          6          6      0.987      0.833      0.972      0.843
                     U          7          7      0.821          1      0.943      0.777
                     V          5          5      0.919        0.6      0.846      0.711
                     W          3          3      0.925          1      0.995      0.796
                     X          1          1      0.827          1      0.995      0.895
                     Y          8          8          1      0.642      0.995      0.664
                     Z          4          4      0.964          1      0.995      0.816
Speed: 4.0ms preprocess, 208.9ms inference, 0.0ms loss, 0.5ms postprocess per image
Results saved to <span class=" -Color -Color-Bold">C:\Users\Usher\Desktop\DL FINAL PROJECT\yolo\runs\detect\yolo_model</span>
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>ultralytics.utils.metrics.DetMetrics object with attributes:

ap_class_index: array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25])
box: ultralytics.utils.metrics.Metric object
confusion_matrix: &lt;ultralytics.utils.metrics.ConfusionMatrix object at 0x000001782022BCE0&gt;
curves: [&#39;Precision-Recall(B)&#39;, &#39;F1-Confidence(B)&#39;, &#39;Precision-Confidence(B)&#39;, &#39;Recall-Confidence(B)&#39;]
curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,
          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,
          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,
          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,
          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,
           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,
           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,
           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,
           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,
           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,
           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,
           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,
           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,
           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,
           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,
           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,
           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,
           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,
           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,
           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,
           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,
            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,
           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,
           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,
           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,
            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,
           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,
           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,
           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,
            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,
           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,
           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,
           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,
           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,
           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,
           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,
           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,
           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,
           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,
           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,
           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,
           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1, ...,     0.71429,     0.71429,           0],
       [          1,           1,           1, ...,           1,           1,           0],
       [          1,           1,           1, ...,           1,           1,           0],
       ...,
       [          1,           1,           1, ...,           1,           1,           0],
       [          1,           1,           1, ...,           1,           1,           0],
       [          1,           1,           1, ...,           1,           1,           0]]), &#39;Recall&#39;, &#39;Precision&#39;], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,
          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,
          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,
          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,
          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,
           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,
           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,
           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,
           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,
           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,
           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,
           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,
           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,
           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,
           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,
           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,
           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,
           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,
           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,
           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,
           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,
            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,
           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,
           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,
           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,
            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,
           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,
           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,
           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,
            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,
           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,
           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,
           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,
           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,
           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,
           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,
           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,
           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,
           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,
           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,
           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,
           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.17857,     0.17857,     0.23288, ...,           0,           0,           0],
       [    0.46154,     0.46154,     0.54682, ...,           0,           0,           0],
       [    0.10526,     0.10526,     0.15419, ...,           0,           0,           0],
       ...,
       [   0.032258,    0.032258,    0.063481, ...,           0,           0,           0],
       [    0.51613,     0.51613,     0.61072, ...,           0,           0,           0],
       [    0.17021,     0.17021,     0.34315, ...,           0,           0,           0]]), &#39;Confidence&#39;, &#39;F1&#39;], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,
          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,
          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,
          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,
          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,
           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,
           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,
           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,
           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,
           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,
           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,
           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,
           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,
           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,
           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,
           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,
           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,
           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,
           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,
           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,
           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,
            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,
           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,
           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,
           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,
            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,
           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,
           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,
           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,
            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,
           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,
           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,
           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,
           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,
           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,
           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,
           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,
           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,
           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,
           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,
           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,
           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[   0.098039,    0.098039,     0.13179, ...,           1,           1,           1],
       [        0.3,         0.3,     0.37629, ...,           1,           1,           1],
       [   0.055556,    0.055556,    0.083537, ...,           1,           1,           1],
       ...,
       [   0.016393,    0.016393,    0.032781, ...,           1,           1,           1],
       [    0.34783,     0.34783,     0.43959, ...,           1,           1,           1],
       [   0.093023,    0.093023,     0.20711, ...,           1,           1,           1]]), &#39;Confidence&#39;, &#39;Precision&#39;], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,
          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,
          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,
          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,
          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,
           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,
           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,
           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,
           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,
           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,
           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,
           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,
           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,
           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,
           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,
           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,
           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,
           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,
           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,
           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,
           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,
            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,
           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,
           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,
           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,
            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,
           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,
           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,
           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,
            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,
           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,
           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,
           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,
           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,
           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,
           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,
           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,
           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,
           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,
           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,
           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,
           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1, ...,           0,           0,           0],
       [          1,           1,           1, ...,           0,           0,           0],
       [          1,           1,           1, ...,           0,           0,           0],
       ...,
       [          1,           1,           1, ...,           0,           0,           0],
       [          1,           1,           1, ...,           0,           0,           0],
       [          1,           1,           1, ...,           0,           0,           0]]), &#39;Confidence&#39;, &#39;Recall&#39;]]
fitness: 0.7775242600275724
keys: [&#39;metrics/precision(B)&#39;, &#39;metrics/recall(B)&#39;, &#39;metrics/mAP50(B)&#39;, &#39;metrics/mAP50-95(B)&#39;]
maps: array([    0.78111,     0.79055,     0.78641,     0.84793,     0.83031,     0.82904,     0.83715,     0.76894,     0.45754,     0.68548,     0.80477,     0.78883,     0.80317,     0.79658,     0.75445,     0.73614,     0.80657,      0.8129,       0.796,     0.84274,     0.77662,     0.71081,       0.796,      0.8955,
           0.66375,     0.81634])
names: {0: &#39;A&#39;, 1: &#39;B&#39;, 2: &#39;C&#39;, 3: &#39;D&#39;, 4: &#39;E&#39;, 5: &#39;F&#39;, 6: &#39;G&#39;, 7: &#39;H&#39;, 8: &#39;I&#39;, 9: &#39;J&#39;, 10: &#39;K&#39;, 11: &#39;L&#39;, 12: &#39;M&#39;, 13: &#39;N&#39;, 14: &#39;O&#39;, 15: &#39;P&#39;, 16: &#39;Q&#39;, 17: &#39;R&#39;, 18: &#39;S&#39;, 19: &#39;T&#39;, 20: &#39;U&#39;, 21: &#39;V&#39;, 22: &#39;W&#39;, 23: &#39;X&#39;, 24: &#39;Y&#39;, 25: &#39;Z&#39;}
nt_per_class: array([5, 9, 3, 6, 4, 8, 5, 9, 2, 8, 6, 4, 8, 4, 7, 7, 4, 7, 4, 6, 7, 5, 3, 1, 8, 4], dtype=int64)
nt_per_image: array([5, 9, 3, 6, 4, 8, 5, 9, 2, 8, 6, 4, 8, 4, 7, 7, 4, 7, 4, 6, 7, 5, 3, 1, 8, 4], dtype=int64)
results_dict: {&#39;metrics/precision(B)&#39;: 0.9422050859437487, &#39;metrics/recall(B)&#39;: 0.8682172775939839, &#39;metrics/mAP50(B)&#39;: 0.9605278855759626, &#39;metrics/mAP50-95(B)&#39;: 0.7775242600275724, &#39;fitness&#39;: 0.7775242600275724}
save_dir: WindowsPath(&#39;C:/Users/Usher/Desktop/DL FINAL PROJECT/yolo/runs/detect/yolo_model&#39;)
speed: {&#39;preprocess&#39;: 4.012181250004687, &#39;inference&#39;: 208.855733333318, &#39;loss&#39;: 3.8194457374629565e-05, &#39;postprocess&#39;: 0.520497222219597}
stats: {&#39;tp&#39;: [], &#39;conf&#39;: [], &#39;pred_cls&#39;: [], &#39;target_cls&#39;: [], &#39;target_img&#39;: []}
task: &#39;detect&#39;
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="results">
<h1>Results<a class="headerlink" href="#results" title="Permalink to this heading">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># ---------- PLOTTER FUNCTION ----------</span>
<span class="k">def</span><span class="w"> </span><span class="nf">plot_results</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">model_title</span><span class="p">):</span>
    <span class="n">rows</span> <span class="o">=</span> <span class="mi">5</span>
    <span class="n">cols</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">rows</span><span class="p">,</span> <span class="n">cols</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span> <span class="mi">18</span><span class="p">))</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_title</span><span class="si">}</span><span class="s2"> Training Metrics&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">metric_key</span><span class="p">,</span> <span class="n">metric_title</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">metrics</span><span class="p">):</span>
        <span class="n">r</span> <span class="o">=</span> <span class="n">i</span> <span class="o">//</span> <span class="n">cols</span>
        <span class="n">c</span> <span class="o">=</span> <span class="n">i</span> <span class="o">%</span> <span class="n">cols</span>
        <span class="n">ax</span> <span class="o">=</span> <span class="n">axes</span><span class="p">[</span><span class="n">r</span><span class="p">][</span><span class="n">c</span><span class="p">]</span>

        <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;epoch&quot;</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="n">metric_key</span><span class="p">],</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">metric_title</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Epoch&quot;</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="n">metric_title</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">(</span><span class="n">rect</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mf">0.97</span><span class="p">])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Metrics to plot</span>
<span class="n">metrics</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="s2">&quot;train/box_loss&quot;</span><span class="p">,</span> <span class="s2">&quot;Train Box Loss&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;train/cls_loss&quot;</span><span class="p">,</span> <span class="s2">&quot;Train Class Loss&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;train/dfl_loss&quot;</span><span class="p">,</span> <span class="s2">&quot;Train DFL Loss&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;val/box_loss&quot;</span><span class="p">,</span> <span class="s2">&quot;Validation Box Loss&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;val/cls_loss&quot;</span><span class="p">,</span> <span class="s2">&quot;Validation Class Loss&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;val/dfl_loss&quot;</span><span class="p">,</span> <span class="s2">&quot;Validation DFL Loss&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;metrics/precision(B)&quot;</span><span class="p">,</span> <span class="s2">&quot;Precision&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;metrics/recall(B)&quot;</span><span class="p">,</span> <span class="s2">&quot;Recall&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;metrics/mAP50(B)&quot;</span><span class="p">,</span> <span class="s2">&quot;mAP@50&quot;</span><span class="p">),</span>
    <span class="p">(</span><span class="s2">&quot;metrics/mAP50-95(B)&quot;</span><span class="p">,</span> <span class="s2">&quot;mAP@50-95&quot;</span><span class="p">)</span>
<span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<section id="id1">
<h2>YOLOv8-n (Nano)<a class="headerlink" href="#id1" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_baseline</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;runs/detect/yolo8n_baseline/results.csv&quot;</span><span class="p">)</span>
<span class="n">plot_results</span><span class="p">(</span><span class="n">df_baseline</span><span class="p">,</span> <span class="s2">&quot;YOLOv8-n&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/b09feb7cbbd952fa37e1d7b7d07be77ee6406ed77110e243b4c5b4062bdb603f.png" src="../_images/b09feb7cbbd952fa37e1d7b7d07be77ee6406ed77110e243b4c5b4062bdb603f.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;runs/detect/yolo8n_baseline/results.csv&quot;</span><span class="p">)</span>
<span class="n">best</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;metrics/mAP50-95(B)&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">idxmax</span><span class="p">()]</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best Epoch:&quot;</span><span class="p">,</span> <span class="n">best</span><span class="p">[</span><span class="s2">&quot;epoch&quot;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best mAP50-95:&quot;</span><span class="p">,</span> <span class="n">best</span><span class="p">[</span><span class="s2">&quot;metrics/mAP50-95(B)&quot;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best Precision:&quot;</span><span class="p">,</span> <span class="n">best</span><span class="p">[</span><span class="s2">&quot;metrics/precision(B)&quot;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best Recall:&quot;</span><span class="p">,</span> <span class="n">best</span><span class="p">[</span><span class="s2">&quot;metrics/recall(B)&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Best Epoch: 10.0
Best mAP50-95: 0.76236
Best Precision: 0.86954
Best Recall: 0.86505
</pre></div>
</div>
</div>
</div>
</section>
<section id="id2">
<h2>YOLOv8-s (Small)<a class="headerlink" href="#id2" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_model</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;runs/detect/yolo_model/results.csv&quot;</span><span class="p">)</span>
<span class="n">plot_results</span><span class="p">(</span><span class="n">df_model</span><span class="p">,</span> <span class="s2">&quot;YOLOv8-s&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/fe27815248a19baf40d58ede11c3437ebfe1b8daab886459814118deb84548e2.png" src="../_images/fe27815248a19baf40d58ede11c3437ebfe1b8daab886459814118deb84548e2.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;runs/detect/yolo_model/results.csv&quot;</span><span class="p">)</span>
<span class="n">best</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;metrics/mAP50-95(B)&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">idxmax</span><span class="p">()]</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best Epoch:&quot;</span><span class="p">,</span> <span class="n">best</span><span class="p">[</span><span class="s2">&quot;epoch&quot;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best mAP50-95:&quot;</span><span class="p">,</span> <span class="n">best</span><span class="p">[</span><span class="s2">&quot;metrics/mAP50-95(B)&quot;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best Precision:&quot;</span><span class="p">,</span> <span class="n">best</span><span class="p">[</span><span class="s2">&quot;metrics/precision(B)&quot;</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Best Recall:&quot;</span><span class="p">,</span> <span class="n">best</span><span class="p">[</span><span class="s2">&quot;metrics/recall(B)&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Best Epoch: 10.0
Best mAP50-95: 0.77813
Best Precision: 0.94178
Best Recall: 0.86841
</pre></div>
</div>
</div>
</div>
</section>
<section id="yolov8-model-performance-comparison">
<h2>YOLOv8 Model Performance Comparison<a class="headerlink" href="#yolov8-model-performance-comparison" title="Permalink to this heading">#</a></h2>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Model</p></th>
<th class="head text-right"><p>Best Epoch</p></th>
<th class="head text-right"><p>mAP50-95</p></th>
<th class="head text-right"><p>Precision</p></th>
<th class="head text-right"><p>Recall</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>YOLOv8-n</strong></p></td>
<td class="text-right"><p>10</p></td>
<td class="text-right"><p>0.76236</p></td>
<td class="text-right"><p>0.86954</p></td>
<td class="text-right"><p>0.86505</p></td>
</tr>
<tr class="row-odd"><td><p><strong>YOLOv8-s</strong></p></td>
<td class="text-right"><p>10</p></td>
<td class="text-right"><p>0.77813</p></td>
<td class="text-right"><p>0.94178</p></td>
<td class="text-right"><p>0.86841</p></td>
</tr>
</tbody>
</table>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="video-testing">
<h1>Video Testing<a class="headerlink" href="#video-testing" title="Permalink to this heading">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ultralytics</span><span class="w"> </span><span class="kn">import</span> <span class="n">YOLO</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">cv2</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn.functional</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">F</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">collections</span><span class="w"> </span><span class="kn">import</span> <span class="n">Counter</span>
</pre></div>
</div>
</div>
</div>
<section id="functions">
<h2>Functions<a class="headerlink" href="#functions" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_video_rotation</span><span class="p">(</span><span class="n">video_path</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Extract rotation metadata from video file.&quot;&quot;&quot;</span>
    <span class="n">cap</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">VideoCapture</span><span class="p">(</span><span class="n">video_path</span><span class="p">)</span>
    <span class="n">rotation</span> <span class="o">=</span> <span class="n">cap</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">cv2</span><span class="o">.</span><span class="n">CAP_PROP_ORIENTATION_META</span><span class="p">)</span>
    <span class="n">cap</span><span class="o">.</span><span class="n">release</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">rotation</span>

<span class="k">def</span><span class="w"> </span><span class="nf">rotate_frame</span><span class="p">(</span><span class="n">frame</span><span class="p">,</span> <span class="n">rotation</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Rotate frame based on rotation angle.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">rotation</span> <span class="o">==</span> <span class="mi">90</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">cv2</span><span class="o">.</span><span class="n">rotate</span><span class="p">(</span><span class="n">frame</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">ROTATE_90_CLOCKWISE</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">rotation</span> <span class="o">==</span> <span class="mi">180</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">cv2</span><span class="o">.</span><span class="n">rotate</span><span class="p">(</span><span class="n">frame</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">ROTATE_180</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">rotation</span> <span class="o">==</span> <span class="mi">270</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">cv2</span><span class="o">.</span><span class="n">rotate</span><span class="p">(</span><span class="n">frame</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">ROTATE_90_COUNTERCLOCKWISE</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">frame</span>

<span class="k">def</span><span class="w"> </span><span class="nf">get_dominant_letter</span><span class="p">(</span><span class="n">detections</span><span class="p">,</span> <span class="n">conf_threshold</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Get the most confident letter detection from a frame.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">detections</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">None</span>
    
    <span class="c1"># Get the first result (frame detections)</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">detections</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    
    <span class="c1"># Check if there are any boxes detected</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">boxes</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">None</span>
    
    <span class="c1"># Filter by confidence threshold</span>
    <span class="n">valid_detections</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">boxes</span><span class="p">)):</span>
        <span class="n">confidence</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">boxes</span><span class="o">.</span><span class="n">conf</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
        <span class="k">if</span> <span class="n">confidence</span> <span class="o">&gt;=</span> <span class="n">conf_threshold</span><span class="p">:</span>
            <span class="n">class_id</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">result</span><span class="o">.</span><span class="n">boxes</span><span class="o">.</span><span class="n">cls</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
            <span class="n">class_name</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">names</span><span class="p">[</span><span class="n">class_id</span><span class="p">]</span>
            <span class="n">valid_detections</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">class_name</span><span class="p">,</span> <span class="n">confidence</span><span class="p">))</span>
    
    <span class="k">if</span> <span class="ow">not</span> <span class="n">valid_detections</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">None</span>
    
    <span class="c1"># Return the detection with highest confidence</span>
    <span class="k">return</span> <span class="nb">max</span><span class="p">(</span><span class="n">valid_detections</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span>

<span class="k">def</span><span class="w"> </span><span class="nf">levenshtein_distance</span><span class="p">(</span><span class="n">s1</span><span class="p">,</span> <span class="n">s2</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Calculate Levenshtein (edit) distance between two strings.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">s1</span><span class="p">)</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">s2</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">levenshtein_distance</span><span class="p">(</span><span class="n">s2</span><span class="p">,</span> <span class="n">s1</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">s2</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="n">s1</span><span class="p">)</span>
    
    <span class="n">previous_row</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">s2</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">c1</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">s1</span><span class="p">):</span>
        <span class="n">current_row</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">c2</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">s2</span><span class="p">):</span>
            <span class="c1"># Cost of insertions, deletions, or substitutions</span>
            <span class="n">insertions</span> <span class="o">=</span> <span class="n">previous_row</span><span class="p">[</span><span class="n">j</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span>
            <span class="n">deletions</span> <span class="o">=</span> <span class="n">current_row</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span>
            <span class="n">substitutions</span> <span class="o">=</span> <span class="n">previous_row</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="n">c1</span> <span class="o">!=</span> <span class="n">c2</span><span class="p">)</span>
            <span class="n">current_row</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">insertions</span><span class="p">,</span> <span class="n">deletions</span><span class="p">,</span> <span class="n">substitutions</span><span class="p">))</span>
        <span class="n">previous_row</span> <span class="o">=</span> <span class="n">current_row</span>
    
    <span class="k">return</span> <span class="n">previous_row</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

<span class="k">def</span><span class="w"> </span><span class="nf">calculate_accuracy_metrics</span><span class="p">(</span><span class="n">predicted</span><span class="p">,</span> <span class="n">ground_truth</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Calculate various accuracy metrics for sequence prediction.&quot;&quot;&quot;</span>
    <span class="c1"># Exact match</span>
    <span class="n">exact_match</span> <span class="o">=</span> <span class="n">predicted</span> <span class="o">==</span> <span class="n">ground_truth</span>
    
    <span class="c1"># Levenshtein distance</span>
    <span class="n">edit_distance</span> <span class="o">=</span> <span class="n">levenshtein_distance</span><span class="p">(</span><span class="n">predicted</span><span class="p">,</span> <span class="n">ground_truth</span><span class="p">)</span>
    
    <span class="c1"># Character-level accuracy (considering alignment)</span>
    <span class="n">max_len</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">predicted</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">ground_truth</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">max_len</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">char_accuracy</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">char_accuracy</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="p">(</span><span class="n">edit_distance</span> <span class="o">/</span> <span class="n">max_len</span><span class="p">)</span>
    
    <span class="c1"># Word Error Rate (WER) - normalized edit distance</span>
    <span class="n">wer</span> <span class="o">=</span> <span class="n">edit_distance</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">ground_truth</span><span class="p">)</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">ground_truth</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">)</span>
    
    <span class="c1"># Character Error Rate (CER)</span>
    <span class="n">cer</span> <span class="o">=</span> <span class="n">edit_distance</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">ground_truth</span><span class="p">)</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">ground_truth</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">)</span>
    
    <span class="c1"># Subsequence matching (how many ground truth chars appear in order)</span>
    <span class="n">subsequence_matches</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">pred_idx</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">gt_char</span> <span class="ow">in</span> <span class="n">ground_truth</span><span class="p">:</span>
        <span class="k">while</span> <span class="n">pred_idx</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">predicted</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">predicted</span><span class="p">[</span><span class="n">pred_idx</span><span class="p">]</span> <span class="o">==</span> <span class="n">gt_char</span><span class="p">:</span>
                <span class="n">subsequence_matches</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="n">pred_idx</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="k">break</span>
            <span class="n">pred_idx</span> <span class="o">+=</span> <span class="mi">1</span>
    
    <span class="n">subsequence_accuracy</span> <span class="o">=</span> <span class="n">subsequence_matches</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">ground_truth</span><span class="p">)</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">ground_truth</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mf">0.0</span>
    
    <span class="k">return</span> <span class="p">{</span>
        <span class="s1">&#39;exact_match&#39;</span><span class="p">:</span> <span class="n">exact_match</span><span class="p">,</span>
        <span class="s1">&#39;edit_distance&#39;</span><span class="p">:</span> <span class="n">edit_distance</span><span class="p">,</span>
        <span class="s1">&#39;character_accuracy&#39;</span><span class="p">:</span> <span class="n">char_accuracy</span> <span class="o">*</span> <span class="mi">100</span><span class="p">,</span>  <span class="c1"># as percentage</span>
        <span class="s1">&#39;wer&#39;</span><span class="p">:</span> <span class="n">wer</span> <span class="o">*</span> <span class="mi">100</span><span class="p">,</span>  <span class="c1"># as percentage</span>
        <span class="s1">&#39;cer&#39;</span><span class="p">:</span> <span class="n">cer</span> <span class="o">*</span> <span class="mi">100</span><span class="p">,</span>  <span class="c1"># as percentage</span>
        <span class="s1">&#39;subsequence_accuracy&#39;</span><span class="p">:</span> <span class="n">subsequence_accuracy</span> <span class="o">*</span> <span class="mi">100</span>  <span class="c1"># as percentage</span>
    <span class="p">}</span>

<span class="k">def</span><span class="w"> </span><span class="nf">evaluate_prediction</span><span class="p">(</span><span class="n">predicted</span><span class="p">,</span> <span class="n">ground_truth</span><span class="p">,</span> <span class="n">model_name</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Evaluate and print prediction metrics.&quot;&quot;&quot;</span>
    <span class="n">metrics</span> <span class="o">=</span> <span class="n">calculate_accuracy_metrics</span><span class="p">(</span><span class="n">predicted</span><span class="p">,</span> <span class="n">ground_truth</span><span class="p">)</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="si">{</span><span class="s1">&#39;=&#39;</span><span class="o">*</span><span class="mi">60</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2"> EVALUATION&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="s1">&#39;=&#39;</span><span class="o">*</span><span class="mi">60</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Ground Truth:  &#39;</span><span class="si">{</span><span class="n">ground_truth</span><span class="si">}</span><span class="s2">&#39;&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Predicted:     &#39;</span><span class="si">{</span><span class="n">predicted</span><span class="si">}</span><span class="s2">&#39;&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Metrics:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Exact Match:           </span><span class="si">{</span><span class="s1">&#39;✓ YES&#39;</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;exact_match&#39;</span><span class="p">]</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="s1">&#39;✗ NO&#39;</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Edit Distance:         </span><span class="si">{</span><span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;edit_distance&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> operations&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Character Accuracy:    </span><span class="si">{</span><span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;character_accuracy&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Character Error Rate:  </span><span class="si">{</span><span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;cer&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Word Error Rate:       </span><span class="si">{</span><span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;wer&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Subsequence Accuracy:  </span><span class="si">{</span><span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;subsequence_accuracy&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="s1">&#39;=&#39;</span><span class="o">*</span><span class="mi">60</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">metrics</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Reconstruct letter sequence from frame-by-frame detections.</span>
<span class="sd">    Only adds a letter if it appears for at least stability_threshold consecutive frames.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">letter_history</span><span class="p">:</span>
        <span class="k">return</span> <span class="s2">&quot;&quot;</span>
    
    <span class="n">sequence</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">current_letter</span> <span class="o">=</span> <span class="n">letter_history</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">count</span> <span class="o">=</span> <span class="mi">1</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">letter_history</span><span class="p">)):</span>
        <span class="k">if</span> <span class="n">letter_history</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="n">current_letter</span><span class="p">:</span>
            <span class="n">count</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Letter changed - check if previous letter was stable enough</span>
            <span class="k">if</span> <span class="n">current_letter</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">count</span> <span class="o">&gt;=</span> <span class="n">stability_threshold</span><span class="p">:</span>
                <span class="n">sequence</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">current_letter</span><span class="p">)</span>
            <span class="n">current_letter</span> <span class="o">=</span> <span class="n">letter_history</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">count</span> <span class="o">=</span> <span class="mi">1</span>
    
    <span class="c1"># Add the last letter if stable</span>
    <span class="k">if</span> <span class="n">current_letter</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">count</span> <span class="o">&gt;=</span> <span class="n">stability_threshold</span><span class="p">:</span>
        <span class="n">sequence</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">current_letter</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">sequence</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">reconstruct_sequence</span><span class="p">(</span><span class="n">letter_history</span><span class="p">,</span> <span class="n">stability_threshold</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Reconstruct letter sequence from frame-by-frame detections.</span>
<span class="sd">    Only adds a letter if it appears for at least stability_threshold consecutive frames.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">letter_history</span><span class="p">:</span>
        <span class="k">return</span> <span class="s2">&quot;&quot;</span>
    
    <span class="n">sequence</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">current_letter</span> <span class="o">=</span> <span class="n">letter_history</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">count</span> <span class="o">=</span> <span class="mi">1</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">letter_history</span><span class="p">)):</span>
        <span class="k">if</span> <span class="n">letter_history</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="n">current_letter</span><span class="p">:</span>
            <span class="n">count</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Letter changed - check if previous letter was stable enough</span>
            <span class="k">if</span> <span class="n">current_letter</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">count</span> <span class="o">&gt;=</span> <span class="n">stability_threshold</span><span class="p">:</span>
                <span class="n">sequence</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">current_letter</span><span class="p">)</span>
            <span class="n">current_letter</span> <span class="o">=</span> <span class="n">letter_history</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="n">count</span> <span class="o">=</span> <span class="mi">1</span>
    
    <span class="c1"># Add the last letter if stable</span>
    <span class="k">if</span> <span class="n">current_letter</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">count</span> <span class="o">&gt;=</span> <span class="n">stability_threshold</span><span class="p">:</span>
        <span class="n">sequence</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">current_letter</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">sequence</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">test_model_with_sequence</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">model_name</span><span class="p">,</span> <span class="n">video_path</span><span class="p">,</span> <span class="n">output_dir</span><span class="p">,</span> <span class="n">vid_name</span><span class="p">,</span> 
                              <span class="n">conf_threshold</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">stability_threshold</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Run inference and reconstruct letter sequence.&quot;&quot;&quot;</span>
    <span class="n">cap</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">VideoCapture</span><span class="p">(</span><span class="n">video_path</span><span class="p">)</span>
    
    <span class="c1"># Get rotation metadata</span>
    <span class="n">rotation</span> <span class="o">=</span> <span class="n">get_video_rotation</span><span class="p">(</span><span class="n">video_path</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Video rotation metadata: </span><span class="si">{</span><span class="n">rotation</span><span class="si">}</span><span class="s2"> degrees&quot;</span><span class="p">)</span>
    
    <span class="n">width</span>  <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">cap</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">cv2</span><span class="o">.</span><span class="n">CAP_PROP_FRAME_WIDTH</span><span class="p">))</span>
    <span class="n">height</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">cap</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">cv2</span><span class="o">.</span><span class="n">CAP_PROP_FRAME_HEIGHT</span><span class="p">))</span>
    <span class="n">fps</span>    <span class="o">=</span> <span class="n">cap</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">cv2</span><span class="o">.</span><span class="n">CAP_PROP_FPS</span><span class="p">)</span>
    
    <span class="c1"># Adjust dimensions if rotation is 90 or 270 degrees</span>
    <span class="k">if</span> <span class="n">rotation</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">90</span><span class="p">,</span> <span class="mi">270</span><span class="p">]:</span>
        <span class="n">width</span><span class="p">,</span> <span class="n">height</span> <span class="o">=</span> <span class="n">height</span><span class="p">,</span> <span class="n">width</span>
    
    <span class="n">out_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_dir</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">vid_name</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">.mp4&quot;</span><span class="p">)</span>
    <span class="n">fourcc</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">VideoWriter_fourcc</span><span class="p">(</span><span class="o">*</span><span class="s1">&#39;mp4v&#39;</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">VideoWriter</span><span class="p">(</span><span class="n">out_path</span><span class="p">,</span> <span class="n">fourcc</span><span class="p">,</span> <span class="n">fps</span><span class="p">,</span> <span class="p">(</span><span class="n">width</span><span class="p">,</span> <span class="n">height</span><span class="p">))</span>
    
    <span class="n">letter_history</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">frame_count</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">detection_stats</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">()</span>
    
    <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
        <span class="n">ret</span><span class="p">,</span> <span class="n">frame</span> <span class="o">=</span> <span class="n">cap</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">ret</span><span class="p">:</span>
            <span class="k">break</span>
        
        <span class="c1"># Apply rotation correction</span>
        <span class="n">frame</span> <span class="o">=</span> <span class="n">rotate_frame</span><span class="p">(</span><span class="n">frame</span><span class="p">,</span> <span class="n">rotation</span><span class="p">)</span>
        
        <span class="c1"># Run inference</span>
        <span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">frame</span><span class="p">,</span> <span class="n">conf</span><span class="o">=</span><span class="n">conf_threshold</span><span class="p">)</span>
        
        <span class="c1"># Get dominant letter in this frame</span>
        <span class="n">dominant_letter</span> <span class="o">=</span> <span class="n">get_dominant_letter</span><span class="p">(</span><span class="n">results</span><span class="p">,</span> <span class="n">conf_threshold</span><span class="p">)</span>
        <span class="n">letter_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dominant_letter</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">dominant_letter</span><span class="p">:</span>
            <span class="n">detection_stats</span><span class="p">[</span><span class="n">dominant_letter</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
        
        <span class="c1"># Get annotated frame</span>
        <span class="n">annotated_frame</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
        
        <span class="c1"># Add current detected letter to frame</span>
        <span class="k">if</span> <span class="n">dominant_letter</span><span class="p">:</span>
            <span class="n">cv2</span><span class="o">.</span><span class="n">putText</span><span class="p">(</span><span class="n">annotated_frame</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Letter: </span><span class="si">{</span><span class="n">dominant_letter</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> 
                       <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">30</span><span class="p">),</span> <span class="n">cv2</span><span class="o">.</span><span class="n">FONT_HERSHEY_SIMPLEX</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>
        
        <span class="c1"># Ensure uint8</span>
        <span class="k">if</span> <span class="n">annotated_frame</span><span class="o">.</span><span class="n">dtype</span> <span class="o">!=</span> <span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">:</span>
            <span class="n">annotated_frame</span> <span class="o">=</span> <span class="p">(</span><span class="n">annotated_frame</span> <span class="o">*</span> <span class="mi">255</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
        
        <span class="n">out</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">annotated_frame</span><span class="p">)</span>
        <span class="n">frame_count</span> <span class="o">+=</span> <span class="mi">1</span>
        
        <span class="k">if</span> <span class="n">frame_count</span> <span class="o">%</span> <span class="mi">30</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Processed </span><span class="si">{</span><span class="n">frame_count</span><span class="si">}</span><span class="s2"> frames...&quot;</span><span class="p">)</span>
    
    <span class="n">cap</span><span class="o">.</span><span class="n">release</span><span class="p">()</span>
    <span class="n">out</span><span class="o">.</span><span class="n">release</span><span class="p">()</span>
    
    <span class="c1"># Reconstruct sequence</span>
    <span class="n">reconstructed_sequence</span> <span class="o">=</span> <span class="n">reconstruct_sequence</span><span class="p">(</span><span class="n">letter_history</span><span class="p">,</span> <span class="n">stability_threshold</span><span class="p">)</span>
    
    <span class="c1"># Print results</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="si">{</span><span class="s1">&#39;=&#39;</span><span class="o">*</span><span class="mi">60</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model: </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="s1">&#39;=&#39;</span><span class="o">*</span><span class="mi">60</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Output video: </span><span class="si">{</span><span class="n">out_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Total frames: </span><span class="si">{</span><span class="n">frame_count</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Frames with detections: </span><span class="si">{</span><span class="nb">sum</span><span class="p">(</span><span class="mi">1</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">letter_history</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="ow">is</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="kc">None</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Detection frequency:&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">letter</span><span class="p">,</span> <span class="n">count</span> <span class="ow">in</span> <span class="n">detection_stats</span><span class="o">.</span><span class="n">most_common</span><span class="p">():</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">letter</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">count</span><span class="si">}</span><span class="s2"> frames (</span><span class="si">{</span><span class="n">count</span><span class="o">/</span><span class="n">frame_count</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">%)&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Reconstructed sequence: </span><span class="si">{</span><span class="n">reconstructed_sequence</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sequence length: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">reconstructed_sequence</span><span class="p">)</span><span class="si">}</span><span class="s2"> letters&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="s1">&#39;=&#39;</span><span class="o">*</span><span class="mi">60</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">reconstructed_sequence</span><span class="p">,</span> <span class="n">detection_stats</span>

<span class="k">def</span><span class="w"> </span><span class="nf">create_side_by_side_comparison</span><span class="p">(</span><span class="n">model_n</span><span class="p">,</span> <span class="n">model_s</span><span class="p">,</span> <span class="n">video_path</span><span class="p">,</span> <span class="n">output_dir</span><span class="p">,</span> <span class="n">vid_name</span><span class="p">,</span>
                                   <span class="n">conf_threshold</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">stability_threshold</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Create side-by-side comparison video of both models.&quot;&quot;&quot;</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">re</span>
    
    <span class="c1"># Extract ground truth from video name</span>
    <span class="n">ground_truth_match</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;([A-Za-z]+)&#39;</span><span class="p">,</span> <span class="n">vid_name</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">ground_truth_match</span><span class="p">:</span>
        <span class="n">ground_truth</span> <span class="o">=</span> <span class="n">ground_truth_match</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">ground_truth</span> <span class="o">=</span> <span class="n">vid_name</span><span class="o">.</span><span class="n">upper</span><span class="p">()</span>
    
    <span class="n">cap</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">VideoCapture</span><span class="p">(</span><span class="n">video_path</span><span class="p">)</span>
    
    <span class="c1"># Get rotation metadata</span>
    <span class="n">rotation</span> <span class="o">=</span> <span class="n">get_video_rotation</span><span class="p">(</span><span class="n">video_path</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Video rotation metadata: </span><span class="si">{</span><span class="n">rotation</span><span class="si">}</span><span class="s2"> degrees&quot;</span><span class="p">)</span>
    
    <span class="n">width</span>  <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">cap</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">cv2</span><span class="o">.</span><span class="n">CAP_PROP_FRAME_WIDTH</span><span class="p">))</span>
    <span class="n">height</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">cap</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">cv2</span><span class="o">.</span><span class="n">CAP_PROP_FRAME_HEIGHT</span><span class="p">))</span>
    <span class="n">fps</span>    <span class="o">=</span> <span class="n">cap</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">cv2</span><span class="o">.</span><span class="n">CAP_PROP_FPS</span><span class="p">)</span>
    
    <span class="c1"># Adjust dimensions if rotation is 90 or 270 degrees</span>
    <span class="k">if</span> <span class="n">rotation</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">90</span><span class="p">,</span> <span class="mi">270</span><span class="p">]:</span>
        <span class="n">width</span><span class="p">,</span> <span class="n">height</span> <span class="o">=</span> <span class="n">height</span><span class="p">,</span> <span class="n">width</span>
    
    <span class="c1"># Side-by-side video will be double width</span>
    <span class="n">comparison_width</span> <span class="o">=</span> <span class="n">width</span> <span class="o">*</span> <span class="mi">2</span>
    
    <span class="n">out_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_dir</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">vid_name</span><span class="si">}</span><span class="s2">_comparison.mp4&quot;</span><span class="p">)</span>
    <span class="n">fourcc</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">VideoWriter_fourcc</span><span class="p">(</span><span class="o">*</span><span class="s1">&#39;mp4v&#39;</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">VideoWriter</span><span class="p">(</span><span class="n">out_path</span><span class="p">,</span> <span class="n">fourcc</span><span class="p">,</span> <span class="n">fps</span><span class="p">,</span> <span class="p">(</span><span class="n">comparison_width</span><span class="p">,</span> <span class="n">height</span><span class="p">))</span>
    
    <span class="n">letter_history_n</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">letter_history_s</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">detection_stats_n</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">()</span>
    <span class="n">detection_stats_s</span> <span class="o">=</span> <span class="n">Counter</span><span class="p">()</span>
    <span class="n">frame_count</span> <span class="o">=</span> <span class="mi">0</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Processing frames for side-by-side comparison...&quot;</span><span class="p">)</span>
    
    <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
        <span class="n">ret</span><span class="p">,</span> <span class="n">frame</span> <span class="o">=</span> <span class="n">cap</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">ret</span><span class="p">:</span>
            <span class="k">break</span>
        
        <span class="c1"># Apply rotation correction</span>
        <span class="n">frame</span> <span class="o">=</span> <span class="n">rotate_frame</span><span class="p">(</span><span class="n">frame</span><span class="p">,</span> <span class="n">rotation</span><span class="p">)</span>
        
        <span class="c1"># Run inference on both models</span>
        <span class="n">results_n</span> <span class="o">=</span> <span class="n">model_n</span><span class="p">(</span><span class="n">frame</span><span class="p">,</span> <span class="n">conf</span><span class="o">=</span><span class="n">conf_threshold</span><span class="p">)</span>
        <span class="n">results_s</span> <span class="o">=</span> <span class="n">model_s</span><span class="p">(</span><span class="n">frame</span><span class="p">,</span> <span class="n">conf</span><span class="o">=</span><span class="n">conf_threshold</span><span class="p">)</span>
        
        <span class="c1"># Get dominant letters</span>
        <span class="n">dominant_letter_n</span> <span class="o">=</span> <span class="n">get_dominant_letter</span><span class="p">(</span><span class="n">results_n</span><span class="p">,</span> <span class="n">conf_threshold</span><span class="p">)</span>
        <span class="n">dominant_letter_s</span> <span class="o">=</span> <span class="n">get_dominant_letter</span><span class="p">(</span><span class="n">results_s</span><span class="p">,</span> <span class="n">conf_threshold</span><span class="p">)</span>
        
        <span class="n">letter_history_n</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dominant_letter_n</span><span class="p">)</span>
        <span class="n">letter_history_s</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dominant_letter_s</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">dominant_letter_n</span><span class="p">:</span>
            <span class="n">detection_stats_n</span><span class="p">[</span><span class="n">dominant_letter_n</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">if</span> <span class="n">dominant_letter_s</span><span class="p">:</span>
            <span class="n">detection_stats_s</span><span class="p">[</span><span class="n">dominant_letter_s</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
        
        <span class="c1"># Get annotated frames</span>
        <span class="n">annotated_n</span> <span class="o">=</span> <span class="n">results_n</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
        <span class="n">annotated_s</span> <span class="o">=</span> <span class="n">results_s</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
        
        <span class="c1"># Ensure uint8</span>
        <span class="k">if</span> <span class="n">annotated_n</span><span class="o">.</span><span class="n">dtype</span> <span class="o">!=</span> <span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">:</span>
            <span class="n">annotated_n</span> <span class="o">=</span> <span class="p">(</span><span class="n">annotated_n</span> <span class="o">*</span> <span class="mi">255</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">annotated_s</span><span class="o">.</span><span class="n">dtype</span> <span class="o">!=</span> <span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">:</span>
            <span class="n">annotated_s</span> <span class="o">=</span> <span class="p">(</span><span class="n">annotated_s</span> <span class="o">*</span> <span class="mi">255</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
        
        <span class="c1"># Add model labels with BLACK color and bold text (thicker stroke)</span>
        <span class="n">cv2</span><span class="o">.</span><span class="n">putText</span><span class="p">(</span>
            <span class="n">annotated_n</span><span class="p">,</span> <span class="s2">&quot;YOLOv8n&quot;</span><span class="p">,</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">30</span><span class="p">),</span>
            <span class="n">cv2</span><span class="o">.</span><span class="n">FONT_HERSHEY_SIMPLEX</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="mi">3</span><span class="p">)</span>
        <span class="n">cv2</span><span class="o">.</span><span class="n">putText</span><span class="p">(</span>
            <span class="n">annotated_s</span><span class="p">,</span> <span class="s2">&quot;YOLOv8s&quot;</span><span class="p">,</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">30</span><span class="p">),</span>
            <span class="n">cv2</span><span class="o">.</span><span class="n">FONT_HERSHEY_SIMPLEX</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="mi">3</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">dominant_letter_n</span><span class="p">:</span>
            <span class="n">cv2</span><span class="o">.</span><span class="n">putText</span><span class="p">(</span>
                <span class="n">annotated_n</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Letter: </span><span class="si">{</span><span class="n">dominant_letter_n</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">70</span><span class="p">),</span> <span class="n">cv2</span><span class="o">.</span><span class="n">FONT_HERSHEY_SIMPLEX</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">dominant_letter_s</span><span class="p">:</span>
            <span class="n">cv2</span><span class="o">.</span><span class="n">putText</span><span class="p">(</span>
                <span class="n">annotated_s</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Letter: </span><span class="si">{</span><span class="n">dominant_letter_s</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">70</span><span class="p">),</span> <span class="n">cv2</span><span class="o">.</span><span class="n">FONT_HERSHEY_SIMPLEX</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>

        <span class="c1"># Concatenate frames side by side</span>
        <span class="n">combined_frame</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">annotated_n</span><span class="p">,</span> <span class="n">annotated_s</span><span class="p">])</span>
        
        <span class="n">out</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">combined_frame</span><span class="p">)</span>
        <span class="n">frame_count</span> <span class="o">+=</span> <span class="mi">1</span>
        
        <span class="k">if</span> <span class="n">frame_count</span> <span class="o">%</span> <span class="mi">30</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Processed </span><span class="si">{</span><span class="n">frame_count</span><span class="si">}</span><span class="s2"> frames...&quot;</span><span class="p">)</span>
    
    <span class="n">cap</span><span class="o">.</span><span class="n">release</span><span class="p">()</span>
    <span class="n">out</span><span class="o">.</span><span class="n">release</span><span class="p">()</span>
    
    <span class="c1"># Reconstruct sequences</span>
    <span class="n">seq_n</span> <span class="o">=</span> <span class="n">reconstruct_sequence</span><span class="p">(</span><span class="n">letter_history_n</span><span class="p">,</span> <span class="n">stability_threshold</span><span class="p">)</span>
    <span class="n">seq_s</span> <span class="o">=</span> <span class="n">reconstruct_sequence</span><span class="p">(</span><span class="n">letter_history_s</span><span class="p">,</span> <span class="n">stability_threshold</span><span class="p">)</span>
    
    <span class="c1"># Calculate evaluation metrics</span>
    <span class="n">metrics_n</span> <span class="o">=</span> <span class="n">calculate_accuracy_metrics</span><span class="p">(</span><span class="n">seq_n</span><span class="p">,</span> <span class="n">ground_truth</span><span class="p">)</span>
    <span class="n">metrics_s</span> <span class="o">=</span> <span class="n">calculate_accuracy_metrics</span><span class="p">(</span><span class="n">seq_s</span><span class="p">,</span> <span class="n">ground_truth</span><span class="p">)</span>
    
    <span class="c1"># Print results</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="si">{</span><span class="s1">&#39;=&#39;</span><span class="o">*</span><span class="mi">60</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;SIDE-BY-SIDE COMPARISON RESULTS&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="s1">&#39;=&#39;</span><span class="o">*</span><span class="mi">60</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Ground Truth (from video name): &#39;</span><span class="si">{</span><span class="n">ground_truth</span><span class="si">}</span><span class="s2">&#39;&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Output video: </span><span class="si">{</span><span class="n">out_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Total frames: </span><span class="si">{</span><span class="n">frame_count</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">YOLOv8n:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Frames with detections: </span><span class="si">{</span><span class="nb">sum</span><span class="p">(</span><span class="mi">1</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">letter_history_n</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="ow">is</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="kc">None</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Reconstructed sequence: &#39;</span><span class="si">{</span><span class="n">seq_n</span><span class="si">}</span><span class="s2">&#39;&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Sequence length: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">seq_n</span><span class="p">)</span><span class="si">}</span><span class="s2"> letters&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Character Accuracy: </span><span class="si">{</span><span class="n">metrics_n</span><span class="p">[</span><span class="s1">&#39;character_accuracy&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Edit Distance: </span><span class="si">{</span><span class="n">metrics_n</span><span class="p">[</span><span class="s1">&#39;edit_distance&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> operations&quot;</span><span class="p">)</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">YOLOv8s:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Frames with detections: </span><span class="si">{</span><span class="nb">sum</span><span class="p">(</span><span class="mi">1</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">letter_history_s</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="ow">is</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="kc">None</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Reconstructed sequence: &#39;</span><span class="si">{</span><span class="n">seq_s</span><span class="si">}</span><span class="s2">&#39;&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Sequence length: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">seq_s</span><span class="p">)</span><span class="si">}</span><span class="s2"> letters&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Character Accuracy: </span><span class="si">{</span><span class="n">metrics_s</span><span class="p">[</span><span class="s1">&#39;character_accuracy&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Edit Distance: </span><span class="si">{</span><span class="n">metrics_s</span><span class="p">[</span><span class="s1">&#39;edit_distance&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2"> operations&quot;</span><span class="p">)</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Sequences match: </span><span class="si">{</span><span class="n">seq_n</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">seq_s</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">metrics_s</span><span class="p">[</span><span class="s1">&#39;character_accuracy&#39;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">metrics_n</span><span class="p">[</span><span class="s1">&#39;character_accuracy&#39;</span><span class="p">]:</span>
        <span class="n">improvement</span> <span class="o">=</span> <span class="n">metrics_s</span><span class="p">[</span><span class="s1">&#39;character_accuracy&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">metrics_n</span><span class="p">[</span><span class="s1">&#39;character_accuracy&#39;</span><span class="p">]</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;✓ YOLOv8s outperforms YOLOv8n by </span><span class="si">{</span><span class="n">improvement</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2"> percentage points&quot;</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">metrics_n</span><span class="p">[</span><span class="s1">&#39;character_accuracy&#39;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">metrics_s</span><span class="p">[</span><span class="s1">&#39;character_accuracy&#39;</span><span class="p">]:</span>
        <span class="n">difference</span> <span class="o">=</span> <span class="n">metrics_n</span><span class="p">[</span><span class="s1">&#39;character_accuracy&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">metrics_s</span><span class="p">[</span><span class="s1">&#39;character_accuracy&#39;</span><span class="p">]</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;✓ YOLOv8n outperforms YOLOv8s by </span><span class="si">{</span><span class="n">difference</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2"> percentage points&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;= Both models have equal character accuracy&quot;</span><span class="p">)</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">YOLOv8n detection frequency:&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">letter</span><span class="p">,</span> <span class="n">count</span> <span class="ow">in</span> <span class="n">detection_stats_n</span><span class="o">.</span><span class="n">most_common</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">letter</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">count</span><span class="si">}</span><span class="s2"> frames (</span><span class="si">{</span><span class="n">count</span><span class="o">/</span><span class="n">frame_count</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">%)&quot;</span><span class="p">)</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">YOLOv8s detection frequency:&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">letter</span><span class="p">,</span> <span class="n">count</span> <span class="ow">in</span> <span class="n">detection_stats_s</span><span class="o">.</span><span class="n">most_common</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">letter</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">count</span><span class="si">}</span><span class="s2"> frames (</span><span class="si">{</span><span class="n">count</span><span class="o">/</span><span class="n">frame_count</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">%)&quot;</span><span class="p">)</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="s1">&#39;=&#39;</span><span class="o">*</span><span class="mi">60</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">seq_n</span><span class="p">,</span> <span class="n">seq_s</span><span class="p">,</span> <span class="n">detection_stats_n</span><span class="p">,</span> <span class="n">detection_stats_s</span><span class="p">,</span> <span class="n">metrics_n</span><span class="p">,</span> <span class="n">metrics_s</span><span class="p">,</span> <span class="n">ground_truth</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">YOLOGradCAM</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Activation-based visualization for YOLOv8&quot;&quot;&quot;</span>
    
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">target_layer_idx</span><span class="o">=-</span><span class="mi">3</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            model: YOLO model</span>
<span class="sd">            target_layer_idx: Index of layer to visualize (default: -3, a deeper layer)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span><span class="o">.</span><span class="n">device</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activations</span> <span class="o">=</span> <span class="kc">None</span>
        
        <span class="c1"># Get a meaningful layer (one of the detection layers)</span>
        <span class="c1"># YOLOv8 typically has detection layers at indices like 15, 18, 21</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target_layer</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">conv_layers</span> <span class="o">=</span> <span class="p">[]</span>
        
        <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">modules</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">):</span>
                <span class="n">conv_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">module</span><span class="p">)</span>
        
        <span class="c1"># Use a layer towards the end but not the very last</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">conv_layers</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">layer_idx</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">conv_layers</span><span class="p">)</span> <span class="o">+</span> <span class="n">target_layer_idx</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">target_layer</span> <span class="o">=</span> <span class="n">conv_layers</span><span class="p">[</span><span class="n">layer_idx</span><span class="p">]</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using layer at index </span><span class="si">{</span><span class="n">layer_idx</span><span class="si">}</span><span class="s2"> out of </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">conv_layers</span><span class="p">)</span><span class="si">}</span><span class="s2"> conv layers&quot;</span><span class="p">)</span>
        
        <span class="c1"># Register hook</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">target_layer</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">target_layer</span><span class="o">.</span><span class="n">register_forward_hook</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">save_activation</span><span class="p">)</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">save_activation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">module</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">output</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Hook to save activations&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activations</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">preprocess_frame</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">frame</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Preprocess frame for YOLO input&quot;&quot;&quot;</span>
        <span class="c1"># Convert BGR to RGB</span>
        <span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">frame</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">COLOR_BGR2RGB</span><span class="p">)</span>
        
        <span class="c1"># Resize to model input size (640x640 for YOLO)</span>
        <span class="n">img_resized</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="p">(</span><span class="mi">640</span><span class="p">,</span> <span class="mi">640</span><span class="p">))</span>
        
        <span class="c1"># Convert to tensor and normalize</span>
        <span class="n">img_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">img_resized</span><span class="p">)</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span> <span class="o">/</span> <span class="mf">255.0</span>
        <span class="n">img_tensor</span> <span class="o">=</span> <span class="n">img_tensor</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">img_tensor</span>
    
    <span class="k">def</span><span class="w"> </span><span class="nf">generate_heatmap</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">frame</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Generate activation heatmap from raw frame&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        
        <span class="c1"># Preprocess frame</span>
        <span class="n">input_tensor</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preprocess_frame</span><span class="p">(</span><span class="n">frame</span><span class="p">)</span>
        
        <span class="c1"># Forward pass</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Forward pass failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="k">return</span> <span class="kc">None</span>
        
        <span class="c1"># Check if we have activations</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">activations</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;No activations captured&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="kc">None</span>
        
        <span class="c1"># Get activations from first batch</span>
        <span class="n">activations</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activations</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># Shape: [C, H, W]</span>
        
        <span class="c1"># Average across channels to get spatial attention map</span>
        <span class="n">heatmap</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">activations</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        
        <span class="c1"># Apply ReLU and move to CPU</span>
        <span class="n">heatmap</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">heatmap</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        
        <span class="c1"># Normalize to 0-1</span>
        <span class="k">if</span> <span class="n">heatmap</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">&gt;</span> <span class="n">heatmap</span><span class="o">.</span><span class="n">min</span><span class="p">():</span>
            <span class="n">heatmap</span> <span class="o">=</span> <span class="p">(</span><span class="n">heatmap</span> <span class="o">-</span> <span class="n">heatmap</span><span class="o">.</span><span class="n">min</span><span class="p">())</span> <span class="o">/</span> <span class="p">(</span><span class="n">heatmap</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">-</span> <span class="n">heatmap</span><span class="o">.</span><span class="n">min</span><span class="p">())</span>
        
        <span class="k">return</span> <span class="n">heatmap</span>

<span class="k">def</span><span class="w"> </span><span class="nf">apply_heatmap</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">heatmap</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Apply heatmap overlay to image&quot;&quot;&quot;</span>
    <span class="c1"># Resize heatmap to match image size</span>
    <span class="n">heatmap_resized</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="n">heatmap</span><span class="p">,</span> <span class="p">(</span><span class="n">image</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">image</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
    
    <span class="c1"># Convert heatmap to color</span>
    <span class="n">heatmap_colored</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">applyColorMap</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">(</span><span class="mi">255</span> <span class="o">*</span> <span class="n">heatmap_resized</span><span class="p">),</span> <span class="n">cv2</span><span class="o">.</span><span class="n">COLORMAP_JET</span><span class="p">)</span>
    
    <span class="c1"># Overlay</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">addWeighted</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">heatmap_colored</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">output</span>

<span class="k">def</span><span class="w"> </span><span class="nf">simple_attention_visualization</span><span class="p">(</span><span class="n">frame</span><span class="p">,</span> <span class="n">results</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Simpler approach: Visualize detection confidence as attention.</span>
<span class="sd">    This doesn&#39;t require gradients but shows where the model is confident.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Create blank heatmap</span>
    <span class="n">heatmap</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">frame</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">frame</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    
    <span class="c1"># Get detections</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">results</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">boxes</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">boxes</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">boxes</span><span class="o">.</span><span class="n">xyxy</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="n">confs</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">boxes</span><span class="o">.</span><span class="n">conf</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        
        <span class="c1"># Draw Gaussian-like attention around each detection</span>
        <span class="k">for</span> <span class="n">box</span><span class="p">,</span> <span class="n">conf</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">boxes</span><span class="p">,</span> <span class="n">confs</span><span class="p">):</span>
            <span class="n">x1</span><span class="p">,</span> <span class="n">y1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">y2</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">box</span><span class="p">)</span>
            <span class="n">center_x</span> <span class="o">=</span> <span class="p">(</span><span class="n">x1</span> <span class="o">+</span> <span class="n">x2</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span>
            <span class="n">center_y</span> <span class="o">=</span> <span class="p">(</span><span class="n">y1</span> <span class="o">+</span> <span class="n">y2</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span>
            <span class="n">width</span> <span class="o">=</span> <span class="n">x2</span> <span class="o">-</span> <span class="n">x1</span>
            <span class="n">height</span> <span class="o">=</span> <span class="n">y2</span> <span class="o">-</span> <span class="n">y1</span>
            
            <span class="c1"># Create Gaussian-like mask</span>
            <span class="n">Y</span><span class="p">,</span> <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ogrid</span><span class="p">[:</span><span class="n">frame</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">:</span><span class="n">frame</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>
            <span class="n">dist</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">((</span><span class="n">X</span> <span class="o">-</span> <span class="n">center_x</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="p">(</span><span class="n">Y</span> <span class="o">-</span> <span class="n">center_y</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
            <span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">dist</span> <span class="o">/</span> <span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">width</span><span class="p">,</span> <span class="n">height</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">))</span>
            
            <span class="c1"># Add weighted by confidence</span>
            <span class="n">heatmap</span> <span class="o">+=</span> <span class="n">mask</span> <span class="o">*</span> <span class="n">conf</span>
    
    <span class="c1"># Normalize</span>
    <span class="k">if</span> <span class="n">heatmap</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">heatmap</span> <span class="o">=</span> <span class="n">heatmap</span> <span class="o">/</span> <span class="n">heatmap</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
    
    <span class="c1"># Apply colormap</span>
    <span class="n">heatmap_colored</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">applyColorMap</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">(</span><span class="mi">255</span> <span class="o">*</span> <span class="n">heatmap</span><span class="p">),</span> <span class="n">cv2</span><span class="o">.</span><span class="n">COLORMAP_JET</span><span class="p">)</span>
    
    <span class="c1"># Overlay</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">addWeighted</span><span class="p">(</span><span class="n">frame</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">heatmap_colored</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">output</span>

<span class="k">def</span><span class="w"> </span><span class="nf">create_gradcam_video</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">video_path</span><span class="p">,</span> <span class="n">output_dir</span><span class="p">,</span> <span class="n">vid_name</span><span class="p">,</span> <span class="n">use_simple</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Create video with Grad-CAM or attention visualization&quot;&quot;&quot;</span>
    <span class="n">cap</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">VideoCapture</span><span class="p">(</span><span class="n">video_path</span><span class="p">)</span>
    
    <span class="n">rotation</span> <span class="o">=</span> <span class="n">get_video_rotation</span><span class="p">(</span><span class="n">video_path</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Video rotation metadata: </span><span class="si">{</span><span class="n">rotation</span><span class="si">}</span><span class="s2"> degrees&quot;</span><span class="p">)</span>
    
    <span class="n">width</span>  <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">cap</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">cv2</span><span class="o">.</span><span class="n">CAP_PROP_FRAME_WIDTH</span><span class="p">))</span>
    <span class="n">height</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">cap</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">cv2</span><span class="o">.</span><span class="n">CAP_PROP_FRAME_HEIGHT</span><span class="p">))</span>
    <span class="n">fps</span>    <span class="o">=</span> <span class="n">cap</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">cv2</span><span class="o">.</span><span class="n">CAP_PROP_FPS</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">rotation</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">90</span><span class="p">,</span> <span class="mi">270</span><span class="p">]:</span>
        <span class="n">width</span><span class="p">,</span> <span class="n">height</span> <span class="o">=</span> <span class="n">height</span><span class="p">,</span> <span class="n">width</span>
    
    <span class="n">out_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">output_dir</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">vid_name</span><span class="si">}</span><span class="s2">_gradcam.mp4&quot;</span><span class="p">)</span>
    <span class="n">fourcc</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">VideoWriter_fourcc</span><span class="p">(</span><span class="o">*</span><span class="s1">&#39;mp4v&#39;</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">VideoWriter</span><span class="p">(</span><span class="n">out_path</span><span class="p">,</span> <span class="n">fourcc</span><span class="p">,</span> <span class="n">fps</span><span class="p">,</span> <span class="p">(</span><span class="n">width</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">height</span><span class="p">))</span>
    
    <span class="n">frame_count</span> <span class="o">=</span> <span class="mi">0</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Creating </span><span class="si">{</span><span class="s1">&#39;attention&#39;</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">use_simple</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="s1">&#39;Grad-CAM&#39;</span><span class="si">}</span><span class="s2"> visualization...&quot;</span><span class="p">)</span>
    
    <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
        <span class="n">ret</span><span class="p">,</span> <span class="n">frame</span> <span class="o">=</span> <span class="n">cap</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">ret</span><span class="p">:</span>
            <span class="k">break</span>
        
        <span class="n">frame</span> <span class="o">=</span> <span class="n">rotate_frame</span><span class="p">(</span><span class="n">frame</span><span class="p">,</span> <span class="n">rotation</span><span class="p">)</span>
        
        <span class="c1"># Run inference</span>
        <span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">frame</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        
        <span class="c1"># Get annotated frame</span>
        <span class="n">annotated</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
        
        <span class="c1"># Create attention/heatmap visualization</span>
        <span class="k">if</span> <span class="n">use_simple</span><span class="p">:</span>
            <span class="n">heatmap_vis</span> <span class="o">=</span> <span class="n">simple_attention_visualization</span><span class="p">(</span><span class="n">frame</span><span class="p">,</span> <span class="n">results</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Activation-based visualization (no gradients needed)</span>
            <span class="n">gradcam</span> <span class="o">=</span> <span class="n">YOLOGradCAM</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
            <span class="n">heatmap</span> <span class="o">=</span> <span class="n">gradcam</span><span class="o">.</span><span class="n">generate_heatmap</span><span class="p">(</span><span class="n">frame</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">heatmap</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">heatmap_vis</span> <span class="o">=</span> <span class="n">apply_heatmap</span><span class="p">(</span><span class="n">frame</span><span class="p">,</span> <span class="n">heatmap</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">heatmap_vis</span> <span class="o">=</span> <span class="n">frame</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
                <span class="n">cv2</span><span class="o">.</span><span class="n">putText</span><span class="p">(</span><span class="n">heatmap_vis</span><span class="p">,</span> <span class="s2">&quot;Heatmap unavailable&quot;</span><span class="p">,</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">60</span><span class="p">),</span> 
                           <span class="n">cv2</span><span class="o">.</span><span class="n">FONT_HERSHEY_SIMPLEX</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>
        
        <span class="c1"># Add labels</span>
        <span class="n">cv2</span><span class="o">.</span><span class="n">putText</span><span class="p">(</span><span class="n">annotated</span><span class="p">,</span> <span class="s2">&quot;Detection&quot;</span><span class="p">,</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">30</span><span class="p">),</span> 
                   <span class="n">cv2</span><span class="o">.</span><span class="n">FONT_HERSHEY_SIMPLEX</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">cv2</span><span class="o">.</span><span class="n">putText</span><span class="p">(</span><span class="n">heatmap_vis</span><span class="p">,</span> <span class="s2">&quot;Attention Map&quot;</span><span class="p">,</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">30</span><span class="p">),</span> 
                   <span class="n">cv2</span><span class="o">.</span><span class="n">FONT_HERSHEY_SIMPLEX</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="mi">255</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>
        
        <span class="c1"># Ensure uint8</span>
        <span class="k">if</span> <span class="n">annotated</span><span class="o">.</span><span class="n">dtype</span> <span class="o">!=</span> <span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">:</span>
            <span class="n">annotated</span> <span class="o">=</span> <span class="p">(</span><span class="n">annotated</span> <span class="o">*</span> <span class="mi">255</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">heatmap_vis</span><span class="o">.</span><span class="n">dtype</span> <span class="o">!=</span> <span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">:</span>
            <span class="n">heatmap_vis</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">heatmap_vis</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
        
        <span class="c1"># Combine side by side</span>
        <span class="n">combined</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">annotated</span><span class="p">,</span> <span class="n">heatmap_vis</span><span class="p">])</span>
        
        <span class="n">out</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">combined</span><span class="p">)</span>
        <span class="n">frame_count</span> <span class="o">+=</span> <span class="mi">1</span>
        
        <span class="k">if</span> <span class="n">frame_count</span> <span class="o">%</span> <span class="mi">30</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Processed </span><span class="si">{</span><span class="n">frame_count</span><span class="si">}</span><span class="s2"> frames...&quot;</span><span class="p">)</span>
    
    <span class="n">cap</span><span class="o">.</span><span class="n">release</span><span class="p">()</span>
    <span class="n">out</span><span class="o">.</span><span class="n">release</span><span class="p">()</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Grad-CAM visualization saved to: </span><span class="si">{</span><span class="n">out_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Total frames: </span><span class="si">{</span><span class="n">frame_count</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="testing">
<h2>Testing<a class="headerlink" href="#testing" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">output_dir</span> <span class="o">=</span> <span class="s2">&quot;video_results&quot;</span>
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">output_dir</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># YOLOv8 weights</span>
<span class="n">weights_s</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">&quot;runs/detect/yolo_model/weights/best.pt&quot;</span>
<span class="n">weights_n</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">&quot;runs/detect/yolo8n_baseline/weights/best.pt&quot;</span>

<span class="c1"># Load models</span>
<span class="n">model_s</span> <span class="o">=</span> <span class="n">YOLO</span><span class="p">(</span><span class="n">weights_s</span><span class="p">)</span>
<span class="n">model_n</span> <span class="o">=</span> <span class="n">YOLO</span><span class="p">(</span><span class="n">weights_n</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<section id="dog">
<h3>Dog<a class="headerlink" href="#dog" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># --- Paths ---</span>
<span class="n">video_path</span> <span class="o">=</span> <span class="s2">&quot;videos/Dog.mp4&quot;</span>
<span class="n">vid_name</span> <span class="o">=</span> <span class="s2">&quot;Dog&quot;</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create side-by-side comparison</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Creating side-by-side comparison video...&quot;</span><span class="p">)</span>
<span class="n">seq_n</span><span class="p">,</span> <span class="n">seq_s</span><span class="p">,</span> <span class="n">stats_n</span><span class="p">,</span> <span class="n">stats_s</span><span class="p">,</span> <span class="n">metrics_n</span><span class="p">,</span> <span class="n">metrics_s</span><span class="p">,</span> <span class="n">ground_truth</span> <span class="o">=</span> <span class="n">create_side_by_side_comparison</span><span class="p">(</span>
    <span class="n">model_n</span><span class="p">,</span> <span class="n">model_s</span><span class="p">,</span> <span class="n">video_path</span><span class="p">,</span> <span class="n">output_dir</span><span class="p">,</span> <span class="n">vid_name</span><span class="p">,</span>
    <span class="n">conf_threshold</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">stability_threshold</span><span class="o">=</span><span class="mi">5</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Creating side-by-side comparison video...
Video rotation metadata: 0.0 degrees
Processing frames for side-by-side comparison...

0: 384x640 (no detections), 115.0ms
Speed: 11.6ms preprocess, 115.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 216.5ms
Speed: 3.2ms preprocess, 216.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 114.1ms
Speed: 4.0ms preprocess, 114.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 D, 283.8ms
Speed: 3.9ms preprocess, 283.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 114.9ms
Speed: 3.6ms preprocess, 114.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 D, 241.9ms
Speed: 4.2ms preprocess, 241.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 120.2ms
Speed: 3.5ms preprocess, 120.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 D, 307.5ms
Speed: 3.8ms preprocess, 307.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 138.6ms
Speed: 3.7ms preprocess, 138.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 D, 299.4ms
Speed: 4.1ms preprocess, 299.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 144.6ms
Speed: 4.4ms preprocess, 144.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 D, 216.1ms
Speed: 5.0ms preprocess, 216.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 115.8ms
Speed: 4.8ms preprocess, 115.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 D, 274.0ms
Speed: 3.8ms preprocess, 274.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 D, 112.3ms
Speed: 4.1ms preprocess, 112.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 D, 244.3ms
Speed: 3.5ms preprocess, 244.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 D, 124.2ms
Speed: 4.7ms preprocess, 124.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 D, 204.9ms
Speed: 3.6ms preprocess, 204.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 D, 89.6ms
Speed: 4.6ms preprocess, 89.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 D, 212.6ms
Speed: 3.3ms preprocess, 212.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 D, 99.4ms
Speed: 3.5ms preprocess, 99.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 D, 217.3ms
Speed: 3.8ms preprocess, 217.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 D, 92.0ms
Speed: 3.4ms preprocess, 92.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 D, 214.3ms
Speed: 3.1ms preprocess, 214.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 101.3ms
Speed: 3.8ms preprocess, 101.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 D, 234.6ms
Speed: 3.5ms preprocess, 234.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 93.0ms
Speed: 3.9ms preprocess, 93.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 D, 216.1ms
Speed: 3.3ms preprocess, 216.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 138.3ms
Speed: 4.3ms preprocess, 138.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 D, 222.0ms
Speed: 4.3ms preprocess, 222.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 91.0ms
Speed: 4.1ms preprocess, 91.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 D, 221.2ms
Speed: 3.0ms preprocess, 221.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 107.1ms
Speed: 3.8ms preprocess, 107.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 D, 233.5ms
Speed: 3.1ms preprocess, 233.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 107.4ms
Speed: 3.6ms preprocess, 107.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 D, 251.2ms
Speed: 3.5ms preprocess, 251.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 96.2ms
Speed: 3.7ms preprocess, 96.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 D, 219.0ms
Speed: 3.4ms preprocess, 219.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 93.2ms
Speed: 3.7ms preprocess, 93.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 D, 220.7ms
Speed: 3.3ms preprocess, 220.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 93.2ms
Speed: 3.1ms preprocess, 93.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 D, 214.3ms
Speed: 4.4ms preprocess, 214.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 91.9ms
Speed: 3.9ms preprocess, 91.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 D, 215.3ms
Speed: 3.4ms preprocess, 215.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 98.3ms
Speed: 3.1ms preprocess, 98.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 D, 225.2ms
Speed: 3.3ms preprocess, 225.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 96.0ms
Speed: 4.3ms preprocess, 96.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 D, 222.6ms
Speed: 3.5ms preprocess, 222.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 137.9ms
Speed: 3.7ms preprocess, 137.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 D, 252.1ms
Speed: 3.7ms preprocess, 252.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 D, 115.5ms
Speed: 3.8ms preprocess, 115.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 D, 210.3ms
Speed: 3.7ms preprocess, 210.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 97.7ms
Speed: 3.9ms preprocess, 97.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 D, 230.4ms
Speed: 3.1ms preprocess, 230.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 99.0ms
Speed: 5.2ms preprocess, 99.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 D, 224.7ms
Speed: 3.5ms preprocess, 224.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 99.2ms
Speed: 3.7ms preprocess, 99.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 D, 225.2ms
Speed: 4.3ms preprocess, 225.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 99.2ms
Speed: 3.5ms preprocess, 99.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 236.8ms
Speed: 3.6ms preprocess, 236.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)
Processed 30 frames...

0: 384x640 (no detections), 110.4ms
Speed: 3.7ms preprocess, 110.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 D, 261.0ms
Speed: 3.9ms preprocess, 261.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 D, 144.2ms
Speed: 4.8ms preprocess, 144.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 269.5ms
Speed: 3.8ms preprocess, 269.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 D, 106.0ms
Speed: 3.8ms preprocess, 106.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 261.6ms
Speed: 3.6ms preprocess, 261.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 D, 127.8ms
Speed: 4.2ms preprocess, 127.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 250.0ms
Speed: 4.1ms preprocess, 250.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 117.5ms
Speed: 4.6ms preprocess, 117.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 248.7ms
Speed: 3.2ms preprocess, 248.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 129.0ms
Speed: 4.2ms preprocess, 129.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 248.9ms
Speed: 3.5ms preprocess, 248.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 104.3ms
Speed: 3.3ms preprocess, 104.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 240.6ms
Speed: 3.7ms preprocess, 240.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 90.7ms
Speed: 3.8ms preprocess, 90.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 206.3ms
Speed: 3.2ms preprocess, 206.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 136.0ms
Speed: 4.2ms preprocess, 136.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 D, 294.7ms
Speed: 3.5ms preprocess, 294.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 97.5ms
Speed: 2.9ms preprocess, 97.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 266.6ms
Speed: 4.7ms preprocess, 266.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 96.6ms
Speed: 4.1ms preprocess, 96.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 245.9ms
Speed: 3.9ms preprocess, 245.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 96.4ms
Speed: 3.8ms preprocess, 96.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 D, 222.5ms
Speed: 3.5ms preprocess, 222.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 D, 97.5ms
Speed: 3.8ms preprocess, 97.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 234.8ms
Speed: 3.1ms preprocess, 234.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 113.8ms
Speed: 3.6ms preprocess, 113.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 236.9ms
Speed: 3.1ms preprocess, 236.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 209.5ms
Speed: 4.5ms preprocess, 209.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 X, 224.3ms
Speed: 3.0ms preprocess, 224.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 149.5ms
Speed: 3.8ms preprocess, 149.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 285.5ms
Speed: 3.4ms preprocess, 285.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 191.6ms
Speed: 4.8ms preprocess, 191.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 407.3ms
Speed: 4.4ms preprocess, 407.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 125.8ms
Speed: 3.5ms preprocess, 125.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 373.5ms
Speed: 6.7ms preprocess, 373.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 118.3ms
Speed: 4.1ms preprocess, 118.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 275.1ms
Speed: 3.7ms preprocess, 275.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 244.1ms
Speed: 3.8ms preprocess, 244.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 254.6ms
Speed: 5.3ms preprocess, 254.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 103.9ms
Speed: 3.9ms preprocess, 103.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 255.6ms
Speed: 3.3ms preprocess, 255.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 124.5ms
Speed: 4.9ms preprocess, 124.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 257.7ms
Speed: 3.7ms preprocess, 257.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 236.1ms
Speed: 5.7ms preprocess, 236.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 327.4ms
Speed: 4.8ms preprocess, 327.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 123.3ms
Speed: 4.2ms preprocess, 123.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 248.1ms
Speed: 3.8ms preprocess, 248.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 357.4ms
Speed: 3.8ms preprocess, 357.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 336.6ms
Speed: 6.4ms preprocess, 336.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 176.7ms
Speed: 4.7ms preprocess, 176.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 317.0ms
Speed: 3.8ms preprocess, 317.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 149.3ms
Speed: 3.8ms preprocess, 149.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 320.4ms
Speed: 3.6ms preprocess, 320.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 110.2ms
Speed: 3.6ms preprocess, 110.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 338.8ms
Speed: 3.5ms preprocess, 338.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 158.5ms
Speed: 4.5ms preprocess, 158.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 261.5ms
Speed: 5.1ms preprocess, 261.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 117.7ms
Speed: 4.2ms preprocess, 117.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 257.7ms
Speed: 3.3ms preprocess, 257.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)
Processed 60 frames...

0: 384x640 1 O, 109.3ms
Speed: 4.9ms preprocess, 109.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 278.1ms
Speed: 3.3ms preprocess, 278.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 98.6ms
Speed: 3.8ms preprocess, 98.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 230.9ms
Speed: 3.3ms preprocess, 230.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 100.7ms
Speed: 3.4ms preprocess, 100.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 228.8ms
Speed: 3.1ms preprocess, 228.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 102.2ms
Speed: 4.5ms preprocess, 102.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 228.9ms
Speed: 3.7ms preprocess, 228.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 115.5ms
Speed: 3.3ms preprocess, 115.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 259.1ms
Speed: 3.8ms preprocess, 259.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 105.6ms
Speed: 5.5ms preprocess, 105.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 259.9ms
Speed: 3.4ms preprocess, 259.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 107.4ms
Speed: 3.5ms preprocess, 107.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 250.7ms
Speed: 3.4ms preprocess, 250.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 106.8ms
Speed: 3.3ms preprocess, 106.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 245.0ms
Speed: 3.3ms preprocess, 245.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 145.1ms
Speed: 3.9ms preprocess, 145.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 283.1ms
Speed: 3.6ms preprocess, 283.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 100.2ms
Speed: 3.4ms preprocess, 100.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 236.7ms
Speed: 3.7ms preprocess, 236.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 101.1ms
Speed: 3.9ms preprocess, 101.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 240.5ms
Speed: 3.2ms preprocess, 240.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 99.0ms
Speed: 3.7ms preprocess, 99.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 231.4ms
Speed: 3.1ms preprocess, 231.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 104.6ms
Speed: 3.6ms preprocess, 104.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 227.6ms
Speed: 4.5ms preprocess, 227.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 98.6ms
Speed: 4.0ms preprocess, 98.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 217.6ms
Speed: 3.1ms preprocess, 217.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 107.9ms
Speed: 3.0ms preprocess, 107.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 230.1ms
Speed: 3.1ms preprocess, 230.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 99.3ms
Speed: 3.7ms preprocess, 99.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 219.5ms
Speed: 3.1ms preprocess, 219.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 101.6ms
Speed: 3.8ms preprocess, 101.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 237.8ms
Speed: 3.4ms preprocess, 237.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 103.4ms
Speed: 4.5ms preprocess, 103.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 223.3ms
Speed: 3.3ms preprocess, 223.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 100.2ms
Speed: 3.3ms preprocess, 100.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 221.9ms
Speed: 3.5ms preprocess, 221.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 99.8ms
Speed: 4.1ms preprocess, 99.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 227.9ms
Speed: 3.3ms preprocess, 227.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 97.7ms
Speed: 3.2ms preprocess, 97.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 225.0ms
Speed: 3.1ms preprocess, 225.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 103.6ms
Speed: 5.1ms preprocess, 103.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 235.9ms
Speed: 3.0ms preprocess, 235.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 98.8ms
Speed: 3.3ms preprocess, 98.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 223.0ms
Speed: 3.6ms preprocess, 223.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 101.7ms
Speed: 3.8ms preprocess, 101.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 237.6ms
Speed: 3.2ms preprocess, 237.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 106.2ms
Speed: 3.2ms preprocess, 106.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 231.7ms
Speed: 3.1ms preprocess, 231.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 106.9ms
Speed: 3.2ms preprocess, 106.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 220.7ms
Speed: 3.1ms preprocess, 220.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 99.6ms
Speed: 4.1ms preprocess, 99.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 238.0ms
Speed: 3.0ms preprocess, 238.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 114.8ms
Speed: 4.3ms preprocess, 114.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 256.3ms
Speed: 3.4ms preprocess, 256.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 105.0ms
Speed: 3.2ms preprocess, 105.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 225.2ms
Speed: 3.3ms preprocess, 225.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 98.8ms
Speed: 3.1ms preprocess, 98.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 230.0ms
Speed: 3.1ms preprocess, 230.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)
Processed 90 frames...

0: 384x640 1 O, 102.2ms
Speed: 4.9ms preprocess, 102.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 235.7ms
Speed: 3.5ms preprocess, 235.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 104.5ms
Speed: 3.5ms preprocess, 104.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 233.4ms
Speed: 3.2ms preprocess, 233.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 99.7ms
Speed: 3.2ms preprocess, 99.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 234.5ms
Speed: 3.2ms preprocess, 234.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 101.9ms
Speed: 3.6ms preprocess, 101.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 J, 232.0ms
Speed: 3.6ms preprocess, 232.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 102.5ms
Speed: 3.7ms preprocess, 102.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 238.0ms
Speed: 3.4ms preprocess, 238.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 102.3ms
Speed: 3.3ms preprocess, 102.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 C, 234.8ms
Speed: 3.5ms preprocess, 234.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 101.5ms
Speed: 3.4ms preprocess, 101.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 232.9ms
Speed: 3.4ms preprocess, 232.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 92.7ms
Speed: 4.0ms preprocess, 92.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 215.5ms
Speed: 3.2ms preprocess, 215.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 105.1ms
Speed: 3.8ms preprocess, 105.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 379.2ms
Speed: 4.0ms preprocess, 379.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 106.5ms
Speed: 3.9ms preprocess, 106.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 231.9ms
Speed: 3.4ms preprocess, 231.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 102.5ms
Speed: 3.7ms preprocess, 102.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 234.8ms
Speed: 4.1ms preprocess, 234.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 105.8ms
Speed: 4.4ms preprocess, 105.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 254.7ms
Speed: 3.5ms preprocess, 254.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 105.0ms
Speed: 3.4ms preprocess, 105.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 240.4ms
Speed: 3.3ms preprocess, 240.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 101.9ms
Speed: 4.7ms preprocess, 101.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 230.6ms
Speed: 3.4ms preprocess, 230.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 109.0ms
Speed: 4.3ms preprocess, 109.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 229.3ms
Speed: 3.9ms preprocess, 229.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 117.0ms
Speed: 3.3ms preprocess, 117.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 257.9ms
Speed: 2.9ms preprocess, 257.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 101.8ms
Speed: 3.5ms preprocess, 101.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 234.3ms
Speed: 3.1ms preprocess, 234.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 99.0ms
Speed: 3.4ms preprocess, 99.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 225.7ms
Speed: 3.3ms preprocess, 225.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 104.5ms
Speed: 3.0ms preprocess, 104.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 234.1ms
Speed: 3.3ms preprocess, 234.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 102.8ms
Speed: 3.4ms preprocess, 102.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 228.1ms
Speed: 3.2ms preprocess, 228.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 103.2ms
Speed: 3.5ms preprocess, 103.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 232.3ms
Speed: 3.4ms preprocess, 232.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 102.2ms
Speed: 3.1ms preprocess, 102.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 233.3ms
Speed: 3.7ms preprocess, 233.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 97.2ms
Speed: 3.4ms preprocess, 97.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 406.2ms
Speed: 3.6ms preprocess, 406.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 107.5ms
Speed: 3.4ms preprocess, 107.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 234.1ms
Speed: 2.8ms preprocess, 234.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 95.3ms
Speed: 3.7ms preprocess, 95.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 230.6ms
Speed: 3.1ms preprocess, 230.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 99.8ms
Speed: 3.2ms preprocess, 99.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 234.8ms
Speed: 3.2ms preprocess, 234.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 98.2ms
Speed: 3.3ms preprocess, 98.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 236.6ms
Speed: 3.1ms preprocess, 236.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 100.4ms
Speed: 4.1ms preprocess, 100.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 233.5ms
Speed: 3.5ms preprocess, 233.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 92.5ms
Speed: 3.1ms preprocess, 92.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 223.5ms
Speed: 3.4ms preprocess, 223.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 97.8ms
Speed: 3.9ms preprocess, 97.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 252.2ms
Speed: 4.0ms preprocess, 252.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)
Processed 120 frames...

0: 384x640 1 G, 109.6ms
Speed: 3.4ms preprocess, 109.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 236.6ms
Speed: 3.8ms preprocess, 236.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 108.5ms
Speed: 3.8ms preprocess, 108.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 244.2ms
Speed: 3.4ms preprocess, 244.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 114.2ms
Speed: 3.7ms preprocess, 114.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 256.6ms
Speed: 3.4ms preprocess, 256.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 140.2ms
Speed: 4.4ms preprocess, 140.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 282.0ms
Speed: 3.8ms preprocess, 282.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 120.7ms
Speed: 2.6ms preprocess, 120.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 381.6ms
Speed: 2.9ms preprocess, 381.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 103.4ms
Speed: 4.0ms preprocess, 103.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 231.2ms
Speed: 3.3ms preprocess, 231.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 97.8ms
Speed: 3.4ms preprocess, 97.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 223.5ms
Speed: 4.2ms preprocess, 223.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 99.4ms
Speed: 3.5ms preprocess, 99.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 231.7ms
Speed: 4.0ms preprocess, 231.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 103.2ms
Speed: 3.5ms preprocess, 103.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 236.1ms
Speed: 3.5ms preprocess, 236.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 116.0ms
Speed: 3.6ms preprocess, 116.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 232.6ms
Speed: 3.2ms preprocess, 232.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 99.2ms
Speed: 3.2ms preprocess, 99.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 227.2ms
Speed: 2.9ms preprocess, 227.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 100.3ms
Speed: 3.4ms preprocess, 100.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 229.9ms
Speed: 3.3ms preprocess, 229.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 99.8ms
Speed: 3.1ms preprocess, 99.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 228.3ms
Speed: 3.3ms preprocess, 228.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 98.7ms
Speed: 3.9ms preprocess, 98.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 223.7ms
Speed: 3.3ms preprocess, 223.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 102.8ms
Speed: 3.4ms preprocess, 102.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 232.6ms
Speed: 3.1ms preprocess, 232.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 256.5ms
Speed: 3.8ms preprocess, 256.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 222.6ms
Speed: 4.0ms preprocess, 222.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 100.9ms
Speed: 3.7ms preprocess, 100.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 221.3ms
Speed: 3.3ms preprocess, 221.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 101.1ms
Speed: 3.2ms preprocess, 101.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 233.9ms
Speed: 3.1ms preprocess, 233.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 96.2ms
Speed: 3.5ms preprocess, 96.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 231.2ms
Speed: 4.4ms preprocess, 231.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 101.7ms
Speed: 3.6ms preprocess, 101.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 250.4ms
Speed: 3.2ms preprocess, 250.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 98.8ms
Speed: 3.6ms preprocess, 98.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 236.5ms
Speed: 3.4ms preprocess, 236.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 96.3ms
Speed: 3.3ms preprocess, 96.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 231.9ms
Speed: 3.8ms preprocess, 231.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 111.9ms
Speed: 3.1ms preprocess, 111.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 252.2ms
Speed: 3.2ms preprocess, 252.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 100.2ms
Speed: 2.9ms preprocess, 100.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 232.3ms
Speed: 3.5ms preprocess, 232.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 102.2ms
Speed: 3.5ms preprocess, 102.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 233.3ms
Speed: 3.8ms preprocess, 233.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 98.6ms
Speed: 3.5ms preprocess, 98.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 374.0ms
Speed: 3.7ms preprocess, 374.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 102.4ms
Speed: 3.1ms preprocess, 102.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 231.3ms
Speed: 3.9ms preprocess, 231.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 100.2ms
Speed: 3.5ms preprocess, 100.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 231.0ms
Speed: 3.2ms preprocess, 231.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 97.7ms
Speed: 3.2ms preprocess, 97.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 224.5ms
Speed: 3.9ms preprocess, 224.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 97.8ms
Speed: 2.9ms preprocess, 97.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 233.0ms
Speed: 3.3ms preprocess, 233.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)
Processed 150 frames...

0: 384x640 1 G, 94.8ms
Speed: 2.7ms preprocess, 94.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 227.1ms
Speed: 3.8ms preprocess, 227.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 98.4ms
Speed: 3.2ms preprocess, 98.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 230.8ms
Speed: 3.3ms preprocess, 230.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 104.9ms
Speed: 3.3ms preprocess, 104.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 231.9ms
Speed: 3.5ms preprocess, 231.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 102.0ms
Speed: 3.6ms preprocess, 102.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 233.0ms
Speed: 3.6ms preprocess, 233.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 99.5ms
Speed: 3.0ms preprocess, 99.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 231.2ms
Speed: 3.1ms preprocess, 231.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 101.0ms
Speed: 4.6ms preprocess, 101.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 391.7ms
Speed: 3.6ms preprocess, 391.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 97.5ms
Speed: 3.2ms preprocess, 97.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 231.5ms
Speed: 3.5ms preprocess, 231.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 94.7ms
Speed: 3.1ms preprocess, 94.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 221.5ms
Speed: 3.3ms preprocess, 221.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 113.2ms
Speed: 3.2ms preprocess, 113.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 G, 225.5ms
Speed: 3.1ms preprocess, 225.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

============================================================
SIDE-BY-SIDE COMPARISON RESULTS
============================================================
Ground Truth (from video name): &#39;DOG&#39;
Output video: video_results\Dog_comparison.mp4
Total frames: 159

YOLOv8n:
  Frames with detections: 116
  Reconstructed sequence: &#39;DOGG&#39;
  Sequence length: 4 letters
  Character Accuracy: 75.0%
  Edit Distance: 1 operations

YOLOv8s:
  Frames with detections: 143
  Reconstructed sequence: &#39;DOG&#39;
  Sequence length: 3 letters
  Character Accuracy: 100.0%
  Edit Distance: 0 operations

Sequences match: False
✓ YOLOv8s outperforms YOLOv8n by 25.0 percentage points

YOLOv8n detection frequency:
  G: 58 frames (36.5%)
  O: 48 frames (30.2%)
  D: 10 frames (6.3%)

YOLOv8s detection frequency:
  G: 61 frames (38.4%)
  O: 48 frames (30.2%)
  D: 31 frames (19.5%)
  X: 1 frames (0.6%)
  J: 1 frames (0.6%)
============================================================
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Detailed evaluation report</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="s2">&quot;=&quot;</span><span class="o">*</span><span class="mi">60</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;DETAILED EVALUATION REPORT&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span><span class="o">*</span><span class="mi">60</span><span class="p">)</span>

<span class="n">evaluate_prediction</span><span class="p">(</span><span class="n">seq_n</span><span class="p">,</span> <span class="n">ground_truth</span><span class="p">,</span> <span class="s2">&quot;YOLOv8n&quot;</span><span class="p">)</span>
<span class="n">evaluate_prediction</span><span class="p">(</span><span class="n">seq_s</span><span class="p">,</span> <span class="n">ground_truth</span><span class="p">,</span> <span class="s2">&quot;YOLOv8s&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>============================================================
DETAILED EVALUATION REPORT
============================================================

============================================================
YOLOv8n EVALUATION
============================================================
Ground Truth:  &#39;DOG&#39;
Predicted:     &#39;DOGG&#39;

Metrics:
  Exact Match:           ✗ NO
  Edit Distance:         1 operations
  Character Accuracy:    75.0%
  Character Error Rate:  33.3%
  Word Error Rate:       33.3%
  Subsequence Accuracy:  100.0%
============================================================

============================================================
YOLOv8s EVALUATION
============================================================
Ground Truth:  &#39;DOG&#39;
Predicted:     &#39;DOG&#39;

Metrics:
  Exact Match:           ✓ YES
  Edit Distance:         0 operations
  Character Accuracy:    100.0%
  Character Error Rate:  0.0%
  Word Error Rate:       0.0%
  Subsequence Accuracy:  100.0%
============================================================
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;exact_match&#39;: True,
 &#39;edit_distance&#39;: 0,
 &#39;character_accuracy&#39;: 100.0,
 &#39;wer&#39;: 0.0,
 &#39;cer&#39;: 0.0,
 &#39;subsequence_accuracy&#39;: 100.0}
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Final comparison summary</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="si">{</span><span class="s1">&#39;=&#39;</span><span class="o">*</span><span class="mi">60</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;FINAL MODEL COMPARISON&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="s1">&#39;=&#39;</span><span class="o">*</span><span class="mi">60</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Ground Truth: &#39;</span><span class="si">{</span><span class="n">ground_truth</span><span class="si">}</span><span class="s2">&#39;&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">YOLOv8n: &#39;</span><span class="si">{</span><span class="n">seq_n</span><span class="si">}</span><span class="s2">&#39; - Character Accuracy: </span><span class="si">{</span><span class="n">metrics_n</span><span class="p">[</span><span class="s1">&#39;character_accuracy&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;YOLOv8s: &#39;</span><span class="si">{</span><span class="n">seq_s</span><span class="si">}</span><span class="s2">&#39; - Character Accuracy: </span><span class="si">{</span><span class="n">metrics_s</span><span class="p">[</span><span class="s1">&#39;character_accuracy&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>

<span class="k">if</span> <span class="n">metrics_s</span><span class="p">[</span><span class="s1">&#39;character_accuracy&#39;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">metrics_n</span><span class="p">[</span><span class="s1">&#39;character_accuracy&#39;</span><span class="p">]:</span>
    <span class="n">improvement</span> <span class="o">=</span> <span class="n">metrics_s</span><span class="p">[</span><span class="s1">&#39;character_accuracy&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">metrics_n</span><span class="p">[</span><span class="s1">&#39;character_accuracy&#39;</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">✓ YOLOv8s is the better model with </span><span class="si">{</span><span class="n">improvement</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2"> percentage point improvement&quot;</span><span class="p">)</span>
<span class="k">elif</span> <span class="n">metrics_n</span><span class="p">[</span><span class="s1">&#39;character_accuracy&#39;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">metrics_s</span><span class="p">[</span><span class="s1">&#39;character_accuracy&#39;</span><span class="p">]:</span>
    <span class="n">difference</span> <span class="o">=</span> <span class="n">metrics_n</span><span class="p">[</span><span class="s1">&#39;character_accuracy&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">metrics_s</span><span class="p">[</span><span class="s1">&#39;character_accuracy&#39;</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">✓ YOLOv8n is the better model with </span><span class="si">{</span><span class="n">difference</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2"> percentage point improvement&quot;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">= Both models perform equally&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="s1">&#39;=&#39;</span><span class="o">*</span><span class="mi">60</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>============================================================
FINAL MODEL COMPARISON
============================================================
Ground Truth: &#39;DOG&#39;

YOLOv8n: &#39;DOGG&#39; - Character Accuracy: 75.0%
YOLOv8s: &#39;DOG&#39; - Character Accuracy: 100.0%

✓ YOLOv8s is the better model with 25.0 percentage point improvement
============================================================
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">create_gradcam_video</span><span class="p">(</span><span class="n">model_s</span><span class="p">,</span> <span class="n">video_path</span><span class="p">,</span> <span class="n">output_dir</span><span class="p">,</span> <span class="n">vid_name</span><span class="p">,</span> <span class="n">use_simple</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Video rotation metadata: 0.0 degrees
Creating attention visualization...
Processed 30 frames...
Processed 60 frames...
Processed 90 frames...
Processed 120 frames...
Processed 150 frames...

Grad-CAM visualization saved to: video_results\Dog_gradcam.mp4
Total frames: 159
</pre></div>
</div>
</div>
</div>
</section>
<section id="hello">
<h3>Hello<a class="headerlink" href="#hello" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># --- Paths ---</span>
<span class="n">video_path</span> <span class="o">=</span> <span class="s2">&quot;videos/Hello1.mov&quot;</span>
<span class="n">vid_name</span> <span class="o">=</span> <span class="s2">&quot;Hello1&quot;</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create side-by-side comparison</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Creating side-by-side comparison video...&quot;</span><span class="p">)</span>
<span class="n">seq_n</span><span class="p">,</span> <span class="n">seq_s</span><span class="p">,</span> <span class="n">stats_n</span><span class="p">,</span> <span class="n">stats_s</span><span class="p">,</span> <span class="n">metrics_n</span><span class="p">,</span> <span class="n">metrics_s</span><span class="p">,</span> <span class="n">ground_truth</span> <span class="o">=</span> <span class="n">create_side_by_side_comparison</span><span class="p">(</span>
    <span class="n">model_n</span><span class="p">,</span> <span class="n">model_s</span><span class="p">,</span> <span class="n">video_path</span><span class="p">,</span> <span class="n">output_dir</span><span class="p">,</span> <span class="n">vid_name</span><span class="p">,</span>
    <span class="n">conf_threshold</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">stability_threshold</span><span class="o">=</span><span class="mi">5</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Creating side-by-side comparison video...
Video rotation metadata: 180.0 degrees
Processing frames for side-by-side comparison...

0: 384x640 1 H, 114.0ms
Speed: 3.8ms preprocess, 114.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 H, 272.9ms
Speed: 3.9ms preprocess, 272.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 H, 126.9ms
Speed: 3.5ms preprocess, 126.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 H, 221.8ms
Speed: 3.7ms preprocess, 221.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 H, 141.0ms
Speed: 3.3ms preprocess, 141.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 H, 310.9ms
Speed: 4.5ms preprocess, 310.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 H, 119.3ms
Speed: 3.6ms preprocess, 119.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 H, 255.5ms
Speed: 3.5ms preprocess, 255.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 H, 340.0ms
Speed: 3.8ms preprocess, 340.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 H, 237.8ms
Speed: 6.0ms preprocess, 237.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 H, 148.7ms
Speed: 3.8ms preprocess, 148.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 H, 381.6ms
Speed: 3.4ms preprocess, 381.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 H, 99.6ms
Speed: 3.7ms preprocess, 99.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 H, 209.9ms
Speed: 2.9ms preprocess, 209.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 H, 87.7ms
Speed: 3.3ms preprocess, 87.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 H, 196.5ms
Speed: 3.0ms preprocess, 196.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 H, 115.5ms
Speed: 2.9ms preprocess, 115.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 H, 233.7ms
Speed: 3.6ms preprocess, 233.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 H, 95.5ms
Speed: 2.9ms preprocess, 95.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 H, 212.4ms
Speed: 3.3ms preprocess, 212.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 H, 77.6ms
Speed: 2.8ms preprocess, 77.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 H, 199.8ms
Speed: 2.9ms preprocess, 199.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 H, 111.7ms
Speed: 3.8ms preprocess, 111.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 H, 263.3ms
Speed: 3.3ms preprocess, 263.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 H, 213.0ms
Speed: 3.6ms preprocess, 213.0ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 H, 700.6ms
Speed: 22.2ms preprocess, 700.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 H, 160.1ms
Speed: 4.8ms preprocess, 160.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 H, 322.9ms
Speed: 3.4ms preprocess, 322.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 H, 149.0ms
Speed: 4.9ms preprocess, 149.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 H, 372.2ms
Speed: 3.4ms preprocess, 372.2ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 H, 151.6ms
Speed: 4.9ms preprocess, 151.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 H, 521.8ms
Speed: 3.1ms preprocess, 521.8ms inference, 23.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 H, 203.6ms
Speed: 11.0ms preprocess, 203.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 H, 374.3ms
Speed: 3.6ms preprocess, 374.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 H, 121.4ms
Speed: 3.8ms preprocess, 121.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 H, 339.5ms
Speed: 3.3ms preprocess, 339.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 H, 164.5ms
Speed: 3.8ms preprocess, 164.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 H, 339.0ms
Speed: 3.6ms preprocess, 339.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 H, 144.4ms
Speed: 4.0ms preprocess, 144.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 H, 385.1ms
Speed: 3.5ms preprocess, 385.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 H, 161.2ms
Speed: 4.3ms preprocess, 161.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 H, 507.9ms
Speed: 3.3ms preprocess, 507.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 H, 151.2ms
Speed: 5.6ms preprocess, 151.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 H, 395.0ms
Speed: 3.6ms preprocess, 395.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 H, 183.5ms
Speed: 4.0ms preprocess, 183.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 H, 396.5ms
Speed: 10.6ms preprocess, 396.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 H, 212.0ms
Speed: 3.9ms preprocess, 212.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 H, 321.4ms
Speed: 4.1ms preprocess, 321.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 H, 192.0ms
Speed: 3.7ms preprocess, 192.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 H, 372.2ms
Speed: 3.9ms preprocess, 372.2ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 H, 299.3ms
Speed: 5.6ms preprocess, 299.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 H, 383.7ms
Speed: 5.0ms preprocess, 383.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 188.5ms
Speed: 5.1ms preprocess, 188.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 384.6ms
Speed: 3.6ms preprocess, 384.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 199.8ms
Speed: 5.1ms preprocess, 199.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 375.8ms
Speed: 3.6ms preprocess, 375.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 332.8ms
Speed: 3.2ms preprocess, 332.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 437.7ms
Speed: 3.9ms preprocess, 437.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 183.6ms
Speed: 4.5ms preprocess, 183.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 675.2ms
Speed: 3.2ms preprocess, 675.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)
Processed 30 frames...

0: 384x640 (no detections), 240.4ms
Speed: 6.0ms preprocess, 240.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 X, 489.2ms
Speed: 23.6ms preprocess, 489.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 C, 139.3ms
Speed: 3.4ms preprocess, 139.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 C, 327.3ms
Speed: 3.7ms preprocess, 327.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 197.5ms
Speed: 4.3ms preprocess, 197.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 357.3ms
Speed: 4.2ms preprocess, 357.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 141.3ms
Speed: 3.0ms preprocess, 141.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 597.8ms
Speed: 3.6ms preprocess, 597.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 149.5ms
Speed: 3.9ms preprocess, 149.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 311.9ms
Speed: 3.6ms preprocess, 311.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 132.8ms
Speed: 3.6ms preprocess, 132.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 296.7ms
Speed: 3.1ms preprocess, 296.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 294.9ms
Speed: 3.5ms preprocess, 294.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 366.8ms
Speed: 4.1ms preprocess, 366.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 151.6ms
Speed: 4.6ms preprocess, 151.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 299.6ms
Speed: 4.1ms preprocess, 299.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 127.3ms
Speed: 3.6ms preprocess, 127.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 319.5ms
Speed: 3.4ms preprocess, 319.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 120.4ms
Speed: 3.8ms preprocess, 120.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 266.5ms
Speed: 3.5ms preprocess, 266.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 132.8ms
Speed: 4.0ms preprocess, 132.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 257.4ms
Speed: 3.6ms preprocess, 257.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 121.3ms
Speed: 3.6ms preprocess, 121.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 288.8ms
Speed: 4.8ms preprocess, 288.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 107.9ms
Speed: 4.2ms preprocess, 107.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 235.5ms
Speed: 3.2ms preprocess, 235.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 112.7ms
Speed: 3.9ms preprocess, 112.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 239.6ms
Speed: 3.2ms preprocess, 239.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 108.4ms
Speed: 3.2ms preprocess, 108.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 228.7ms
Speed: 3.5ms preprocess, 228.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 116.6ms
Speed: 4.6ms preprocess, 116.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 367.2ms
Speed: 3.2ms preprocess, 367.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 86.0ms
Speed: 3.1ms preprocess, 86.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 230.7ms
Speed: 2.9ms preprocess, 230.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 99.6ms
Speed: 3.6ms preprocess, 99.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 253.4ms
Speed: 2.9ms preprocess, 253.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 93.3ms
Speed: 3.1ms preprocess, 93.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 218.0ms
Speed: 3.0ms preprocess, 218.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 92.1ms
Speed: 3.2ms preprocess, 92.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 220.3ms
Speed: 3.0ms preprocess, 220.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 122.3ms
Speed: 3.6ms preprocess, 122.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 248.6ms
Speed: 3.7ms preprocess, 248.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 119.1ms
Speed: 4.0ms preprocess, 119.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 242.4ms
Speed: 2.9ms preprocess, 242.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 88.5ms
Speed: 3.0ms preprocess, 88.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 208.0ms
Speed: 3.4ms preprocess, 208.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 1 M, 88.3ms
Speed: 3.3ms preprocess, 88.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 209.8ms
Speed: 3.0ms preprocess, 209.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 87.6ms
Speed: 3.4ms preprocess, 87.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 209.2ms
Speed: 3.1ms preprocess, 209.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 1 M, 86.8ms
Speed: 3.3ms preprocess, 86.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 205.3ms
Speed: 3.1ms preprocess, 205.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 1 M, 89.3ms
Speed: 3.1ms preprocess, 89.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 216.8ms
Speed: 3.1ms preprocess, 216.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 1 M, 88.6ms
Speed: 3.0ms preprocess, 88.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 209.4ms
Speed: 3.1ms preprocess, 209.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 87.5ms
Speed: 3.1ms preprocess, 87.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 206.9ms
Speed: 3.6ms preprocess, 206.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 88.2ms
Speed: 3.1ms preprocess, 88.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 209.5ms
Speed: 3.1ms preprocess, 209.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)
Processed 60 frames...

0: 384x640 1 E, 89.0ms
Speed: 3.1ms preprocess, 89.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 223.0ms
Speed: 2.8ms preprocess, 223.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 120.4ms
Speed: 3.3ms preprocess, 120.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 248.2ms
Speed: 3.1ms preprocess, 248.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 106.5ms
Speed: 3.2ms preprocess, 106.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 235.4ms
Speed: 3.1ms preprocess, 235.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 87.2ms
Speed: 3.5ms preprocess, 87.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 208.0ms
Speed: 3.0ms preprocess, 208.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 91.3ms
Speed: 3.1ms preprocess, 91.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 206.4ms
Speed: 3.1ms preprocess, 206.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 90.5ms
Speed: 3.0ms preprocess, 90.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 207.9ms
Speed: 3.2ms preprocess, 207.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 88.1ms
Speed: 3.3ms preprocess, 88.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 211.3ms
Speed: 3.1ms preprocess, 211.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 87.9ms
Speed: 3.1ms preprocess, 87.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 228.0ms
Speed: 2.8ms preprocess, 228.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 95.5ms
Speed: 3.4ms preprocess, 95.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 223.3ms
Speed: 3.6ms preprocess, 223.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 1 M, 89.6ms
Speed: 3.0ms preprocess, 89.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 207.7ms
Speed: 3.2ms preprocess, 207.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 1 M, 94.0ms
Speed: 5.3ms preprocess, 94.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 217.3ms
Speed: 3.1ms preprocess, 217.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 1 M, 91.5ms
Speed: 3.2ms preprocess, 91.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 211.7ms
Speed: 3.1ms preprocess, 211.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 88.6ms
Speed: 3.1ms preprocess, 88.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 246.9ms
Speed: 3.1ms preprocess, 246.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 140.0ms
Speed: 3.7ms preprocess, 140.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 261.1ms
Speed: 3.4ms preprocess, 261.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 110.2ms
Speed: 3.5ms preprocess, 110.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 260.5ms
Speed: 3.2ms preprocess, 260.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 109.4ms
Speed: 3.4ms preprocess, 109.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 210.1ms
Speed: 3.2ms preprocess, 210.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 88.9ms
Speed: 3.6ms preprocess, 88.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 216.8ms
Speed: 3.2ms preprocess, 216.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 92.9ms
Speed: 3.6ms preprocess, 92.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 206.4ms
Speed: 2.7ms preprocess, 206.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 89.9ms
Speed: 4.2ms preprocess, 89.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 210.5ms
Speed: 3.5ms preprocess, 210.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 88.4ms
Speed: 3.1ms preprocess, 88.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 1 M, 209.9ms
Speed: 3.2ms preprocess, 209.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 91.4ms
Speed: 3.1ms preprocess, 91.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 1 M, 206.6ms
Speed: 2.8ms preprocess, 206.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 88.7ms
Speed: 3.2ms preprocess, 88.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 214.0ms
Speed: 3.0ms preprocess, 214.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 89.3ms
Speed: 3.4ms preprocess, 89.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 1 M, 206.0ms
Speed: 3.2ms preprocess, 206.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 87.3ms
Speed: 3.1ms preprocess, 87.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 1 M, 208.0ms
Speed: 3.2ms preprocess, 208.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 90.0ms
Speed: 3.2ms preprocess, 90.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 1 M, 208.6ms
Speed: 3.1ms preprocess, 208.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 89.7ms
Speed: 3.1ms preprocess, 89.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 1 M, 206.9ms
Speed: 2.8ms preprocess, 206.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 87.6ms
Speed: 3.2ms preprocess, 87.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 1 M, 216.5ms
Speed: 3.2ms preprocess, 216.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 93.9ms
Speed: 3.1ms preprocess, 93.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 1 M, 209.4ms
Speed: 2.9ms preprocess, 209.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 129.6ms
Speed: 3.2ms preprocess, 129.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 234.1ms
Speed: 3.0ms preprocess, 234.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 100.9ms
Speed: 3.2ms preprocess, 100.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 240.9ms
Speed: 3.5ms preprocess, 240.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)
Processed 90 frames...

0: 384x640 1 E, 88.1ms
Speed: 3.3ms preprocess, 88.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 207.2ms
Speed: 3.1ms preprocess, 207.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 88.3ms
Speed: 3.1ms preprocess, 88.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 207.9ms
Speed: 3.0ms preprocess, 207.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 99.5ms
Speed: 3.1ms preprocess, 99.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 210.4ms
Speed: 3.1ms preprocess, 210.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 88.7ms
Speed: 3.1ms preprocess, 88.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 208.3ms
Speed: 3.3ms preprocess, 208.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 89.4ms
Speed: 3.3ms preprocess, 89.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 210.2ms
Speed: 3.5ms preprocess, 210.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 88.6ms
Speed: 3.4ms preprocess, 88.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 212.8ms
Speed: 3.1ms preprocess, 212.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 91.0ms
Speed: 3.1ms preprocess, 91.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 210.7ms
Speed: 3.2ms preprocess, 210.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 93.0ms
Speed: 3.2ms preprocess, 93.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 208.2ms
Speed: 3.2ms preprocess, 208.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 86.5ms
Speed: 3.5ms preprocess, 86.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 209.9ms
Speed: 3.1ms preprocess, 209.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 86.1ms
Speed: 3.2ms preprocess, 86.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 228.8ms
Speed: 3.2ms preprocess, 228.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 90.2ms
Speed: 3.2ms preprocess, 90.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 206.1ms
Speed: 3.3ms preprocess, 206.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 88.7ms
Speed: 3.5ms preprocess, 88.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 208.3ms
Speed: 3.1ms preprocess, 208.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 89.2ms
Speed: 3.0ms preprocess, 89.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 214.7ms
Speed: 3.3ms preprocess, 214.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 185.8ms
Speed: 3.1ms preprocess, 185.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 268.0ms
Speed: 2.7ms preprocess, 268.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 89.4ms
Speed: 3.0ms preprocess, 89.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 208.8ms
Speed: 3.1ms preprocess, 208.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 90.5ms
Speed: 3.1ms preprocess, 90.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 282.4ms
Speed: 3.0ms preprocess, 282.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 105.5ms
Speed: 3.9ms preprocess, 105.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 232.5ms
Speed: 3.6ms preprocess, 232.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 93.1ms
Speed: 3.2ms preprocess, 93.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 210.5ms
Speed: 2.9ms preprocess, 210.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 91.8ms
Speed: 3.1ms preprocess, 91.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 205.9ms
Speed: 3.1ms preprocess, 205.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 88.6ms
Speed: 3.0ms preprocess, 88.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 208.9ms
Speed: 3.2ms preprocess, 208.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 89.3ms
Speed: 3.1ms preprocess, 89.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 239.1ms
Speed: 3.3ms preprocess, 239.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 105.4ms
Speed: 3.4ms preprocess, 105.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 212.8ms
Speed: 4.0ms preprocess, 212.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 89.4ms
Speed: 3.1ms preprocess, 89.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 216.8ms
Speed: 3.8ms preprocess, 216.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 90.3ms
Speed: 3.0ms preprocess, 90.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 209.5ms
Speed: 2.9ms preprocess, 209.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 87.4ms
Speed: 3.1ms preprocess, 87.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 221.7ms
Speed: 2.9ms preprocess, 221.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 99.1ms
Speed: 3.2ms preprocess, 99.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 233.5ms
Speed: 2.8ms preprocess, 233.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 143.9ms
Speed: 5.1ms preprocess, 143.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 449.4ms
Speed: 3.1ms preprocess, 449.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 129.2ms
Speed: 3.5ms preprocess, 129.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 248.0ms
Speed: 3.8ms preprocess, 248.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 88.0ms
Speed: 3.0ms preprocess, 88.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 210.8ms
Speed: 2.9ms preprocess, 210.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 90.1ms
Speed: 3.1ms preprocess, 90.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 212.0ms
Speed: 2.8ms preprocess, 212.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)
Processed 120 frames...

0: 384x640 1 L, 92.9ms
Speed: 3.1ms preprocess, 92.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 212.5ms
Speed: 2.8ms preprocess, 212.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 90.5ms
Speed: 3.1ms preprocess, 90.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 208.8ms
Speed: 3.0ms preprocess, 208.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 87.8ms
Speed: 3.0ms preprocess, 87.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 209.5ms
Speed: 2.9ms preprocess, 209.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 89.3ms
Speed: 3.2ms preprocess, 89.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 217.4ms
Speed: 3.2ms preprocess, 217.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 93.5ms
Speed: 3.1ms preprocess, 93.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 211.8ms
Speed: 3.2ms preprocess, 211.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 89.8ms
Speed: 3.1ms preprocess, 89.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 212.5ms
Speed: 3.0ms preprocess, 212.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 86.6ms
Speed: 3.3ms preprocess, 86.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 222.8ms
Speed: 3.0ms preprocess, 222.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 104.0ms
Speed: 3.3ms preprocess, 104.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 235.8ms
Speed: 3.3ms preprocess, 235.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 98.8ms
Speed: 3.1ms preprocess, 98.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 428.1ms
Speed: 3.1ms preprocess, 428.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 111.9ms
Speed: 5.1ms preprocess, 111.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 293.8ms
Speed: 3.5ms preprocess, 293.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 117.1ms
Speed: 3.4ms preprocess, 117.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 258.0ms
Speed: 3.4ms preprocess, 258.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 105.1ms
Speed: 3.9ms preprocess, 105.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 247.7ms
Speed: 3.5ms preprocess, 247.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 109.9ms
Speed: 3.2ms preprocess, 109.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 238.1ms
Speed: 3.1ms preprocess, 238.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 143.5ms
Speed: 3.6ms preprocess, 143.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 249.9ms
Speed: 3.9ms preprocess, 249.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 94.6ms
Speed: 3.2ms preprocess, 94.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 215.9ms
Speed: 3.2ms preprocess, 215.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 89.4ms
Speed: 3.2ms preprocess, 89.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 215.3ms
Speed: 3.1ms preprocess, 215.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 96.3ms
Speed: 3.2ms preprocess, 96.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 211.8ms
Speed: 2.7ms preprocess, 211.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 89.7ms
Speed: 3.0ms preprocess, 89.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 212.1ms
Speed: 3.1ms preprocess, 212.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 90.3ms
Speed: 3.2ms preprocess, 90.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 213.2ms
Speed: 3.1ms preprocess, 213.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 89.4ms
Speed: 3.3ms preprocess, 89.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 383.4ms
Speed: 3.0ms preprocess, 383.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 107.9ms
Speed: 3.8ms preprocess, 107.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 271.9ms
Speed: 3.4ms preprocess, 271.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 106.9ms
Speed: 3.3ms preprocess, 106.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 239.4ms
Speed: 2.9ms preprocess, 239.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 87.5ms
Speed: 3.0ms preprocess, 87.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 214.6ms
Speed: 2.9ms preprocess, 214.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 86.7ms
Speed: 3.2ms preprocess, 86.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 211.4ms
Speed: 3.2ms preprocess, 211.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 90.8ms
Speed: 3.1ms preprocess, 90.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 209.6ms
Speed: 2.9ms preprocess, 209.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 91.5ms
Speed: 3.1ms preprocess, 91.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 213.8ms
Speed: 3.3ms preprocess, 213.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 93.4ms
Speed: 3.4ms preprocess, 93.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 211.7ms
Speed: 3.0ms preprocess, 211.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 88.2ms
Speed: 3.2ms preprocess, 88.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 247.6ms
Speed: 3.3ms preprocess, 247.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 89.4ms
Speed: 3.2ms preprocess, 89.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 208.1ms
Speed: 3.0ms preprocess, 208.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 90.1ms
Speed: 3.0ms preprocess, 90.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 213.3ms
Speed: 3.0ms preprocess, 213.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)
Processed 150 frames...

0: 384x640 1 L, 101.8ms
Speed: 22.4ms preprocess, 101.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 210.1ms
Speed: 3.8ms preprocess, 210.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 87.9ms
Speed: 3.0ms preprocess, 87.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 208.6ms
Speed: 3.0ms preprocess, 208.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 92.3ms
Speed: 3.3ms preprocess, 92.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 208.5ms
Speed: 3.1ms preprocess, 208.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 89.3ms
Speed: 3.0ms preprocess, 89.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 223.7ms
Speed: 3.1ms preprocess, 223.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 96.7ms
Speed: 3.3ms preprocess, 96.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 249.3ms
Speed: 3.3ms preprocess, 249.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 88.7ms
Speed: 3.1ms preprocess, 88.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 210.3ms
Speed: 3.2ms preprocess, 210.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 96.2ms
Speed: 3.1ms preprocess, 96.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 238.3ms
Speed: 3.2ms preprocess, 238.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 96.8ms
Speed: 3.3ms preprocess, 96.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 244.7ms
Speed: 3.2ms preprocess, 244.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 86.8ms
Speed: 3.1ms preprocess, 86.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 210.5ms
Speed: 3.9ms preprocess, 210.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 86.5ms
Speed: 3.1ms preprocess, 86.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 372.0ms
Speed: 3.0ms preprocess, 372.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 89.5ms
Speed: 3.0ms preprocess, 89.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 209.7ms
Speed: 3.1ms preprocess, 209.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 92.3ms
Speed: 3.4ms preprocess, 92.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 210.2ms
Speed: 3.1ms preprocess, 210.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 88.5ms
Speed: 3.1ms preprocess, 88.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 211.0ms
Speed: 3.2ms preprocess, 211.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 88.1ms
Speed: 3.2ms preprocess, 88.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 208.6ms
Speed: 2.9ms preprocess, 208.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 91.6ms
Speed: 3.0ms preprocess, 91.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 214.3ms
Speed: 3.5ms preprocess, 214.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 91.7ms
Speed: 3.0ms preprocess, 91.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 213.7ms
Speed: 2.9ms preprocess, 213.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 86.9ms
Speed: 3.6ms preprocess, 86.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 217.6ms
Speed: 2.9ms preprocess, 217.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 91.7ms
Speed: 3.1ms preprocess, 91.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 238.8ms
Speed: 3.6ms preprocess, 238.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 108.6ms
Speed: 3.0ms preprocess, 108.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 240.5ms
Speed: 2.9ms preprocess, 240.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 156.3ms
Speed: 4.3ms preprocess, 156.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 268.5ms
Speed: 3.3ms preprocess, 268.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 137.4ms
Speed: 4.6ms preprocess, 137.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 312.7ms
Speed: 3.2ms preprocess, 312.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 89.4ms
Speed: 3.1ms preprocess, 89.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 263.8ms
Speed: 3.2ms preprocess, 263.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 99.6ms
Speed: 3.1ms preprocess, 99.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 212.5ms
Speed: 3.0ms preprocess, 212.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 126.9ms
Speed: 3.3ms preprocess, 126.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 281.3ms
Speed: 3.5ms preprocess, 281.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 134.5ms
Speed: 3.8ms preprocess, 134.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 313.2ms
Speed: 3.3ms preprocess, 313.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 91.0ms
Speed: 3.0ms preprocess, 91.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 227.7ms
Speed: 2.9ms preprocess, 227.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 95.1ms
Speed: 3.4ms preprocess, 95.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 223.7ms
Speed: 3.6ms preprocess, 223.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 90.4ms
Speed: 3.0ms preprocess, 90.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 371.8ms
Speed: 2.9ms preprocess, 371.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 88.5ms
Speed: 3.1ms preprocess, 88.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 216.6ms
Speed: 2.9ms preprocess, 216.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 88.4ms
Speed: 3.1ms preprocess, 88.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 218.9ms
Speed: 3.1ms preprocess, 218.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)
Processed 180 frames...

0: 384x640 1 L, 92.7ms
Speed: 3.1ms preprocess, 92.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 218.8ms
Speed: 3.1ms preprocess, 218.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 99.9ms
Speed: 3.4ms preprocess, 99.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 220.8ms
Speed: 3.2ms preprocess, 220.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 88.3ms
Speed: 3.0ms preprocess, 88.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 214.3ms
Speed: 3.5ms preprocess, 214.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 89.5ms
Speed: 3.2ms preprocess, 89.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 215.6ms
Speed: 3.2ms preprocess, 215.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 92.8ms
Speed: 3.1ms preprocess, 92.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 213.9ms
Speed: 2.8ms preprocess, 213.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 93.1ms
Speed: 3.3ms preprocess, 93.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 215.6ms
Speed: 2.8ms preprocess, 215.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 136.7ms
Speed: 3.2ms preprocess, 136.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 233.4ms
Speed: 3.7ms preprocess, 233.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 88.2ms
Speed: 3.1ms preprocess, 88.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 215.6ms
Speed: 2.9ms preprocess, 215.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 93.2ms
Speed: 3.1ms preprocess, 93.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 220.5ms
Speed: 3.0ms preprocess, 220.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 94.3ms
Speed: 3.0ms preprocess, 94.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 215.8ms
Speed: 3.2ms preprocess, 215.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 88.4ms
Speed: 3.3ms preprocess, 88.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 212.7ms
Speed: 3.0ms preprocess, 212.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 89.6ms
Speed: 3.0ms preprocess, 89.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 211.4ms
Speed: 2.8ms preprocess, 211.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 100.4ms
Speed: 2.9ms preprocess, 100.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 237.4ms
Speed: 3.2ms preprocess, 237.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 103.5ms
Speed: 3.8ms preprocess, 103.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 250.7ms
Speed: 3.1ms preprocess, 250.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 124.2ms
Speed: 3.2ms preprocess, 124.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 248.7ms
Speed: 3.2ms preprocess, 248.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 97.8ms
Speed: 3.5ms preprocess, 97.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 241.3ms
Speed: 3.4ms preprocess, 241.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 92.6ms
Speed: 3.0ms preprocess, 92.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 211.6ms
Speed: 3.3ms preprocess, 211.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 107.7ms
Speed: 3.2ms preprocess, 107.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 242.6ms
Speed: 3.1ms preprocess, 242.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 111.6ms
Speed: 3.2ms preprocess, 111.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 217.0ms
Speed: 2.9ms preprocess, 217.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 87.8ms
Speed: 3.1ms preprocess, 87.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 215.5ms
Speed: 3.1ms preprocess, 215.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 93.8ms
Speed: 3.2ms preprocess, 93.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 213.2ms
Speed: 3.0ms preprocess, 213.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 91.6ms
Speed: 3.2ms preprocess, 91.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 373.2ms
Speed: 3.0ms preprocess, 373.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 101.5ms
Speed: 3.0ms preprocess, 101.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 245.6ms
Speed: 3.3ms preprocess, 245.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 89.2ms
Speed: 3.4ms preprocess, 89.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 218.4ms
Speed: 3.0ms preprocess, 218.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 99.9ms
Speed: 2.9ms preprocess, 99.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 214.3ms
Speed: 3.3ms preprocess, 214.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 101.2ms
Speed: 3.3ms preprocess, 101.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 215.8ms
Speed: 3.2ms preprocess, 215.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 89.0ms
Speed: 3.2ms preprocess, 89.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 213.0ms
Speed: 2.9ms preprocess, 213.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 F, 1 K, 88.5ms
Speed: 3.1ms preprocess, 88.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 K, 216.6ms
Speed: 3.2ms preprocess, 216.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 K, 122.6ms
Speed: 3.2ms preprocess, 122.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 K, 216.5ms
Speed: 3.1ms preprocess, 216.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 92.9ms
Speed: 3.2ms preprocess, 92.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 R, 216.9ms
Speed: 3.2ms preprocess, 216.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)
Processed 210 frames...

0: 384x640 1 O, 88.5ms
Speed: 3.6ms preprocess, 88.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 215.5ms
Speed: 2.9ms preprocess, 215.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 88.2ms
Speed: 2.9ms preprocess, 88.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 C, 215.6ms
Speed: 3.1ms preprocess, 215.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 92.9ms
Speed: 3.0ms preprocess, 92.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 J, 217.1ms
Speed: 3.0ms preprocess, 217.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 93.3ms
Speed: 3.1ms preprocess, 93.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 213.1ms
Speed: 2.8ms preprocess, 213.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 92.7ms
Speed: 3.5ms preprocess, 92.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 217.8ms
Speed: 3.2ms preprocess, 217.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 244.1ms
Speed: 3.1ms preprocess, 244.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 214.9ms
Speed: 3.6ms preprocess, 214.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 97.7ms
Speed: 3.1ms preprocess, 97.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 215.0ms
Speed: 3.1ms preprocess, 215.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 91.2ms
Speed: 3.2ms preprocess, 91.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 221.3ms
Speed: 3.0ms preprocess, 221.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 113.7ms
Speed: 3.1ms preprocess, 113.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 308.5ms
Speed: 3.4ms preprocess, 308.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 111.5ms
Speed: 4.1ms preprocess, 111.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 229.5ms
Speed: 3.3ms preprocess, 229.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 91.6ms
Speed: 3.3ms preprocess, 91.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 219.2ms
Speed: 3.0ms preprocess, 219.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 91.4ms
Speed: 3.0ms preprocess, 91.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 219.4ms
Speed: 3.7ms preprocess, 219.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 246.4ms
Speed: 3.3ms preprocess, 246.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 211.6ms
Speed: 3.4ms preprocess, 211.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 87.9ms
Speed: 3.2ms preprocess, 87.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 221.9ms
Speed: 2.9ms preprocess, 221.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 92.9ms
Speed: 3.1ms preprocess, 92.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 210.2ms
Speed: 3.1ms preprocess, 210.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 91.9ms
Speed: 3.1ms preprocess, 91.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 210.8ms
Speed: 3.2ms preprocess, 210.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 89.6ms
Speed: 3.6ms preprocess, 89.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 210.6ms
Speed: 3.9ms preprocess, 210.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 88.8ms
Speed: 3.7ms preprocess, 88.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 213.2ms
Speed: 3.0ms preprocess, 213.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 92.3ms
Speed: 3.2ms preprocess, 92.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 213.8ms
Speed: 3.8ms preprocess, 213.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 128.8ms
Speed: 3.6ms preprocess, 128.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 213.7ms
Speed: 3.1ms preprocess, 213.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 86.7ms
Speed: 3.1ms preprocess, 86.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 215.4ms
Speed: 3.0ms preprocess, 215.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 89.4ms
Speed: 3.1ms preprocess, 89.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 211.4ms
Speed: 2.9ms preprocess, 211.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 92.5ms
Speed: 3.6ms preprocess, 92.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 213.8ms
Speed: 3.1ms preprocess, 213.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 90.7ms
Speed: 3.1ms preprocess, 90.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 216.7ms
Speed: 3.0ms preprocess, 216.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 90.3ms
Speed: 3.8ms preprocess, 90.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 211.8ms
Speed: 2.9ms preprocess, 211.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 90.1ms
Speed: 3.2ms preprocess, 90.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 372.4ms
Speed: 2.9ms preprocess, 372.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 100.8ms
Speed: 3.9ms preprocess, 100.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 211.4ms
Speed: 3.9ms preprocess, 211.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 90.1ms
Speed: 3.6ms preprocess, 90.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 211.8ms
Speed: 2.8ms preprocess, 211.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 90.7ms
Speed: 3.5ms preprocess, 90.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 228.6ms
Speed: 2.9ms preprocess, 228.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 90.2ms
Speed: 3.3ms preprocess, 90.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 211.0ms
Speed: 2.8ms preprocess, 211.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)
Processed 240 frames...

0: 384x640 1 O, 94.5ms
Speed: 3.1ms preprocess, 94.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 215.5ms
Speed: 3.5ms preprocess, 215.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 91.6ms
Speed: 3.3ms preprocess, 91.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 211.6ms
Speed: 2.8ms preprocess, 211.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 130.5ms
Speed: 4.7ms preprocess, 130.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 210.7ms
Speed: 3.2ms preprocess, 210.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 103.5ms
Speed: 4.2ms preprocess, 103.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 230.1ms
Speed: 3.1ms preprocess, 230.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 106.2ms
Speed: 3.8ms preprocess, 106.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 244.5ms
Speed: 3.0ms preprocess, 244.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 106.0ms
Speed: 2.9ms preprocess, 106.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 232.9ms
Speed: 3.2ms preprocess, 232.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 87.9ms
Speed: 3.2ms preprocess, 87.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 212.8ms
Speed: 2.9ms preprocess, 212.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 89.2ms
Speed: 3.2ms preprocess, 89.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 227.3ms
Speed: 3.1ms preprocess, 227.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 259.5ms
Speed: 3.3ms preprocess, 259.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 212.5ms
Speed: 3.2ms preprocess, 212.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 93.1ms
Speed: 2.9ms preprocess, 93.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 215.0ms
Speed: 3.6ms preprocess, 215.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 98.7ms
Speed: 3.3ms preprocess, 98.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 235.8ms
Speed: 3.2ms preprocess, 235.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 91.2ms
Speed: 3.2ms preprocess, 91.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 219.1ms
Speed: 2.9ms preprocess, 219.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 95.1ms
Speed: 3.1ms preprocess, 95.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 221.0ms
Speed: 3.8ms preprocess, 221.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 97.2ms
Speed: 3.2ms preprocess, 97.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 216.7ms
Speed: 3.2ms preprocess, 216.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 250.8ms
Speed: 3.2ms preprocess, 250.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 219.3ms
Speed: 3.4ms preprocess, 219.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 93.7ms
Speed: 3.7ms preprocess, 93.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 218.6ms
Speed: 3.5ms preprocess, 218.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 97.2ms
Speed: 3.0ms preprocess, 97.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 219.6ms
Speed: 2.9ms preprocess, 219.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 93.0ms
Speed: 3.2ms preprocess, 93.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 220.0ms
Speed: 2.9ms preprocess, 220.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 102.7ms
Speed: 3.2ms preprocess, 102.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 249.2ms
Speed: 3.4ms preprocess, 249.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 92.7ms
Speed: 3.7ms preprocess, 92.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 219.5ms
Speed: 3.0ms preprocess, 219.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 265.2ms
Speed: 3.1ms preprocess, 265.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 222.9ms
Speed: 3.1ms preprocess, 222.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 95.1ms
Speed: 3.2ms preprocess, 95.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 220.6ms
Speed: 2.9ms preprocess, 220.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 90.4ms
Speed: 3.1ms preprocess, 90.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 223.0ms
Speed: 2.9ms preprocess, 223.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 91.5ms
Speed: 3.2ms preprocess, 91.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 223.5ms
Speed: 3.2ms preprocess, 223.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 97.0ms
Speed: 3.4ms preprocess, 97.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 220.2ms
Speed: 3.0ms preprocess, 220.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 95.2ms
Speed: 3.3ms preprocess, 95.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 225.5ms
Speed: 3.0ms preprocess, 225.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 131.3ms
Speed: 3.8ms preprocess, 131.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 217.2ms
Speed: 3.0ms preprocess, 217.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 95.9ms
Speed: 3.2ms preprocess, 95.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 218.4ms
Speed: 3.0ms preprocess, 218.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 96.5ms
Speed: 3.2ms preprocess, 96.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 225.3ms
Speed: 4.3ms preprocess, 225.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 108.9ms
Speed: 3.3ms preprocess, 108.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 256.6ms
Speed: 2.9ms preprocess, 256.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)
Processed 270 frames...

0: 384x640 1 O, 106.5ms
Speed: 3.8ms preprocess, 106.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 256.2ms
Speed: 3.4ms preprocess, 256.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 90.3ms
Speed: 3.4ms preprocess, 90.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 389.4ms
Speed: 3.1ms preprocess, 389.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 93.3ms
Speed: 3.3ms preprocess, 93.3ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 220.2ms
Speed: 3.0ms preprocess, 220.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 95.8ms
Speed: 5.6ms preprocess, 95.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 220.1ms
Speed: 3.3ms preprocess, 220.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 91.7ms
Speed: 3.3ms preprocess, 91.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 221.0ms
Speed: 3.4ms preprocess, 221.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 92.1ms
Speed: 3.6ms preprocess, 92.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 222.0ms
Speed: 3.0ms preprocess, 222.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 89.9ms
Speed: 3.0ms preprocess, 89.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 224.6ms
Speed: 3.0ms preprocess, 224.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 89.6ms
Speed: 2.9ms preprocess, 89.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 384.2ms
Speed: 3.2ms preprocess, 384.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 91.7ms
Speed: 3.0ms preprocess, 91.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 220.1ms
Speed: 3.0ms preprocess, 220.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 95.1ms
Speed: 3.1ms preprocess, 95.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 221.1ms
Speed: 3.5ms preprocess, 221.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 89.9ms
Speed: 3.1ms preprocess, 89.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 223.1ms
Speed: 3.2ms preprocess, 223.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 92.0ms
Speed: 3.6ms preprocess, 92.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 227.7ms
Speed: 2.9ms preprocess, 227.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 89.5ms
Speed: 3.2ms preprocess, 89.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 221.7ms
Speed: 3.2ms preprocess, 221.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 258.1ms
Speed: 3.3ms preprocess, 258.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 231.9ms
Speed: 3.6ms preprocess, 231.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 90.0ms
Speed: 3.0ms preprocess, 90.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 224.7ms
Speed: 3.0ms preprocess, 224.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

============================================================
SIDE-BY-SIDE COMPARISON RESULTS
============================================================
Ground Truth (from video name): &#39;HELLO&#39;
Output video: video_results\Hello1_comparison.mp4
Total frames: 285

YOLOv8n:
  Frames with detections: 261
  Reconstructed sequence: &#39;HMMELO&#39;
  Sequence length: 6 letters
  Character Accuracy: 50.0%
  Edit Distance: 3 operations

YOLOv8s:
  Frames with detections: 268
  Reconstructed sequence: &#39;HEEELO&#39;
  Sequence length: 6 letters
  Character Accuracy: 66.7%
  Edit Distance: 2 operations

Sequences match: False
✓ YOLOv8s outperforms YOLOv8n by 16.7 percentage points

YOLOv8n detection frequency:
  L: 104 frames (36.5%)
  O: 75 frames (26.3%)
  E: 30 frames (10.5%)
  H: 26 frames (9.1%)
  M: 23 frames (8.1%)

YOLOv8s detection frequency:
  L: 106 frames (37.2%)
  O: 71 frames (24.9%)
  E: 50 frames (17.5%)
  H: 26 frames (9.1%)
  M: 8 frames (2.8%)
============================================================
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Detailed evaluation report</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="s2">&quot;=&quot;</span><span class="o">*</span><span class="mi">60</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;DETAILED EVALUATION REPORT&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span><span class="o">*</span><span class="mi">60</span><span class="p">)</span>

<span class="n">evaluate_prediction</span><span class="p">(</span><span class="n">seq_n</span><span class="p">,</span> <span class="n">ground_truth</span><span class="p">,</span> <span class="s2">&quot;YOLOv8n&quot;</span><span class="p">)</span>
<span class="n">evaluate_prediction</span><span class="p">(</span><span class="n">seq_s</span><span class="p">,</span> <span class="n">ground_truth</span><span class="p">,</span> <span class="s2">&quot;YOLOv8s&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>============================================================
DETAILED EVALUATION REPORT
============================================================

============================================================
YOLOv8n EVALUATION
============================================================
Ground Truth:  &#39;HELLO&#39;
Predicted:     &#39;HMMELO&#39;

Metrics:
  Exact Match:           ✗ NO
  Edit Distance:         3 operations
  Character Accuracy:    50.0%
  Character Error Rate:  60.0%
  Word Error Rate:       60.0%
  Subsequence Accuracy:  60.0%
============================================================

============================================================
YOLOv8s EVALUATION
============================================================
Ground Truth:  &#39;HELLO&#39;
Predicted:     &#39;HEEELO&#39;

Metrics:
  Exact Match:           ✗ NO
  Edit Distance:         2 operations
  Character Accuracy:    66.7%
  Character Error Rate:  40.0%
  Word Error Rate:       40.0%
  Subsequence Accuracy:  60.0%
============================================================
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;exact_match&#39;: False,
 &#39;edit_distance&#39;: 2,
 &#39;character_accuracy&#39;: 66.66666666666667,
 &#39;wer&#39;: 40.0,
 &#39;cer&#39;: 40.0,
 &#39;subsequence_accuracy&#39;: 60.0}
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Final comparison summary</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="si">{</span><span class="s1">&#39;=&#39;</span><span class="o">*</span><span class="mi">60</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;FINAL MODEL COMPARISON&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="s1">&#39;=&#39;</span><span class="o">*</span><span class="mi">60</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Ground Truth: &#39;</span><span class="si">{</span><span class="n">ground_truth</span><span class="si">}</span><span class="s2">&#39;&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">YOLOv8n: &#39;</span><span class="si">{</span><span class="n">seq_n</span><span class="si">}</span><span class="s2">&#39; - Character Accuracy: </span><span class="si">{</span><span class="n">metrics_n</span><span class="p">[</span><span class="s1">&#39;character_accuracy&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;YOLOv8s: &#39;</span><span class="si">{</span><span class="n">seq_s</span><span class="si">}</span><span class="s2">&#39; - Character Accuracy: </span><span class="si">{</span><span class="n">metrics_s</span><span class="p">[</span><span class="s1">&#39;character_accuracy&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>

<span class="k">if</span> <span class="n">metrics_s</span><span class="p">[</span><span class="s1">&#39;character_accuracy&#39;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">metrics_n</span><span class="p">[</span><span class="s1">&#39;character_accuracy&#39;</span><span class="p">]:</span>
    <span class="n">improvement</span> <span class="o">=</span> <span class="n">metrics_s</span><span class="p">[</span><span class="s1">&#39;character_accuracy&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">metrics_n</span><span class="p">[</span><span class="s1">&#39;character_accuracy&#39;</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">✓ YOLOv8s is the better model with </span><span class="si">{</span><span class="n">improvement</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2"> percentage point improvement&quot;</span><span class="p">)</span>
<span class="k">elif</span> <span class="n">metrics_n</span><span class="p">[</span><span class="s1">&#39;character_accuracy&#39;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">metrics_s</span><span class="p">[</span><span class="s1">&#39;character_accuracy&#39;</span><span class="p">]:</span>
    <span class="n">difference</span> <span class="o">=</span> <span class="n">metrics_n</span><span class="p">[</span><span class="s1">&#39;character_accuracy&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">metrics_s</span><span class="p">[</span><span class="s1">&#39;character_accuracy&#39;</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">✓ YOLOv8n is the better model with </span><span class="si">{</span><span class="n">difference</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2"> percentage point improvement&quot;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">= Both models perform equally&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="s1">&#39;=&#39;</span><span class="o">*</span><span class="mi">60</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>============================================================
FINAL MODEL COMPARISON
============================================================
Ground Truth: &#39;HELLO&#39;

YOLOv8n: &#39;HMMELO&#39; - Character Accuracy: 50.0%
YOLOv8s: &#39;HEEELO&#39; - Character Accuracy: 66.7%

✓ YOLOv8s is the better model with 16.7 percentage point improvement
============================================================
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">create_gradcam_video</span><span class="p">(</span><span class="n">model_s</span><span class="p">,</span> <span class="n">video_path</span><span class="p">,</span> <span class="n">output_dir</span><span class="p">,</span> <span class="n">vid_name</span><span class="p">,</span> <span class="n">use_simple</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Video rotation metadata: 180.0 degrees
Creating attention visualization...
Processed 30 frames...
Processed 60 frames...
Processed 90 frames...
Processed 120 frames...
Processed 150 frames...
Processed 180 frames...
Processed 210 frames...
Processed 240 frames...
Processed 270 frames...

Grad-CAM visualization saved to: video_results\Hello1_gradcam.mp4
Total frames: 285
</pre></div>
</div>
</div>
</div>
</section>
<section id="camera">
<h3>Camera<a class="headerlink" href="#camera" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># --- Paths ---</span>
<span class="n">video_path</span> <span class="o">=</span> <span class="s2">&quot;videos/CAMERA.mp4&quot;</span>
<span class="n">vid_name</span> <span class="o">=</span> <span class="s2">&quot;Camera&quot;</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create side-by-side comparison</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Creating side-by-side comparison video...&quot;</span><span class="p">)</span>
<span class="n">seq_n</span><span class="p">,</span> <span class="n">seq_s</span><span class="p">,</span> <span class="n">stats_n</span><span class="p">,</span> <span class="n">stats_s</span><span class="p">,</span> <span class="n">metrics_n</span><span class="p">,</span> <span class="n">metrics_s</span><span class="p">,</span> <span class="n">ground_truth</span> <span class="o">=</span> <span class="n">create_side_by_side_comparison</span><span class="p">(</span>
    <span class="n">model_n</span><span class="p">,</span> <span class="n">model_s</span><span class="p">,</span> <span class="n">video_path</span><span class="p">,</span> <span class="n">output_dir</span><span class="p">,</span> <span class="n">vid_name</span><span class="p">,</span>
    <span class="n">conf_threshold</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">stability_threshold</span><span class="o">=</span><span class="mi">5</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Creating side-by-side comparison video...
Video rotation metadata: 0.0 degrees
Processing frames for side-by-side comparison...

0: 384x640 (no detections), 107.0ms
Speed: 3.2ms preprocess, 107.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 97.7ms
Speed: 3.1ms preprocess, 97.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 102.7ms
Speed: 3.2ms preprocess, 102.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 95.6ms
Speed: 2.8ms preprocess, 95.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 96.8ms
Speed: 3.1ms preprocess, 96.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 83.8ms
Speed: 2.9ms preprocess, 83.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 86.0ms
Speed: 2.9ms preprocess, 86.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 79.7ms
Speed: 3.1ms preprocess, 79.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 90.0ms
Speed: 3.5ms preprocess, 90.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 96.7ms
Speed: 2.7ms preprocess, 96.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 117.0ms
Speed: 4.3ms preprocess, 117.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 90.8ms
Speed: 2.9ms preprocess, 90.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 101.3ms
Speed: 3.8ms preprocess, 101.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 96.0ms
Speed: 2.8ms preprocess, 96.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 116.9ms
Speed: 4.3ms preprocess, 116.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 174.6ms
Speed: 3.8ms preprocess, 174.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 107.0ms
Speed: 3.3ms preprocess, 107.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 154.7ms
Speed: 3.3ms preprocess, 154.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 316.5ms
Speed: 4.4ms preprocess, 316.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 B, 174.7ms
Speed: 3.2ms preprocess, 174.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 C, 155.7ms
Speed: 3.6ms preprocess, 155.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 C, 126.7ms
Speed: 3.9ms preprocess, 126.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 C, 145.8ms
Speed: 3.9ms preprocess, 145.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 C, 137.0ms
Speed: 3.5ms preprocess, 137.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 C, 196.7ms
Speed: 4.7ms preprocess, 196.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 C, 227.0ms
Speed: 3.8ms preprocess, 227.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 C, 132.8ms
Speed: 3.3ms preprocess, 132.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 C, 1 O, 143.1ms
Speed: 3.9ms preprocess, 143.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 C, 1 O, 161.4ms
Speed: 4.7ms preprocess, 161.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 C, 1 O, 137.7ms
Speed: 3.6ms preprocess, 137.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)
Processed 30 frames...

0: 384x640 1 C, 1 O, 102.8ms
Speed: 3.1ms preprocess, 102.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 136.7ms
Speed: 3.2ms preprocess, 136.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 102.3ms
Speed: 3.0ms preprocess, 102.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 100.5ms
Speed: 3.1ms preprocess, 100.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 83.5ms
Speed: 2.8ms preprocess, 83.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 104.2ms
Speed: 3.3ms preprocess, 104.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 117.8ms
Speed: 3.6ms preprocess, 117.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 140.9ms
Speed: 3.5ms preprocess, 140.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 102.3ms
Speed: 3.3ms preprocess, 102.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 101.8ms
Speed: 3.4ms preprocess, 101.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 95.3ms
Speed: 3.2ms preprocess, 95.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 123.4ms
Speed: 3.2ms preprocess, 123.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 C, 1 O, 83.1ms
Speed: 3.1ms preprocess, 83.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 174.1ms
Speed: 3.8ms preprocess, 174.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 C, 1 O, 156.9ms
Speed: 3.6ms preprocess, 156.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 C, 1 O, 101.4ms
Speed: 3.4ms preprocess, 101.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 C, 1 O, 82.9ms
Speed: 2.9ms preprocess, 82.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 78.9ms
Speed: 3.0ms preprocess, 78.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 89.5ms
Speed: 3.5ms preprocess, 89.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 157.9ms
Speed: 4.2ms preprocess, 157.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 C, 1 O, 145.9ms
Speed: 4.5ms preprocess, 145.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 C, 1 O, 130.7ms
Speed: 3.8ms preprocess, 130.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 C, 1 O, 108.9ms
Speed: 4.1ms preprocess, 108.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 C, 1 O, 136.3ms
Speed: 4.2ms preprocess, 136.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 C, 1 O, 182.1ms
Speed: 3.8ms preprocess, 182.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 C, 1 O, 105.9ms
Speed: 3.4ms preprocess, 105.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 C, 1 O, 172.5ms
Speed: 4.2ms preprocess, 172.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 C, 1 O, 192.0ms
Speed: 3.3ms preprocess, 192.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 C, 1 O, 178.2ms
Speed: 4.1ms preprocess, 178.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 C, 1 O, 88.0ms
Speed: 3.3ms preprocess, 88.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)
Processed 60 frames...

0: 384x640 1 C, 1 O, 140.2ms
Speed: 3.4ms preprocess, 140.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 C, 1 O, 99.6ms
Speed: 5.1ms preprocess, 99.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 C, 1 O, 95.1ms
Speed: 3.0ms preprocess, 95.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 C, 1 O, 152.7ms
Speed: 3.5ms preprocess, 152.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 164.9ms
Speed: 3.9ms preprocess, 164.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 128.5ms
Speed: 3.6ms preprocess, 128.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 116.0ms
Speed: 3.6ms preprocess, 116.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 130.0ms
Speed: 3.6ms preprocess, 130.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 102.5ms
Speed: 3.3ms preprocess, 102.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 90.1ms
Speed: 3.4ms preprocess, 90.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 92.0ms
Speed: 3.9ms preprocess, 92.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 98.5ms
Speed: 3.4ms preprocess, 98.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 84.7ms
Speed: 3.2ms preprocess, 84.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 1 M, 82.0ms
Speed: 3.0ms preprocess, 82.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 99.0ms
Speed: 3.0ms preprocess, 99.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 1 M, 105.9ms
Speed: 3.7ms preprocess, 105.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 1 M, 97.9ms
Speed: 4.4ms preprocess, 97.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 1 M, 148.5ms
Speed: 3.6ms preprocess, 148.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 1 M, 92.8ms
Speed: 2.9ms preprocess, 92.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 1 M, 93.2ms
Speed: 3.6ms preprocess, 93.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 1 M, 148.2ms
Speed: 4.2ms preprocess, 148.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 1 M, 209.4ms
Speed: 3.3ms preprocess, 209.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 1 M, 144.7ms
Speed: 4.6ms preprocess, 144.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 1 M, 172.1ms
Speed: 10.0ms preprocess, 172.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 1 M, 166.8ms
Speed: 4.6ms preprocess, 166.8ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 1 M, 180.9ms
Speed: 4.5ms preprocess, 180.9ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 1 M, 98.9ms
Speed: 3.6ms preprocess, 98.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 1 M, 97.1ms
Speed: 4.5ms preprocess, 97.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 1 M, 88.9ms
Speed: 3.1ms preprocess, 88.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 108.5ms
Speed: 3.4ms preprocess, 108.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)
Processed 90 frames...

0: 384x640 1 A, 1 M, 86.5ms
Speed: 3.3ms preprocess, 86.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 1 M, 86.5ms
Speed: 3.5ms preprocess, 86.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 1 M, 123.1ms
Speed: 4.2ms preprocess, 123.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 1 M, 91.1ms
Speed: 3.2ms preprocess, 91.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 1 M, 89.0ms
Speed: 3.0ms preprocess, 89.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 87.6ms
Speed: 3.1ms preprocess, 87.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 117.7ms
Speed: 3.4ms preprocess, 117.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 117.8ms
Speed: 3.3ms preprocess, 117.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 196.4ms
Speed: 3.6ms preprocess, 196.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 84.0ms
Speed: 3.7ms preprocess, 84.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 118.8ms
Speed: 3.8ms preprocess, 118.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 91.8ms
Speed: 3.5ms preprocess, 91.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 126.3ms
Speed: 8.0ms preprocess, 126.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 89.8ms
Speed: 3.4ms preprocess, 89.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 B, 1 M, 90.7ms
Speed: 4.6ms preprocess, 90.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 1 M, 96.6ms
Speed: 3.3ms preprocess, 96.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 109.0ms
Speed: 3.3ms preprocess, 109.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 1 M, 109.3ms
Speed: 4.3ms preprocess, 109.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 92.0ms
Speed: 3.1ms preprocess, 92.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 87.3ms
Speed: 3.4ms preprocess, 87.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 91.3ms
Speed: 3.2ms preprocess, 91.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 86.2ms
Speed: 3.2ms preprocess, 86.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 87.5ms
Speed: 3.3ms preprocess, 87.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 83.9ms
Speed: 3.0ms preprocess, 83.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 89.6ms
Speed: 3.0ms preprocess, 89.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 88.4ms
Speed: 3.0ms preprocess, 88.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 85.5ms
Speed: 3.0ms preprocess, 85.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 84.1ms
Speed: 2.9ms preprocess, 84.1ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 83.7ms
Speed: 2.9ms preprocess, 83.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 87.3ms
Speed: 3.3ms preprocess, 87.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)
Processed 120 frames...

0: 384x640 1 M, 98.2ms
Speed: 3.3ms preprocess, 98.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 83.0ms
Speed: 2.9ms preprocess, 83.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 87.8ms
Speed: 3.0ms preprocess, 87.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 93.5ms
Speed: 2.9ms preprocess, 93.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 88.3ms
Speed: 2.8ms preprocess, 88.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 85.4ms
Speed: 3.0ms preprocess, 85.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 83.0ms
Speed: 3.1ms preprocess, 83.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 97.8ms
Speed: 3.2ms preprocess, 97.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 87.8ms
Speed: 2.8ms preprocess, 87.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 108.2ms
Speed: 3.3ms preprocess, 108.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 88.2ms
Speed: 3.1ms preprocess, 88.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 83.7ms
Speed: 3.0ms preprocess, 83.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 92.6ms
Speed: 3.3ms preprocess, 92.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 83.0ms
Speed: 2.9ms preprocess, 83.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 137.5ms
Speed: 3.0ms preprocess, 137.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 98.4ms
Speed: 3.1ms preprocess, 98.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 98.2ms
Speed: 3.3ms preprocess, 98.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 87.9ms
Speed: 3.2ms preprocess, 87.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 91.0ms
Speed: 3.0ms preprocess, 91.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 88.2ms
Speed: 3.3ms preprocess, 88.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 104.0ms
Speed: 3.4ms preprocess, 104.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 89.0ms
Speed: 2.8ms preprocess, 89.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 134.9ms
Speed: 6.3ms preprocess, 134.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 155.9ms
Speed: 3.2ms preprocess, 155.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 112.3ms
Speed: 3.3ms preprocess, 112.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 B, 84.5ms
Speed: 3.7ms preprocess, 84.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 83.5ms
Speed: 3.0ms preprocess, 83.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 305.9ms
Speed: 4.2ms preprocess, 305.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 234.8ms
Speed: 3.9ms preprocess, 234.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 152.5ms
Speed: 3.6ms preprocess, 152.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)
Processed 150 frames...

0: 384x640 1 M, 126.2ms
Speed: 3.6ms preprocess, 126.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 223.9ms
Speed: 3.8ms preprocess, 223.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 316.1ms
Speed: 6.9ms preprocess, 316.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 1 M, 206.2ms
Speed: 5.1ms preprocess, 206.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 211.7ms
Speed: 3.7ms preprocess, 211.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 1 M, 166.3ms
Speed: 4.4ms preprocess, 166.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 151.6ms
Speed: 3.7ms preprocess, 151.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 173.9ms
Speed: 7.5ms preprocess, 173.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 176.8ms
Speed: 3.4ms preprocess, 176.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 281.9ms
Speed: 4.2ms preprocess, 281.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 178.9ms
Speed: 5.1ms preprocess, 178.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 141.6ms
Speed: 3.8ms preprocess, 141.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 160.9ms
Speed: 38.2ms preprocess, 160.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 160.6ms
Speed: 4.3ms preprocess, 160.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 151.4ms
Speed: 4.1ms preprocess, 151.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 134.4ms
Speed: 3.7ms preprocess, 134.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 186.7ms
Speed: 18.1ms preprocess, 186.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 159.1ms
Speed: 3.8ms preprocess, 159.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 164.4ms
Speed: 3.7ms preprocess, 164.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 176.9ms
Speed: 3.9ms preprocess, 176.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 131.9ms
Speed: 4.8ms preprocess, 131.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 193.0ms
Speed: 5.5ms preprocess, 193.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 174.4ms
Speed: 4.2ms preprocess, 174.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 1 M, 91.3ms
Speed: 4.0ms preprocess, 91.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 1 M, 85.2ms
Speed: 2.8ms preprocess, 85.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 1 M, 94.1ms
Speed: 3.0ms preprocess, 94.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 1 M, 115.7ms
Speed: 3.6ms preprocess, 115.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 1 M, 88.3ms
Speed: 3.2ms preprocess, 88.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 1 M, 98.8ms
Speed: 4.7ms preprocess, 98.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 1 M, 88.4ms
Speed: 3.1ms preprocess, 88.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)
Processed 180 frames...

0: 384x640 1 E, 1 M, 84.0ms
Speed: 3.0ms preprocess, 84.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 99.3ms
Speed: 3.5ms preprocess, 99.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 96.7ms
Speed: 3.3ms preprocess, 96.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 113.5ms
Speed: 3.2ms preprocess, 113.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 134.5ms
Speed: 3.7ms preprocess, 134.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 84.4ms
Speed: 3.1ms preprocess, 84.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 130.2ms
Speed: 3.4ms preprocess, 130.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 120.0ms
Speed: 4.0ms preprocess, 120.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 131.9ms
Speed: 6.0ms preprocess, 131.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 111.0ms
Speed: 3.5ms preprocess, 111.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 117.4ms
Speed: 4.7ms preprocess, 117.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 144.5ms
Speed: 3.8ms preprocess, 144.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 112.6ms
Speed: 3.6ms preprocess, 112.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 101.2ms
Speed: 3.5ms preprocess, 101.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 94.4ms
Speed: 3.1ms preprocess, 94.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 U, 115.3ms
Speed: 3.2ms preprocess, 115.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 U, 101.9ms
Speed: 3.7ms preprocess, 101.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 U, 98.8ms
Speed: 3.3ms preprocess, 98.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 U, 104.7ms
Speed: 4.5ms preprocess, 104.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 R, 1 U, 128.3ms
Speed: 3.7ms preprocess, 128.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 R, 107.3ms
Speed: 3.5ms preprocess, 107.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 K, 124.2ms
Speed: 3.5ms preprocess, 124.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 K, 105.5ms
Speed: 3.8ms preprocess, 105.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 R, 98.8ms
Speed: 3.1ms preprocess, 98.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 R, 95.4ms
Speed: 3.8ms preprocess, 95.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 R, 98.9ms
Speed: 3.4ms preprocess, 98.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 R, 100.2ms
Speed: 4.0ms preprocess, 100.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 R, 113.9ms
Speed: 3.4ms preprocess, 113.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 R, 137.5ms
Speed: 3.6ms preprocess, 137.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 R, 93.2ms
Speed: 3.5ms preprocess, 93.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)
Processed 210 frames...

0: 384x640 1 R, 152.2ms
Speed: 4.0ms preprocess, 152.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 K, 132.2ms
Speed: 3.5ms preprocess, 132.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 K, 107.8ms
Speed: 4.0ms preprocess, 107.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 R, 93.8ms
Speed: 3.6ms preprocess, 93.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 85.1ms
Speed: 3.1ms preprocess, 85.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 91.9ms
Speed: 3.2ms preprocess, 91.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 R, 91.4ms
Speed: 3.0ms preprocess, 91.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 R, 95.6ms
Speed: 3.5ms preprocess, 95.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 R, 89.3ms
Speed: 3.1ms preprocess, 89.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 R, 85.5ms
Speed: 3.7ms preprocess, 85.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 119.4ms
Speed: 3.6ms preprocess, 119.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 R, 110.0ms
Speed: 3.6ms preprocess, 110.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 R, 90.8ms
Speed: 3.4ms preprocess, 90.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 146.5ms
Speed: 4.4ms preprocess, 146.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 123.0ms
Speed: 3.5ms preprocess, 123.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 R, 113.3ms
Speed: 3.4ms preprocess, 113.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 R, 139.0ms
Speed: 3.6ms preprocess, 139.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 148.1ms
Speed: 4.1ms preprocess, 148.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 101.0ms
Speed: 3.9ms preprocess, 101.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 123.2ms
Speed: 3.4ms preprocess, 123.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 U, 211.7ms
Speed: 4.1ms preprocess, 211.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 U, 98.3ms
Speed: 3.8ms preprocess, 98.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 122.0ms
Speed: 4.3ms preprocess, 122.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 F, 113.8ms
Speed: 3.0ms preprocess, 113.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 F, 114.4ms
Speed: 4.4ms preprocess, 114.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 90.7ms
Speed: 3.4ms preprocess, 90.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 100.0ms
Speed: 3.7ms preprocess, 100.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 92.1ms
Speed: 3.6ms preprocess, 92.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 88.3ms
Speed: 3.3ms preprocess, 88.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 1 M, 107.3ms
Speed: 3.7ms preprocess, 107.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)
Processed 240 frames...

0: 384x640 1 A, 119.5ms
Speed: 3.2ms preprocess, 119.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 133.8ms
Speed: 4.0ms preprocess, 133.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 99.2ms
Speed: 4.0ms preprocess, 99.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 115.2ms
Speed: 3.8ms preprocess, 115.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 85.6ms
Speed: 3.1ms preprocess, 85.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 88.6ms
Speed: 3.1ms preprocess, 88.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 137.4ms
Speed: 5.8ms preprocess, 137.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 94.2ms
Speed: 3.4ms preprocess, 94.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 102.3ms
Speed: 3.5ms preprocess, 102.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 96.5ms
Speed: 3.3ms preprocess, 96.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 88.7ms
Speed: 3.2ms preprocess, 88.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 91.8ms
Speed: 3.1ms preprocess, 91.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 87.7ms
Speed: 3.0ms preprocess, 87.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 86.9ms
Speed: 3.0ms preprocess, 86.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 87.9ms
Speed: 3.5ms preprocess, 87.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 89.4ms
Speed: 2.9ms preprocess, 89.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 87.6ms
Speed: 2.8ms preprocess, 87.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 117.7ms
Speed: 3.6ms preprocess, 117.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 86.8ms
Speed: 3.2ms preprocess, 86.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 89.3ms
Speed: 3.3ms preprocess, 89.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 87.7ms
Speed: 3.0ms preprocess, 87.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 149.4ms
Speed: 3.7ms preprocess, 149.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 178.3ms
Speed: 3.6ms preprocess, 178.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 117.1ms
Speed: 3.7ms preprocess, 117.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 114.1ms
Speed: 4.3ms preprocess, 114.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 130.4ms
Speed: 3.7ms preprocess, 130.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 154.0ms
Speed: 4.3ms preprocess, 154.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 103.2ms
Speed: 3.8ms preprocess, 103.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 223.7ms
Speed: 7.6ms preprocess, 223.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 147.9ms
Speed: 4.6ms preprocess, 147.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)
Processed 270 frames...

0: 384x640 1 A, 107.8ms
Speed: 3.8ms preprocess, 107.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 94.9ms
Speed: 3.2ms preprocess, 94.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 131.1ms
Speed: 3.2ms preprocess, 131.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 119.8ms
Speed: 4.5ms preprocess, 119.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 155.4ms
Speed: 3.6ms preprocess, 155.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 97.9ms
Speed: 3.2ms preprocess, 97.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 86.3ms
Speed: 2.8ms preprocess, 86.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 110.0ms
Speed: 4.0ms preprocess, 110.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 89.0ms
Speed: 3.1ms preprocess, 89.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 88.6ms
Speed: 2.9ms preprocess, 88.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 112.8ms
Speed: 3.4ms preprocess, 112.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 142.2ms
Speed: 4.3ms preprocess, 142.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 157.8ms
Speed: 3.1ms preprocess, 157.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)

============================================================
SIDE-BY-SIDE COMPARISON RESULTS
============================================================
Ground Truth (from video name): &#39;CAMERA&#39;
Output video: video_results\Camera_comparison.mp4
Total frames: 283

YOLOv8n:
  Frames with detections: 244
  Reconstructed sequence: &#39;COMAMMMEURA&#39;
  Sequence length: 11 letters
  Character Accuracy: 54.5%
  Edit Distance: 5 operations

YOLOv8s:
  Frames with detections: 215
  Reconstructed sequence: &#39;CMMMEXA&#39;
  Sequence length: 7 letters
  Character Accuracy: 57.1%
  Edit Distance: 3 operations

Sequences match: False
✓ YOLOv8s outperforms YOLOv8n by 2.6 percentage points

YOLOv8n detection frequency:
  M: 75 frames (26.5%)
  A: 58 frames (20.5%)
  O: 34 frames (12.0%)
  E: 32 frames (11.3%)
  R: 18 frames (6.4%)

YOLOv8s detection frequency:
  M: 82 frames (29.0%)
  A: 46 frames (16.3%)
  C: 34 frames (12.0%)
  E: 34 frames (12.0%)
  X: 6 frames (2.1%)
============================================================
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Detailed evaluation report</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="s2">&quot;=&quot;</span><span class="o">*</span><span class="mi">60</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;DETAILED EVALUATION REPORT&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span><span class="o">*</span><span class="mi">60</span><span class="p">)</span>

<span class="n">evaluate_prediction</span><span class="p">(</span><span class="n">seq_n</span><span class="p">,</span> <span class="n">ground_truth</span><span class="p">,</span> <span class="s2">&quot;YOLOv8n&quot;</span><span class="p">)</span>
<span class="n">evaluate_prediction</span><span class="p">(</span><span class="n">seq_s</span><span class="p">,</span> <span class="n">ground_truth</span><span class="p">,</span> <span class="s2">&quot;YOLOv8s&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>============================================================
DETAILED EVALUATION REPORT
============================================================

============================================================
YOLOv8n EVALUATION
============================================================
Ground Truth:  &#39;CAMERA&#39;
Predicted:     &#39;COMAMMMEURA&#39;

Metrics:
  Exact Match:           ✗ NO
  Edit Distance:         5 operations
  Character Accuracy:    54.5%
  Character Error Rate:  83.3%
  Word Error Rate:       83.3%
  Subsequence Accuracy:  100.0%
============================================================

============================================================
YOLOv8s EVALUATION
============================================================
Ground Truth:  &#39;CAMERA&#39;
Predicted:     &#39;CMMMEXA&#39;

Metrics:
  Exact Match:           ✗ NO
  Edit Distance:         3 operations
  Character Accuracy:    57.1%
  Character Error Rate:  50.0%
  Word Error Rate:       50.0%
  Subsequence Accuracy:  33.3%
============================================================
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;exact_match&#39;: False,
 &#39;edit_distance&#39;: 3,
 &#39;character_accuracy&#39;: 57.14285714285714,
 &#39;wer&#39;: 50.0,
 &#39;cer&#39;: 50.0,
 &#39;subsequence_accuracy&#39;: 33.33333333333333}
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Final comparison summary</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="si">{</span><span class="s1">&#39;=&#39;</span><span class="o">*</span><span class="mi">60</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;FINAL MODEL COMPARISON&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="s1">&#39;=&#39;</span><span class="o">*</span><span class="mi">60</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Ground Truth: &#39;</span><span class="si">{</span><span class="n">ground_truth</span><span class="si">}</span><span class="s2">&#39;&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">YOLOv8n: &#39;</span><span class="si">{</span><span class="n">seq_n</span><span class="si">}</span><span class="s2">&#39; - Character Accuracy: </span><span class="si">{</span><span class="n">metrics_n</span><span class="p">[</span><span class="s1">&#39;character_accuracy&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;YOLOv8s: &#39;</span><span class="si">{</span><span class="n">seq_s</span><span class="si">}</span><span class="s2">&#39; - Character Accuracy: </span><span class="si">{</span><span class="n">metrics_s</span><span class="p">[</span><span class="s1">&#39;character_accuracy&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>

<span class="k">if</span> <span class="n">metrics_s</span><span class="p">[</span><span class="s1">&#39;character_accuracy&#39;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">metrics_n</span><span class="p">[</span><span class="s1">&#39;character_accuracy&#39;</span><span class="p">]:</span>
    <span class="n">improvement</span> <span class="o">=</span> <span class="n">metrics_s</span><span class="p">[</span><span class="s1">&#39;character_accuracy&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">metrics_n</span><span class="p">[</span><span class="s1">&#39;character_accuracy&#39;</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">✓ YOLOv8s is the better model with </span><span class="si">{</span><span class="n">improvement</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2"> percentage point improvement&quot;</span><span class="p">)</span>
<span class="k">elif</span> <span class="n">metrics_n</span><span class="p">[</span><span class="s1">&#39;character_accuracy&#39;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">metrics_s</span><span class="p">[</span><span class="s1">&#39;character_accuracy&#39;</span><span class="p">]:</span>
    <span class="n">difference</span> <span class="o">=</span> <span class="n">metrics_n</span><span class="p">[</span><span class="s1">&#39;character_accuracy&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">metrics_s</span><span class="p">[</span><span class="s1">&#39;character_accuracy&#39;</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">✓ YOLOv8n is the better model with </span><span class="si">{</span><span class="n">difference</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2"> percentage point improvement&quot;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">= Both models perform equally&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="s1">&#39;=&#39;</span><span class="o">*</span><span class="mi">60</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>============================================================
FINAL MODEL COMPARISON
============================================================
Ground Truth: &#39;CAMERA&#39;

YOLOv8n: &#39;COMAMMMEURA&#39; - Character Accuracy: 54.5%
YOLOv8s: &#39;CMMMEXA&#39; - Character Accuracy: 57.1%

✓ YOLOv8s is the better model with 2.6 percentage point improvement
============================================================
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">create_gradcam_video</span><span class="p">(</span><span class="n">model_s</span><span class="p">,</span> <span class="n">video_path</span><span class="p">,</span> <span class="n">output_dir</span><span class="p">,</span> <span class="n">vid_name</span><span class="p">,</span> <span class="n">use_simple</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Video rotation metadata: 0.0 degrees
Creating attention visualization...
Processed 30 frames...
Processed 60 frames...
Processed 90 frames...
Processed 120 frames...
Processed 150 frames...
Processed 180 frames...
Processed 210 frames...
Processed 240 frames...
Processed 270 frames...

Grad-CAM visualization saved to: video_results\Camera_gradcam.mp4
Total frames: 283
</pre></div>
</div>
</div>
</div>
</section>
<section id="travel">
<h3>Travel<a class="headerlink" href="#travel" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># --- Paths ---</span>
<span class="n">video_path</span> <span class="o">=</span> <span class="s2">&quot;videos/Travel1.mov&quot;</span>
<span class="n">vid_name</span> <span class="o">=</span> <span class="s2">&quot;Travel1&quot;</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create side-by-side comparison</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Creating side-by-side comparison video...&quot;</span><span class="p">)</span>
<span class="n">seq_n</span><span class="p">,</span> <span class="n">seq_s</span><span class="p">,</span> <span class="n">stats_n</span><span class="p">,</span> <span class="n">stats_s</span><span class="p">,</span> <span class="n">metrics_n</span><span class="p">,</span> <span class="n">metrics_s</span><span class="p">,</span> <span class="n">ground_truth</span> <span class="o">=</span> <span class="n">create_side_by_side_comparison</span><span class="p">(</span>
    <span class="n">model_n</span><span class="p">,</span> <span class="n">model_s</span><span class="p">,</span> <span class="n">video_path</span><span class="p">,</span> <span class="n">output_dir</span><span class="p">,</span> <span class="n">vid_name</span><span class="p">,</span>
    <span class="n">conf_threshold</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">stability_threshold</span><span class="o">=</span><span class="mi">5</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Creating side-by-side comparison video...
Video rotation metadata: 180.0 degrees
Processing frames for side-by-side comparison...

0: 384x640 (no detections), 98.6ms
Speed: 6.0ms preprocess, 98.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 87.8ms
Speed: 3.1ms preprocess, 87.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 T, 86.0ms
Speed: 2.9ms preprocess, 86.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 T, 87.6ms
Speed: 2.8ms preprocess, 87.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 T, 87.0ms
Speed: 2.9ms preprocess, 87.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 T, 81.2ms
Speed: 2.9ms preprocess, 81.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 T, 82.2ms
Speed: 2.9ms preprocess, 82.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 N, 1 T, 81.0ms
Speed: 2.9ms preprocess, 81.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 N, 1 T, 89.4ms
Speed: 2.9ms preprocess, 89.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 T, 82.3ms
Speed: 2.8ms preprocess, 82.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 T, 85.1ms
Speed: 4.1ms preprocess, 85.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 T, 87.9ms
Speed: 3.5ms preprocess, 87.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 N, 1 T, 87.0ms
Speed: 2.7ms preprocess, 87.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 T, 84.9ms
Speed: 3.0ms preprocess, 84.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 N, 1 T, 82.7ms
Speed: 2.9ms preprocess, 82.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 N, 1 T, 84.5ms
Speed: 2.9ms preprocess, 84.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 N, 1 T, 109.3ms
Speed: 3.7ms preprocess, 109.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 N, 1 T, 96.2ms
Speed: 2.9ms preprocess, 96.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 N, 1 T, 83.4ms
Speed: 2.9ms preprocess, 83.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 81.8ms
Speed: 3.0ms preprocess, 81.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 T, 90.3ms
Speed: 2.9ms preprocess, 90.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 N, 1 T, 94.0ms
Speed: 4.1ms preprocess, 94.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 N, 1 T, 97.8ms
Speed: 3.1ms preprocess, 97.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 N, 1 T, 96.1ms
Speed: 3.2ms preprocess, 96.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 N, 1 T, 96.8ms
Speed: 3.5ms preprocess, 96.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 T, 111.1ms
Speed: 4.1ms preprocess, 111.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 N, 1 T, 138.2ms
Speed: 4.7ms preprocess, 138.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 N, 1 T, 92.5ms
Speed: 3.3ms preprocess, 92.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 N, 1 T, 87.8ms
Speed: 2.9ms preprocess, 87.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 N, 1 T, 88.1ms
Speed: 3.0ms preprocess, 88.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)
Processed 30 frames...

0: 384x640 1 N, 1 T, 84.2ms
Speed: 3.1ms preprocess, 84.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 T, 83.3ms
Speed: 3.2ms preprocess, 83.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 N, 1 T, 86.8ms
Speed: 3.0ms preprocess, 86.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 T, 99.0ms
Speed: 3.1ms preprocess, 99.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 T, 90.1ms
Speed: 3.0ms preprocess, 90.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 T, 85.1ms
Speed: 3.0ms preprocess, 85.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 N, 1 T, 88.3ms
Speed: 3.1ms preprocess, 88.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 N, 1 T, 85.6ms
Speed: 2.9ms preprocess, 85.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 T, 89.3ms
Speed: 3.0ms preprocess, 89.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 T, 84.7ms
Speed: 3.1ms preprocess, 84.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 T, 89.5ms
Speed: 3.3ms preprocess, 89.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 T, 86.1ms
Speed: 3.0ms preprocess, 86.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 T, 89.5ms
Speed: 3.0ms preprocess, 89.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 T, 85.7ms
Speed: 3.1ms preprocess, 85.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 T, 151.4ms
Speed: 3.3ms preprocess, 151.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 T, 124.3ms
Speed: 3.0ms preprocess, 124.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 N, 1 T, 142.1ms
Speed: 7.9ms preprocess, 142.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 T, 104.2ms
Speed: 3.8ms preprocess, 104.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 T, 96.0ms
Speed: 3.1ms preprocess, 96.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 T, 88.5ms
Speed: 3.0ms preprocess, 88.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 84.1ms
Speed: 3.1ms preprocess, 84.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 84.7ms
Speed: 3.1ms preprocess, 84.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 T, 87.5ms
Speed: 3.1ms preprocess, 87.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 88.6ms
Speed: 3.0ms preprocess, 88.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 84.1ms
Speed: 3.0ms preprocess, 84.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 K, 84.6ms
Speed: 3.1ms preprocess, 84.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 K, 87.6ms
Speed: 3.0ms preprocess, 87.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 K, 85.9ms
Speed: 3.0ms preprocess, 85.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 K, 86.7ms
Speed: 3.1ms preprocess, 86.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 K, 88.0ms
Speed: 3.1ms preprocess, 88.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)
Processed 60 frames...

0: 384x640 (no detections), 86.8ms
Speed: 3.0ms preprocess, 86.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 85.9ms
Speed: 4.3ms preprocess, 85.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 U, 85.2ms
Speed: 3.2ms preprocess, 85.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 94.4ms
Speed: 2.9ms preprocess, 94.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 K, 1 P, 87.0ms
Speed: 3.0ms preprocess, 87.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 K, 1 P, 85.2ms
Speed: 3.1ms preprocess, 85.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 K, 85.1ms
Speed: 3.1ms preprocess, 85.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 P, 85.1ms
Speed: 3.1ms preprocess, 85.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 K, 1 P, 86.8ms
Speed: 3.0ms preprocess, 86.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 K, 90.8ms
Speed: 2.9ms preprocess, 90.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 K, 86.4ms
Speed: 3.4ms preprocess, 86.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 K, 89.9ms
Speed: 3.5ms preprocess, 89.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 K, 102.5ms
Speed: 3.7ms preprocess, 102.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 K, 86.8ms
Speed: 3.0ms preprocess, 86.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 K, 1 R, 94.1ms
Speed: 3.3ms preprocess, 94.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 R, 107.1ms
Speed: 3.5ms preprocess, 107.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 K, 87.0ms
Speed: 3.1ms preprocess, 87.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 87.3ms
Speed: 3.9ms preprocess, 87.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 84.0ms
Speed: 3.1ms preprocess, 84.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 84.2ms
Speed: 3.1ms preprocess, 84.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 87.8ms
Speed: 3.2ms preprocess, 87.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 R, 86.4ms
Speed: 3.2ms preprocess, 86.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 K, 93.7ms
Speed: 3.1ms preprocess, 93.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 K, 93.5ms
Speed: 3.6ms preprocess, 93.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 K, 92.2ms
Speed: 3.6ms preprocess, 92.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 K, 88.1ms
Speed: 3.1ms preprocess, 88.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 K, 150.4ms
Speed: 3.1ms preprocess, 150.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 83.7ms
Speed: 3.1ms preprocess, 83.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 104.8ms
Speed: 3.1ms preprocess, 104.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 99.5ms
Speed: 3.7ms preprocess, 99.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)
Processed 90 frames...

0: 384x640 (no detections), 88.4ms
Speed: 3.1ms preprocess, 88.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 K, 85.3ms
Speed: 3.4ms preprocess, 85.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 87.5ms
Speed: 2.9ms preprocess, 87.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 R, 151.3ms
Speed: 5.5ms preprocess, 151.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 R, 98.0ms
Speed: 3.6ms preprocess, 98.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 R, 87.1ms
Speed: 3.0ms preprocess, 87.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 88.0ms
Speed: 3.0ms preprocess, 88.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 R, 87.2ms
Speed: 3.0ms preprocess, 87.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 R, 86.6ms
Speed: 3.1ms preprocess, 86.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 86.2ms
Speed: 3.0ms preprocess, 86.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 86.8ms
Speed: 3.0ms preprocess, 86.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 K, 86.9ms
Speed: 3.1ms preprocess, 86.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 R, 88.9ms
Speed: 3.1ms preprocess, 88.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 R, 84.9ms
Speed: 3.0ms preprocess, 84.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 R, 87.6ms
Speed: 3.1ms preprocess, 87.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 R, 87.4ms
Speed: 3.3ms preprocess, 87.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 R, 84.4ms
Speed: 3.1ms preprocess, 84.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 K, 86.1ms
Speed: 3.1ms preprocess, 86.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 K, 87.8ms
Speed: 2.9ms preprocess, 87.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 K, 88.2ms
Speed: 3.1ms preprocess, 88.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 88.3ms
Speed: 3.1ms preprocess, 88.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 84.7ms
Speed: 3.5ms preprocess, 84.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 90.6ms
Speed: 2.9ms preprocess, 90.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 96.4ms
Speed: 3.0ms preprocess, 96.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 100.3ms
Speed: 3.4ms preprocess, 100.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 95.1ms
Speed: 3.4ms preprocess, 95.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 90.0ms
Speed: 2.9ms preprocess, 90.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 88.4ms
Speed: 3.1ms preprocess, 88.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 87.1ms
Speed: 3.1ms preprocess, 87.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 87.1ms
Speed: 3.2ms preprocess, 87.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)
Processed 120 frames...

0: 384x640 (no detections), 86.2ms
Speed: 3.1ms preprocess, 86.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 87.5ms
Speed: 3.0ms preprocess, 87.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 85.6ms
Speed: 3.2ms preprocess, 85.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 84.8ms
Speed: 3.0ms preprocess, 84.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 98.3ms
Speed: 2.9ms preprocess, 98.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 87.3ms
Speed: 3.0ms preprocess, 87.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 84.5ms
Speed: 3.0ms preprocess, 84.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 85.6ms
Speed: 3.1ms preprocess, 85.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 89.5ms
Speed: 3.4ms preprocess, 89.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 88.7ms
Speed: 3.1ms preprocess, 88.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 85.7ms
Speed: 3.4ms preprocess, 85.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 92.1ms
Speed: 3.4ms preprocess, 92.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 88.0ms
Speed: 3.0ms preprocess, 88.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 86.7ms
Speed: 3.1ms preprocess, 86.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 83.5ms
Speed: 3.1ms preprocess, 83.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 160.4ms
Speed: 3.2ms preprocess, 160.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 87.5ms
Speed: 3.0ms preprocess, 87.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 87.9ms
Speed: 3.1ms preprocess, 87.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 86.7ms
Speed: 3.0ms preprocess, 86.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 85.6ms
Speed: 2.9ms preprocess, 85.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 88.9ms
Speed: 3.4ms preprocess, 88.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 87.6ms
Speed: 3.2ms preprocess, 87.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 83.6ms
Speed: 3.1ms preprocess, 83.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 85.8ms
Speed: 3.0ms preprocess, 85.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 87.8ms
Speed: 3.0ms preprocess, 87.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 87.5ms
Speed: 3.0ms preprocess, 87.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 88.8ms
Speed: 3.0ms preprocess, 88.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 85.8ms
Speed: 2.9ms preprocess, 85.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 90.9ms
Speed: 3.2ms preprocess, 90.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 88.2ms
Speed: 3.0ms preprocess, 88.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)
Processed 150 frames...

0: 384x640 (no detections), 86.2ms
Speed: 3.3ms preprocess, 86.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 85.2ms
Speed: 3.1ms preprocess, 85.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 89.8ms
Speed: 3.2ms preprocess, 89.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 88.8ms
Speed: 3.1ms preprocess, 88.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 T, 85.7ms
Speed: 3.0ms preprocess, 85.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 T, 88.4ms
Speed: 3.0ms preprocess, 88.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 87.0ms
Speed: 3.0ms preprocess, 87.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 88.5ms
Speed: 3.0ms preprocess, 88.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 T, 97.1ms
Speed: 3.3ms preprocess, 97.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 87.0ms
Speed: 3.0ms preprocess, 87.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 87.8ms
Speed: 3.0ms preprocess, 87.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 88.8ms
Speed: 3.5ms preprocess, 88.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 87.4ms
Speed: 3.2ms preprocess, 87.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 89.7ms
Speed: 2.9ms preprocess, 89.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 88.4ms
Speed: 3.0ms preprocess, 88.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 88.8ms
Speed: 3.0ms preprocess, 88.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 86.5ms
Speed: 3.2ms preprocess, 86.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 84.7ms
Speed: 3.4ms preprocess, 84.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 92.3ms
Speed: 2.9ms preprocess, 92.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 89.3ms
Speed: 3.0ms preprocess, 89.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 86.7ms
Speed: 3.2ms preprocess, 86.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 85.4ms
Speed: 3.1ms preprocess, 85.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 88.1ms
Speed: 3.0ms preprocess, 88.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 K, 99.1ms
Speed: 3.0ms preprocess, 99.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 K, 85.1ms
Speed: 3.3ms preprocess, 85.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 85.0ms
Speed: 3.4ms preprocess, 85.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 K, 88.8ms
Speed: 2.9ms preprocess, 88.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 K, 89.2ms
Speed: 3.0ms preprocess, 89.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 84.9ms
Speed: 3.2ms preprocess, 84.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 86.6ms
Speed: 3.0ms preprocess, 86.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)
Processed 180 frames...

0: 384x640 (no detections), 89.6ms
Speed: 3.0ms preprocess, 89.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 V, 89.8ms
Speed: 3.1ms preprocess, 89.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 V, 86.1ms
Speed: 3.0ms preprocess, 86.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 V, 84.5ms
Speed: 3.1ms preprocess, 84.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 V, 89.0ms
Speed: 3.0ms preprocess, 89.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 V, 88.4ms
Speed: 3.1ms preprocess, 88.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 V, 85.7ms
Speed: 3.0ms preprocess, 85.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 V, 83.8ms
Speed: 3.3ms preprocess, 83.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 V, 88.6ms
Speed: 2.9ms preprocess, 88.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 V, 88.5ms
Speed: 3.1ms preprocess, 88.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 V, 83.8ms
Speed: 3.5ms preprocess, 83.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 V, 85.9ms
Speed: 3.1ms preprocess, 85.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 V, 87.3ms
Speed: 2.9ms preprocess, 87.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 V, 88.7ms
Speed: 2.9ms preprocess, 88.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 V, 84.7ms
Speed: 3.1ms preprocess, 84.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 V, 84.8ms
Speed: 3.5ms preprocess, 84.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 V, 102.9ms
Speed: 4.2ms preprocess, 102.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 V, 89.0ms
Speed: 3.0ms preprocess, 89.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 V, 86.4ms
Speed: 3.1ms preprocess, 86.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 V, 86.9ms
Speed: 3.1ms preprocess, 86.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 V, 90.5ms
Speed: 3.2ms preprocess, 90.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 V, 99.9ms
Speed: 2.9ms preprocess, 99.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 V, 84.6ms
Speed: 3.1ms preprocess, 84.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 V, 86.2ms
Speed: 3.2ms preprocess, 86.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 V, 88.2ms
Speed: 3.0ms preprocess, 88.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 V, 91.1ms
Speed: 3.2ms preprocess, 91.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 V, 86.7ms
Speed: 3.1ms preprocess, 86.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 V, 96.9ms
Speed: 3.2ms preprocess, 96.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 V, 88.2ms
Speed: 3.0ms preprocess, 88.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 V, 90.8ms
Speed: 3.0ms preprocess, 90.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)
Processed 210 frames...

0: 384x640 1 V, 86.3ms
Speed: 3.0ms preprocess, 86.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 V, 87.5ms
Speed: 3.0ms preprocess, 87.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 V, 88.5ms
Speed: 2.9ms preprocess, 88.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 V, 102.9ms
Speed: 3.2ms preprocess, 102.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 V, 87.1ms
Speed: 3.1ms preprocess, 87.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 V, 86.1ms
Speed: 3.0ms preprocess, 86.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 V, 106.1ms
Speed: 3.8ms preprocess, 106.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 V, 88.6ms
Speed: 3.0ms preprocess, 88.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 V, 85.4ms
Speed: 3.8ms preprocess, 85.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 V, 86.1ms
Speed: 3.2ms preprocess, 86.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 V, 90.1ms
Speed: 3.0ms preprocess, 90.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 88.6ms
Speed: 3.1ms preprocess, 88.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 86.1ms
Speed: 3.0ms preprocess, 86.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 94.4ms
Speed: 3.5ms preprocess, 94.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 87.7ms
Speed: 3.2ms preprocess, 87.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 88.5ms
Speed: 3.1ms preprocess, 88.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 85.4ms
Speed: 3.3ms preprocess, 85.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 86.6ms
Speed: 3.0ms preprocess, 86.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 89.8ms
Speed: 3.0ms preprocess, 89.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 90.1ms
Speed: 2.9ms preprocess, 90.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 86.1ms
Speed: 3.0ms preprocess, 86.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 86.3ms
Speed: 3.1ms preprocess, 86.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 89.4ms
Speed: 3.0ms preprocess, 89.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 89.9ms
Speed: 3.1ms preprocess, 89.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 86.2ms
Speed: 3.1ms preprocess, 86.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 1 M, 85.8ms
Speed: 3.0ms preprocess, 85.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 89.9ms
Speed: 3.1ms preprocess, 89.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 90.1ms
Speed: 3.0ms preprocess, 90.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 93.1ms
Speed: 3.1ms preprocess, 93.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 1 M, 87.1ms
Speed: 3.6ms preprocess, 87.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)
Processed 240 frames...

0: 384x640 1 M, 90.0ms
Speed: 3.4ms preprocess, 90.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 92.9ms
Speed: 3.6ms preprocess, 92.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 90.9ms
Speed: 3.7ms preprocess, 90.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 87.8ms
Speed: 3.1ms preprocess, 87.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 90.3ms
Speed: 3.1ms preprocess, 90.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 90.6ms
Speed: 3.1ms preprocess, 90.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 89.0ms
Speed: 3.1ms preprocess, 89.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 88.8ms
Speed: 3.1ms preprocess, 88.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 111.7ms
Speed: 3.4ms preprocess, 111.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 90.7ms
Speed: 3.3ms preprocess, 90.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 94.4ms
Speed: 3.2ms preprocess, 94.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 96.4ms
Speed: 3.4ms preprocess, 96.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 92.2ms
Speed: 3.0ms preprocess, 92.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 90.0ms
Speed: 3.3ms preprocess, 90.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 87.4ms
Speed: 3.3ms preprocess, 87.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 105.9ms
Speed: 3.1ms preprocess, 105.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 94.0ms
Speed: 3.1ms preprocess, 94.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 100.8ms
Speed: 3.1ms preprocess, 100.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 88.2ms
Speed: 3.1ms preprocess, 88.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 88.7ms
Speed: 3.2ms preprocess, 88.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 92.4ms
Speed: 3.1ms preprocess, 92.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 127.4ms
Speed: 3.5ms preprocess, 127.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 90.4ms
Speed: 3.2ms preprocess, 90.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 88.6ms
Speed: 3.1ms preprocess, 88.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 1 M, 92.8ms
Speed: 3.1ms preprocess, 92.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 92.2ms
Speed: 3.7ms preprocess, 92.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 88.9ms
Speed: 3.3ms preprocess, 88.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 90.8ms
Speed: 3.2ms preprocess, 90.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 91.2ms
Speed: 3.3ms preprocess, 91.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 91.6ms
Speed: 3.3ms preprocess, 91.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)
Processed 270 frames...

0: 384x640 1 M, 89.7ms
Speed: 3.1ms preprocess, 89.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 89.4ms
Speed: 3.1ms preprocess, 89.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 92.4ms
Speed: 3.1ms preprocess, 92.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 92.4ms
Speed: 3.1ms preprocess, 92.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 88.4ms
Speed: 3.5ms preprocess, 88.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 90.2ms
Speed: 3.2ms preprocess, 90.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 1 M, 111.9ms
Speed: 3.6ms preprocess, 111.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 1 M, 92.1ms
Speed: 3.5ms preprocess, 92.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 90.2ms
Speed: 3.2ms preprocess, 90.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 88.5ms
Speed: 3.1ms preprocess, 88.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 92.8ms
Speed: 3.1ms preprocess, 92.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 94.5ms
Speed: 3.2ms preprocess, 94.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 88.5ms
Speed: 3.2ms preprocess, 88.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 K, 89.5ms
Speed: 3.2ms preprocess, 89.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 92.6ms
Speed: 3.2ms preprocess, 92.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 92.1ms
Speed: 3.1ms preprocess, 92.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 89.6ms
Speed: 3.2ms preprocess, 89.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 87.7ms
Speed: 3.2ms preprocess, 87.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 106.5ms
Speed: 3.2ms preprocess, 106.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 92.2ms
Speed: 3.2ms preprocess, 92.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 87.5ms
Speed: 3.3ms preprocess, 87.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 90.6ms
Speed: 3.4ms preprocess, 90.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 97.2ms
Speed: 3.2ms preprocess, 97.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 92.7ms
Speed: 3.4ms preprocess, 92.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 87.9ms
Speed: 3.3ms preprocess, 87.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 89.4ms
Speed: 3.2ms preprocess, 89.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 94.9ms
Speed: 3.2ms preprocess, 94.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 95.7ms
Speed: 3.2ms preprocess, 95.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 86.7ms
Speed: 3.2ms preprocess, 86.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 88.4ms
Speed: 3.1ms preprocess, 88.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)
Processed 300 frames...

0: 384x640 1 L, 92.4ms
Speed: 3.1ms preprocess, 92.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 92.8ms
Speed: 3.1ms preprocess, 92.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 92.3ms
Speed: 3.2ms preprocess, 92.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 88.8ms
Speed: 3.2ms preprocess, 88.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 93.9ms
Speed: 3.1ms preprocess, 93.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 91.3ms
Speed: 3.2ms preprocess, 91.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 87.0ms
Speed: 3.1ms preprocess, 87.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 90.0ms
Speed: 3.1ms preprocess, 90.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 101.7ms
Speed: 3.2ms preprocess, 101.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 92.6ms
Speed: 3.0ms preprocess, 92.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 89.8ms
Speed: 3.4ms preprocess, 89.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 87.6ms
Speed: 3.2ms preprocess, 87.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 92.5ms
Speed: 3.1ms preprocess, 92.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 96.5ms
Speed: 3.1ms preprocess, 96.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 88.2ms
Speed: 3.1ms preprocess, 88.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 89.9ms
Speed: 3.2ms preprocess, 89.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 97.6ms
Speed: 3.2ms preprocess, 97.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 102.3ms
Speed: 4.6ms preprocess, 102.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 88.5ms
Speed: 3.3ms preprocess, 88.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 87.9ms
Speed: 3.2ms preprocess, 87.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 90.7ms
Speed: 3.3ms preprocess, 90.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 92.3ms
Speed: 3.1ms preprocess, 92.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 88.9ms
Speed: 2.8ms preprocess, 88.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 86.3ms
Speed: 3.1ms preprocess, 86.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 87.3ms
Speed: 2.8ms preprocess, 87.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 98.7ms
Speed: 3.4ms preprocess, 98.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 87.2ms
Speed: 2.8ms preprocess, 87.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 87.4ms
Speed: 2.8ms preprocess, 87.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 93.5ms
Speed: 2.8ms preprocess, 93.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 L, 90.2ms
Speed: 3.0ms preprocess, 90.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)
Processed 330 frames...

============================================================
SIDE-BY-SIDE COMPARISON RESULTS
============================================================
Ground Truth (from video name): &#39;TRAVEL&#39;
Output video: video_results\Travel1_comparison.mp4
Total frames: 330

YOLOv8n:
  Frames with detections: 230
  Reconstructed sequence: &#39;TTKKKRVMML&#39;
  Sequence length: 10 letters
  Character Accuracy: 30.0%
  Edit Distance: 7 operations

YOLOv8s:
  Frames with detections: 235
  Reconstructed sequence: &#39;KRAKVMEMEEL&#39;
  Sequence length: 11 letters
  Character Accuracy: 45.5%
  Edit Distance: 6 operations

Sequences match: False
✓ YOLOv8s outperforms YOLOv8n by 15.5 percentage points

YOLOv8n detection frequency:
  T: 50 frames (15.2%)
  M: 48 frames (14.5%)
  L: 41 frames (12.4%)
  V: 40 frames (12.1%)
  K: 29 frames (8.8%)

YOLOv8s detection frequency:
  A: 49 frames (14.8%)
  L: 42 frames (12.7%)
  V: 39 frames (11.8%)
  K: 32 frames (9.7%)
  M: 25 frames (7.6%)
============================================================
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Detailed evaluation report</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="s2">&quot;=&quot;</span><span class="o">*</span><span class="mi">60</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;DETAILED EVALUATION REPORT&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span><span class="o">*</span><span class="mi">60</span><span class="p">)</span>

<span class="n">evaluate_prediction</span><span class="p">(</span><span class="n">seq_n</span><span class="p">,</span> <span class="n">ground_truth</span><span class="p">,</span> <span class="s2">&quot;YOLOv8n&quot;</span><span class="p">)</span>
<span class="n">evaluate_prediction</span><span class="p">(</span><span class="n">seq_s</span><span class="p">,</span> <span class="n">ground_truth</span><span class="p">,</span> <span class="s2">&quot;YOLOv8s&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>============================================================
DETAILED EVALUATION REPORT
============================================================

============================================================
YOLOv8n EVALUATION
============================================================
Ground Truth:  &#39;TRAVEL&#39;
Predicted:     &#39;TTKKKRVMML&#39;

Metrics:
  Exact Match:           ✗ NO
  Edit Distance:         7 operations
  Character Accuracy:    30.0%
  Character Error Rate:  116.7%
  Word Error Rate:       116.7%
  Subsequence Accuracy:  33.3%
============================================================

============================================================
YOLOv8s EVALUATION
============================================================
Ground Truth:  &#39;TRAVEL&#39;
Predicted:     &#39;KRAKVMEMEEL&#39;

Metrics:
  Exact Match:           ✗ NO
  Edit Distance:         6 operations
  Character Accuracy:    45.5%
  Character Error Rate:  100.0%
  Word Error Rate:       100.0%
  Subsequence Accuracy:  0.0%
============================================================
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;exact_match&#39;: False,
 &#39;edit_distance&#39;: 6,
 &#39;character_accuracy&#39;: 45.45454545454546,
 &#39;wer&#39;: 100.0,
 &#39;cer&#39;: 100.0,
 &#39;subsequence_accuracy&#39;: 0.0}
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Final comparison summary</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="si">{</span><span class="s1">&#39;=&#39;</span><span class="o">*</span><span class="mi">60</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;FINAL MODEL COMPARISON&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="s1">&#39;=&#39;</span><span class="o">*</span><span class="mi">60</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Ground Truth: &#39;</span><span class="si">{</span><span class="n">ground_truth</span><span class="si">}</span><span class="s2">&#39;&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">YOLOv8n: &#39;</span><span class="si">{</span><span class="n">seq_n</span><span class="si">}</span><span class="s2">&#39; - Character Accuracy: </span><span class="si">{</span><span class="n">metrics_n</span><span class="p">[</span><span class="s1">&#39;character_accuracy&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;YOLOv8s: &#39;</span><span class="si">{</span><span class="n">seq_s</span><span class="si">}</span><span class="s2">&#39; - Character Accuracy: </span><span class="si">{</span><span class="n">metrics_s</span><span class="p">[</span><span class="s1">&#39;character_accuracy&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>

<span class="k">if</span> <span class="n">metrics_s</span><span class="p">[</span><span class="s1">&#39;character_accuracy&#39;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">metrics_n</span><span class="p">[</span><span class="s1">&#39;character_accuracy&#39;</span><span class="p">]:</span>
    <span class="n">improvement</span> <span class="o">=</span> <span class="n">metrics_s</span><span class="p">[</span><span class="s1">&#39;character_accuracy&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">metrics_n</span><span class="p">[</span><span class="s1">&#39;character_accuracy&#39;</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">✓ YOLOv8s is the better model with </span><span class="si">{</span><span class="n">improvement</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2"> percentage point improvement&quot;</span><span class="p">)</span>
<span class="k">elif</span> <span class="n">metrics_n</span><span class="p">[</span><span class="s1">&#39;character_accuracy&#39;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">metrics_s</span><span class="p">[</span><span class="s1">&#39;character_accuracy&#39;</span><span class="p">]:</span>
    <span class="n">difference</span> <span class="o">=</span> <span class="n">metrics_n</span><span class="p">[</span><span class="s1">&#39;character_accuracy&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">metrics_s</span><span class="p">[</span><span class="s1">&#39;character_accuracy&#39;</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">✓ YOLOv8n is the better model with </span><span class="si">{</span><span class="n">difference</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2"> percentage point improvement&quot;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">= Both models perform equally&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="s1">&#39;=&#39;</span><span class="o">*</span><span class="mi">60</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>============================================================
FINAL MODEL COMPARISON
============================================================
Ground Truth: &#39;TRAVEL&#39;

YOLOv8n: &#39;TTKKKRVMML&#39; - Character Accuracy: 30.0%
YOLOv8s: &#39;KRAKVMEMEEL&#39; - Character Accuracy: 45.5%

✓ YOLOv8s is the better model with 15.5 percentage point improvement
============================================================
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">create_gradcam_video</span><span class="p">(</span><span class="n">model_s</span><span class="p">,</span> <span class="n">video_path</span><span class="p">,</span> <span class="n">output_dir</span><span class="p">,</span> <span class="n">vid_name</span><span class="p">,</span> <span class="n">use_simple</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Video rotation metadata: 180.0 degrees
Creating attention visualization...
Processed 30 frames...
Processed 60 frames...
Processed 90 frames...
Processed 120 frames...
Processed 150 frames...
Processed 180 frames...
Processed 210 frames...
Processed 240 frames...
Processed 270 frames...
Processed 300 frames...
Processed 330 frames...

Grad-CAM visualization saved to: video_results\Travel1_gradcam.mp4
Total frames: 330
</pre></div>
</div>
</div>
</div>
</section>
<section id="forest">
<h3>Forest<a class="headerlink" href="#forest" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># --- Paths ---</span>
<span class="n">video_path</span> <span class="o">=</span> <span class="s2">&quot;videos/FOREST.mp4&quot;</span>
<span class="n">vid_name</span> <span class="o">=</span> <span class="s2">&quot;Forest&quot;</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create side-by-side comparison</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Creating side-by-side comparison video...&quot;</span><span class="p">)</span>
<span class="n">seq_n</span><span class="p">,</span> <span class="n">seq_s</span><span class="p">,</span> <span class="n">stats_n</span><span class="p">,</span> <span class="n">stats_s</span><span class="p">,</span> <span class="n">metrics_n</span><span class="p">,</span> <span class="n">metrics_s</span><span class="p">,</span> <span class="n">ground_truth</span> <span class="o">=</span> <span class="n">create_side_by_side_comparison</span><span class="p">(</span>
    <span class="n">model_n</span><span class="p">,</span> <span class="n">model_s</span><span class="p">,</span> <span class="n">video_path</span><span class="p">,</span> <span class="n">output_dir</span><span class="p">,</span> <span class="n">vid_name</span><span class="p">,</span>
    <span class="n">conf_threshold</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">stability_threshold</span><span class="o">=</span><span class="mi">5</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Creating side-by-side comparison video...
Video rotation metadata: 0.0 degrees
Processing frames for side-by-side comparison...

0: 384x640 (no detections), 126.3ms
Speed: 3.0ms preprocess, 126.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 96.8ms
Speed: 3.1ms preprocess, 96.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 99.0ms
Speed: 3.2ms preprocess, 99.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 95.7ms
Speed: 3.3ms preprocess, 95.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 118.9ms
Speed: 3.8ms preprocess, 118.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 122.1ms
Speed: 3.7ms preprocess, 122.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 91.1ms
Speed: 2.9ms preprocess, 91.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 78.7ms
Speed: 3.3ms preprocess, 78.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 83.2ms
Speed: 2.6ms preprocess, 83.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 80.2ms
Speed: 2.6ms preprocess, 80.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 96.2ms
Speed: 3.2ms preprocess, 96.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 84.9ms
Speed: 2.8ms preprocess, 84.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 100.1ms
Speed: 2.9ms preprocess, 100.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 154.2ms
Speed: 3.4ms preprocess, 154.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 90.4ms
Speed: 3.5ms preprocess, 90.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 83.3ms
Speed: 2.9ms preprocess, 83.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 102.3ms
Speed: 3.0ms preprocess, 102.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 117.6ms
Speed: 3.4ms preprocess, 117.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 85.6ms
Speed: 3.5ms preprocess, 85.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 91.3ms
Speed: 3.0ms preprocess, 91.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 91.8ms
Speed: 3.4ms preprocess, 91.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 128.7ms
Speed: 3.1ms preprocess, 128.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 114.5ms
Speed: 3.7ms preprocess, 114.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 90.5ms
Speed: 3.5ms preprocess, 90.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 101.3ms
Speed: 4.2ms preprocess, 101.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 78.4ms
Speed: 2.8ms preprocess, 78.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 79.5ms
Speed: 2.9ms preprocess, 79.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 81.2ms
Speed: 3.6ms preprocess, 81.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 83.2ms
Speed: 3.1ms preprocess, 83.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 79.8ms
Speed: 2.8ms preprocess, 79.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)
Processed 30 frames...

0: 384x640 (no detections), 79.8ms
Speed: 2.8ms preprocess, 79.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 86.4ms
Speed: 2.8ms preprocess, 86.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 F, 1 U, 80.2ms
Speed: 3.0ms preprocess, 80.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 U, 83.8ms
Speed: 2.9ms preprocess, 83.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 B, 84.1ms
Speed: 3.5ms preprocess, 84.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 84.8ms
Speed: 3.0ms preprocess, 84.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 94.7ms
Speed: 3.6ms preprocess, 94.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 F, 115.1ms
Speed: 4.0ms preprocess, 115.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 F, 113.8ms
Speed: 2.6ms preprocess, 113.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 F, 81.2ms
Speed: 3.0ms preprocess, 81.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 F, 98.0ms
Speed: 3.4ms preprocess, 98.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 F, 103.3ms
Speed: 3.1ms preprocess, 103.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 F, 80.9ms
Speed: 2.9ms preprocess, 80.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 F, 81.2ms
Speed: 3.3ms preprocess, 81.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 84.1ms
Speed: 3.4ms preprocess, 84.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 F, 94.0ms
Speed: 3.2ms preprocess, 94.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 F, 87.5ms
Speed: 3.2ms preprocess, 87.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 F, 80.3ms
Speed: 2.8ms preprocess, 80.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 F, 81.4ms
Speed: 2.8ms preprocess, 81.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 F, 83.4ms
Speed: 2.8ms preprocess, 83.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 F, 114.5ms
Speed: 3.3ms preprocess, 114.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 F, 85.5ms
Speed: 3.3ms preprocess, 85.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 82.1ms
Speed: 2.8ms preprocess, 82.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 83.9ms
Speed: 3.0ms preprocess, 83.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 81.5ms
Speed: 2.9ms preprocess, 81.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 80.2ms
Speed: 2.9ms preprocess, 80.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 96.0ms
Speed: 3.6ms preprocess, 96.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 81.6ms
Speed: 2.9ms preprocess, 81.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 85.4ms
Speed: 3.1ms preprocess, 85.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 81.1ms
Speed: 2.9ms preprocess, 81.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)
Processed 60 frames...

0: 384x640 (no detections), 82.7ms
Speed: 2.8ms preprocess, 82.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 F, 96.0ms
Speed: 3.4ms preprocess, 96.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 86.6ms
Speed: 2.9ms preprocess, 86.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 80.4ms
Speed: 3.7ms preprocess, 80.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 79.9ms
Speed: 2.8ms preprocess, 79.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 82.6ms
Speed: 3.1ms preprocess, 82.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 80.6ms
Speed: 3.0ms preprocess, 80.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 82.8ms
Speed: 3.1ms preprocess, 82.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 F, 81.1ms
Speed: 2.8ms preprocess, 81.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 F, 112.7ms
Speed: 3.1ms preprocess, 112.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 88.7ms
Speed: 3.2ms preprocess, 88.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 122.2ms
Speed: 4.7ms preprocess, 122.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 136.4ms
Speed: 3.5ms preprocess, 136.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 98.2ms
Speed: 3.9ms preprocess, 98.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 106.4ms
Speed: 3.5ms preprocess, 106.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 F, 94.6ms
Speed: 3.4ms preprocess, 94.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 84.2ms
Speed: 3.0ms preprocess, 84.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 F, 92.1ms
Speed: 3.7ms preprocess, 92.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 F, 81.7ms
Speed: 2.9ms preprocess, 81.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 F, 105.4ms
Speed: 3.0ms preprocess, 105.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 F, 96.4ms
Speed: 3.2ms preprocess, 96.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 F, 90.3ms
Speed: 4.1ms preprocess, 90.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 F, 90.9ms
Speed: 3.2ms preprocess, 90.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 F, 84.1ms
Speed: 2.8ms preprocess, 84.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 F, 85.9ms
Speed: 3.5ms preprocess, 85.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 F, 83.3ms
Speed: 3.8ms preprocess, 83.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 83.7ms
Speed: 2.7ms preprocess, 83.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 F, 118.7ms
Speed: 3.7ms preprocess, 118.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 F, 94.8ms
Speed: 3.4ms preprocess, 94.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 W, 91.3ms
Speed: 2.9ms preprocess, 91.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)
Processed 90 frames...

0: 384x640 1 W, 88.4ms
Speed: 3.1ms preprocess, 88.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 F, 90.1ms
Speed: 2.9ms preprocess, 90.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 85.2ms
Speed: 3.2ms preprocess, 85.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 B, 1 C, 84.5ms
Speed: 3.2ms preprocess, 84.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 C, 82.6ms
Speed: 3.0ms preprocess, 82.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 C, 93.8ms
Speed: 3.4ms preprocess, 93.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 C, 90.9ms
Speed: 3.7ms preprocess, 90.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 C, 84.4ms
Speed: 3.0ms preprocess, 84.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 C, 82.3ms
Speed: 2.8ms preprocess, 82.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 C, 1 O, 81.0ms
Speed: 2.7ms preprocess, 81.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 84.0ms
Speed: 2.9ms preprocess, 84.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 82.7ms
Speed: 3.1ms preprocess, 82.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 81.2ms
Speed: 3.2ms preprocess, 81.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 83.2ms
Speed: 3.0ms preprocess, 83.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 95.9ms
Speed: 2.9ms preprocess, 95.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 184.0ms
Speed: 3.5ms preprocess, 184.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 83.3ms
Speed: 3.2ms preprocess, 83.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 116.3ms
Speed: 3.0ms preprocess, 116.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 93.0ms
Speed: 3.7ms preprocess, 93.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 84.2ms
Speed: 3.0ms preprocess, 84.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 84.1ms
Speed: 3.2ms preprocess, 84.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 Q, 82.0ms
Speed: 3.4ms preprocess, 82.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 83.7ms
Speed: 3.0ms preprocess, 83.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 1 Q, 86.7ms
Speed: 2.9ms preprocess, 86.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 106.6ms
Speed: 3.6ms preprocess, 106.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 81.6ms
Speed: 3.2ms preprocess, 81.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 92.6ms
Speed: 19.7ms preprocess, 92.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 82.3ms
Speed: 2.9ms preprocess, 82.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 84.4ms
Speed: 3.0ms preprocess, 84.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 82.3ms
Speed: 3.3ms preprocess, 82.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)
Processed 120 frames...

0: 384x640 (no detections), 105.4ms
Speed: 3.5ms preprocess, 105.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 81.6ms
Speed: 3.3ms preprocess, 81.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 92.9ms
Speed: 3.3ms preprocess, 92.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 98.0ms
Speed: 3.5ms preprocess, 98.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 93.5ms
Speed: 4.4ms preprocess, 93.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 98.8ms
Speed: 3.6ms preprocess, 98.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 181.8ms
Speed: 3.0ms preprocess, 181.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 120.5ms
Speed: 3.5ms preprocess, 120.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 102.4ms
Speed: 3.2ms preprocess, 102.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 133.1ms
Speed: 3.4ms preprocess, 133.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 81.2ms
Speed: 2.8ms preprocess, 81.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 151.7ms
Speed: 4.5ms preprocess, 151.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 142.6ms
Speed: 48.1ms preprocess, 142.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 99.4ms
Speed: 4.1ms preprocess, 99.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 116.8ms
Speed: 3.7ms preprocess, 116.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 88.7ms
Speed: 3.4ms preprocess, 88.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 113.2ms
Speed: 3.1ms preprocess, 113.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 83.7ms
Speed: 2.9ms preprocess, 83.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 93.1ms
Speed: 3.4ms preprocess, 93.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 88.6ms
Speed: 3.4ms preprocess, 88.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 95.2ms
Speed: 3.1ms preprocess, 95.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 87.4ms
Speed: 3.2ms preprocess, 87.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 81.7ms
Speed: 3.2ms preprocess, 81.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 O, 88.1ms
Speed: 3.3ms preprocess, 88.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 93.1ms
Speed: 4.0ms preprocess, 93.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 81.3ms
Speed: 2.8ms preprocess, 81.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 U, 110.1ms
Speed: 3.2ms preprocess, 110.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 U, 93.5ms
Speed: 3.8ms preprocess, 93.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 U, 95.1ms
Speed: 3.1ms preprocess, 95.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 U, 82.3ms
Speed: 2.8ms preprocess, 82.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)
Processed 150 frames...

0: 384x640 1 U, 85.2ms
Speed: 2.9ms preprocess, 85.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 U, 126.1ms
Speed: 5.4ms preprocess, 126.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 U, 83.5ms
Speed: 3.2ms preprocess, 83.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 95.0ms
Speed: 3.3ms preprocess, 95.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 104.1ms
Speed: 2.9ms preprocess, 104.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 87.5ms
Speed: 3.1ms preprocess, 87.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 R, 86.8ms
Speed: 3.1ms preprocess, 86.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 R, 93.5ms
Speed: 3.1ms preprocess, 93.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 R, 81.3ms
Speed: 2.7ms preprocess, 81.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 108.0ms
Speed: 3.4ms preprocess, 108.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 101.6ms
Speed: 3.2ms preprocess, 101.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 R, 101.0ms
Speed: 3.3ms preprocess, 101.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 R, 108.3ms
Speed: 3.5ms preprocess, 108.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 R, 120.5ms
Speed: 4.4ms preprocess, 120.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 R, 125.8ms
Speed: 3.0ms preprocess, 125.8ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 R, 105.7ms
Speed: 3.0ms preprocess, 105.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 R, 127.3ms
Speed: 4.0ms preprocess, 127.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 R, 93.6ms
Speed: 3.6ms preprocess, 93.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 R, 119.7ms
Speed: 3.1ms preprocess, 119.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 R, 101.3ms
Speed: 3.2ms preprocess, 101.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 R, 116.5ms
Speed: 3.1ms preprocess, 116.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 R, 96.9ms
Speed: 4.4ms preprocess, 96.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 R, 91.8ms
Speed: 4.1ms preprocess, 91.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 R, 88.4ms
Speed: 3.0ms preprocess, 88.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 R, 111.9ms
Speed: 3.1ms preprocess, 111.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 R, 172.0ms
Speed: 4.5ms preprocess, 172.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 R, 125.5ms
Speed: 3.6ms preprocess, 125.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 R, 137.7ms
Speed: 3.3ms preprocess, 137.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 R, 117.7ms
Speed: 3.2ms preprocess, 117.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 R, 151.2ms
Speed: 4.4ms preprocess, 151.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)
Processed 180 frames...

0: 384x640 1 R, 145.4ms
Speed: 3.8ms preprocess, 145.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 R, 96.4ms
Speed: 3.3ms preprocess, 96.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 R, 82.7ms
Speed: 3.3ms preprocess, 82.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 R, 103.2ms
Speed: 3.7ms preprocess, 103.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 R, 109.6ms
Speed: 3.9ms preprocess, 109.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 R, 105.2ms
Speed: 3.2ms preprocess, 105.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 R, 82.7ms
Speed: 2.8ms preprocess, 82.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 R, 93.4ms
Speed: 3.3ms preprocess, 93.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 R, 87.9ms
Speed: 2.7ms preprocess, 87.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 R, 84.4ms
Speed: 2.7ms preprocess, 84.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 R, 88.8ms
Speed: 3.2ms preprocess, 88.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 116.0ms
Speed: 3.2ms preprocess, 116.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 R, 129.4ms
Speed: 3.6ms preprocess, 129.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 R, 139.6ms
Speed: 3.7ms preprocess, 139.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 R, 92.1ms
Speed: 3.0ms preprocess, 92.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 89.5ms
Speed: 3.1ms preprocess, 89.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 88.6ms
Speed: 3.3ms preprocess, 88.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 R, 81.8ms
Speed: 3.2ms preprocess, 81.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 R, 82.4ms
Speed: 3.0ms preprocess, 82.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 R, 91.7ms
Speed: 2.9ms preprocess, 91.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 R, 108.2ms
Speed: 3.3ms preprocess, 108.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 R, 94.4ms
Speed: 3.0ms preprocess, 94.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 U, 104.8ms
Speed: 3.8ms preprocess, 104.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 U, 91.8ms
Speed: 3.8ms preprocess, 91.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 85.6ms
Speed: 3.1ms preprocess, 85.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 U, 91.2ms
Speed: 3.0ms preprocess, 91.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 F, 92.8ms
Speed: 3.1ms preprocess, 92.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 F, 89.2ms
Speed: 2.7ms preprocess, 89.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 92.5ms
Speed: 3.0ms preprocess, 92.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 81.7ms
Speed: 3.0ms preprocess, 81.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)
Processed 210 frames...

0: 384x640 (no detections), 80.7ms
Speed: 2.8ms preprocess, 80.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 80.5ms
Speed: 3.0ms preprocess, 80.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 80.4ms
Speed: 2.9ms preprocess, 80.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 94.4ms
Speed: 2.9ms preprocess, 94.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 102.0ms
Speed: 3.0ms preprocess, 102.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 1 M, 81.6ms
Speed: 2.9ms preprocess, 81.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 1 M, 82.5ms
Speed: 2.9ms preprocess, 82.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 1 M, 82.0ms
Speed: 2.9ms preprocess, 82.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 1 M, 81.9ms
Speed: 2.6ms preprocess, 81.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 128.5ms
Speed: 3.7ms preprocess, 128.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 102.7ms
Speed: 3.0ms preprocess, 102.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 94.7ms
Speed: 3.5ms preprocess, 94.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 115.9ms
Speed: 6.8ms preprocess, 115.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 111.6ms
Speed: 3.0ms preprocess, 111.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 88.5ms
Speed: 2.9ms preprocess, 88.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 103.1ms
Speed: 2.9ms preprocess, 103.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 85.9ms
Speed: 2.8ms preprocess, 85.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 131.4ms
Speed: 5.0ms preprocess, 131.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 1 M, 107.2ms
Speed: 3.4ms preprocess, 107.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 1 M, 126.9ms
Speed: 3.3ms preprocess, 126.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 120.1ms
Speed: 3.1ms preprocess, 120.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 114.4ms
Speed: 3.2ms preprocess, 114.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 1 M, 97.7ms
Speed: 3.8ms preprocess, 97.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 1 M, 137.3ms
Speed: 3.2ms preprocess, 137.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 1 M, 120.8ms
Speed: 3.4ms preprocess, 120.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 123.0ms
Speed: 3.6ms preprocess, 123.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 104.2ms
Speed: 5.2ms preprocess, 104.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 81.4ms
Speed: 2.7ms preprocess, 81.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 81.7ms
Speed: 3.1ms preprocess, 81.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 101.7ms
Speed: 3.0ms preprocess, 101.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)
Processed 240 frames...

0: 384x640 1 E, 95.1ms
Speed: 3.6ms preprocess, 95.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 82.4ms
Speed: 2.8ms preprocess, 82.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 82.1ms
Speed: 2.9ms preprocess, 82.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 81.8ms
Speed: 2.7ms preprocess, 81.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 95.0ms
Speed: 3.3ms preprocess, 95.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 83.1ms
Speed: 2.8ms preprocess, 83.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 102.8ms
Speed: 3.2ms preprocess, 102.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 89.8ms
Speed: 2.8ms preprocess, 89.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 82.8ms
Speed: 2.6ms preprocess, 82.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 128.3ms
Speed: 2.8ms preprocess, 128.3ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 83.6ms
Speed: 2.8ms preprocess, 83.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 82.4ms
Speed: 3.0ms preprocess, 82.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 87.8ms
Speed: 3.2ms preprocess, 87.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 91.6ms
Speed: 2.9ms preprocess, 91.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 90.0ms
Speed: 3.7ms preprocess, 90.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 82.8ms
Speed: 2.8ms preprocess, 82.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 80.0ms
Speed: 2.9ms preprocess, 80.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 109.0ms
Speed: 3.8ms preprocess, 109.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 97.5ms
Speed: 3.5ms preprocess, 97.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 126.4ms
Speed: 3.8ms preprocess, 126.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 136.7ms
Speed: 3.3ms preprocess, 136.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 99.4ms
Speed: 3.1ms preprocess, 99.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 E, 97.9ms
Speed: 2.9ms preprocess, 97.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 83.0ms
Speed: 2.9ms preprocess, 83.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 85.6ms
Speed: 2.8ms preprocess, 85.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 88.8ms
Speed: 3.1ms preprocess, 88.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 82.9ms
Speed: 3.5ms preprocess, 82.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 112.2ms
Speed: 5.2ms preprocess, 112.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 93.1ms
Speed: 3.2ms preprocess, 93.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 89.4ms
Speed: 3.2ms preprocess, 89.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)
Processed 270 frames...

0: 384x640 1 M, 124.3ms
Speed: 3.6ms preprocess, 124.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 91.1ms
Speed: 2.9ms preprocess, 91.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 100.1ms
Speed: 3.0ms preprocess, 100.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 112.3ms
Speed: 3.3ms preprocess, 112.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 105.4ms
Speed: 3.7ms preprocess, 105.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 97.4ms
Speed: 3.3ms preprocess, 97.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 114.1ms
Speed: 3.4ms preprocess, 114.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 104.8ms
Speed: 3.1ms preprocess, 104.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 142.0ms
Speed: 3.0ms preprocess, 142.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 94.5ms
Speed: 3.1ms preprocess, 94.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 83.1ms
Speed: 3.0ms preprocess, 83.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 89.3ms
Speed: 3.4ms preprocess, 89.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 206.1ms
Speed: 3.4ms preprocess, 206.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 84.4ms
Speed: 3.2ms preprocess, 84.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 94.6ms
Speed: 3.3ms preprocess, 94.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 132.0ms
Speed: 5.2ms preprocess, 132.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 125.3ms
Speed: 3.5ms preprocess, 125.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 105.6ms
Speed: 3.9ms preprocess, 105.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 96.9ms
Speed: 3.1ms preprocess, 96.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 111.4ms
Speed: 3.8ms preprocess, 111.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 85.4ms
Speed: 3.0ms preprocess, 85.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 91.2ms
Speed: 3.4ms preprocess, 91.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 85.0ms
Speed: 3.2ms preprocess, 85.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 124.0ms
Speed: 4.4ms preprocess, 124.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 85.6ms
Speed: 3.1ms preprocess, 85.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 87.7ms
Speed: 3.3ms preprocess, 87.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 100.2ms
Speed: 3.2ms preprocess, 100.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 96.0ms
Speed: 3.5ms preprocess, 96.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 100.1ms
Speed: 3.6ms preprocess, 100.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 97.8ms
Speed: 3.3ms preprocess, 97.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)
Processed 300 frames...

0: 384x640 1 M, 98.5ms
Speed: 3.4ms preprocess, 98.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 90.6ms
Speed: 3.0ms preprocess, 90.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 84.5ms
Speed: 3.3ms preprocess, 84.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 113.8ms
Speed: 3.6ms preprocess, 113.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 90.4ms
Speed: 3.3ms preprocess, 90.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 85.5ms
Speed: 3.0ms preprocess, 85.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 91.1ms
Speed: 3.0ms preprocess, 91.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 101.5ms
Speed: 3.2ms preprocess, 101.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 88.7ms
Speed: 3.1ms preprocess, 88.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 86.4ms
Speed: 3.1ms preprocess, 86.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 96.5ms
Speed: 3.1ms preprocess, 96.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 86.7ms
Speed: 3.2ms preprocess, 86.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 88.6ms
Speed: 2.8ms preprocess, 88.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 83.2ms
Speed: 3.5ms preprocess, 83.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 85.7ms
Speed: 3.0ms preprocess, 85.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 96.8ms
Speed: 3.3ms preprocess, 96.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 86.0ms
Speed: 3.1ms preprocess, 86.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 114.2ms
Speed: 3.2ms preprocess, 114.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 99.2ms
Speed: 3.3ms preprocess, 99.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 83.9ms
Speed: 3.1ms preprocess, 83.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 85.6ms
Speed: 3.2ms preprocess, 85.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 91.1ms
Speed: 3.5ms preprocess, 91.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 91.5ms
Speed: 3.0ms preprocess, 91.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 84.8ms
Speed: 2.9ms preprocess, 84.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 121.9ms
Speed: 3.9ms preprocess, 121.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 96.1ms
Speed: 3.8ms preprocess, 96.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 1 T, 120.1ms
Speed: 4.2ms preprocess, 120.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 84.6ms
Speed: 3.3ms preprocess, 84.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 T, 113.6ms
Speed: 4.1ms preprocess, 113.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 T, 86.9ms
Speed: 3.3ms preprocess, 86.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)
Processed 330 frames...

0: 384x640 (no detections), 85.4ms
Speed: 3.1ms preprocess, 85.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 131.1ms
Speed: 3.2ms preprocess, 131.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 89.6ms
Speed: 3.1ms preprocess, 89.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 99.4ms
Speed: 3.1ms preprocess, 99.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 127.5ms
Speed: 3.9ms preprocess, 127.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 T, 88.4ms
Speed: 3.1ms preprocess, 88.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 148.7ms
Speed: 3.9ms preprocess, 148.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 141.3ms
Speed: 3.7ms preprocess, 141.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 103.3ms
Speed: 3.2ms preprocess, 103.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 148.1ms
Speed: 4.4ms preprocess, 148.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 130.2ms
Speed: 3.7ms preprocess, 130.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 101.3ms
Speed: 3.5ms preprocess, 101.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 99.7ms
Speed: 3.6ms preprocess, 99.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 87.2ms
Speed: 2.9ms preprocess, 87.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 110.0ms
Speed: 3.2ms preprocess, 110.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 100.2ms
Speed: 3.2ms preprocess, 100.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 97.7ms
Speed: 3.1ms preprocess, 97.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 87.8ms
Speed: 3.3ms preprocess, 87.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 87.9ms
Speed: 3.3ms preprocess, 87.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 87.0ms
Speed: 3.0ms preprocess, 87.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 118.3ms
Speed: 6.0ms preprocess, 118.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 98.3ms
Speed: 3.5ms preprocess, 98.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 89.4ms
Speed: 3.1ms preprocess, 89.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 89.4ms
Speed: 3.1ms preprocess, 89.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 89.6ms
Speed: 3.1ms preprocess, 89.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 89.9ms
Speed: 3.1ms preprocess, 89.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 87.3ms
Speed: 3.2ms preprocess, 87.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 87.3ms
Speed: 3.4ms preprocess, 87.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 86.7ms
Speed: 3.1ms preprocess, 86.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 98.3ms
Speed: 3.3ms preprocess, 98.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)
Processed 360 frames...

0: 384x640 1 M, 87.2ms
Speed: 3.1ms preprocess, 87.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 171.1ms
Speed: 3.1ms preprocess, 171.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 95.1ms
Speed: 3.5ms preprocess, 95.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 1 M, 89.5ms
Speed: 3.3ms preprocess, 89.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 1 M, 87.6ms
Speed: 3.1ms preprocess, 87.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 1 M, 94.8ms
Speed: 3.1ms preprocess, 94.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 1 M, 145.4ms
Speed: 4.1ms preprocess, 145.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 1 M, 90.5ms
Speed: 3.0ms preprocess, 90.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 1 M, 87.0ms
Speed: 2.8ms preprocess, 87.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 1 M, 86.5ms
Speed: 3.0ms preprocess, 86.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 1 M, 91.3ms
Speed: 3.0ms preprocess, 91.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 1 M, 131.5ms
Speed: 3.4ms preprocess, 131.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 1 M, 116.2ms
Speed: 3.1ms preprocess, 116.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 1 M, 191.3ms
Speed: 4.2ms preprocess, 191.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 1 M, 90.6ms
Speed: 3.1ms preprocess, 90.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 A, 1 M, 111.4ms
Speed: 3.0ms preprocess, 111.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 91.6ms
Speed: 3.1ms preprocess, 91.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 99.1ms
Speed: 3.1ms preprocess, 99.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 87.4ms
Speed: 3.2ms preprocess, 87.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 91.6ms
Speed: 3.0ms preprocess, 91.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 115.4ms
Speed: 3.5ms preprocess, 115.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 84.6ms
Speed: 3.8ms preprocess, 84.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 111.7ms
Speed: 3.4ms preprocess, 111.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 123.9ms
Speed: 3.9ms preprocess, 123.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 142.3ms
Speed: 4.9ms preprocess, 142.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 117.1ms
Speed: 3.4ms preprocess, 117.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 102.7ms
Speed: 3.0ms preprocess, 102.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 97.6ms
Speed: 3.1ms preprocess, 97.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 87.5ms
Speed: 2.8ms preprocess, 87.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 98.8ms
Speed: 3.3ms preprocess, 98.8ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)
Processed 390 frames...

0: 384x640 1 M, 106.1ms
Speed: 3.1ms preprocess, 106.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 142.9ms
Speed: 3.7ms preprocess, 142.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 111.5ms
Speed: 3.3ms preprocess, 111.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 122.2ms
Speed: 3.3ms preprocess, 122.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 129.8ms
Speed: 3.8ms preprocess, 129.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 152.8ms
Speed: 4.5ms preprocess, 152.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 148.3ms
Speed: 3.7ms preprocess, 148.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 144.5ms
Speed: 3.5ms preprocess, 144.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 124.6ms
Speed: 3.7ms preprocess, 124.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 101.5ms
Speed: 3.3ms preprocess, 101.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 97.7ms
Speed: 3.3ms preprocess, 97.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 125.3ms
Speed: 3.7ms preprocess, 125.3ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 128.0ms
Speed: 5.3ms preprocess, 128.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 269.7ms
Speed: 5.1ms preprocess, 269.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 89.2ms
Speed: 3.0ms preprocess, 89.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 86.3ms
Speed: 3.0ms preprocess, 86.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 134.5ms
Speed: 5.3ms preprocess, 134.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 131.6ms
Speed: 3.4ms preprocess, 131.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 106.9ms
Speed: 3.5ms preprocess, 106.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 99.3ms
Speed: 3.5ms preprocess, 99.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 125.1ms
Speed: 4.7ms preprocess, 125.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 T, 117.1ms
Speed: 4.1ms preprocess, 117.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 M, 84.7ms
Speed: 3.5ms preprocess, 84.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 141.4ms
Speed: 5.0ms preprocess, 141.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 90.9ms
Speed: 3.2ms preprocess, 90.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 86.4ms
Speed: 3.0ms preprocess, 86.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 95.2ms
Speed: 3.4ms preprocess, 95.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 119.6ms
Speed: 3.5ms preprocess, 119.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 87.5ms
Speed: 3.6ms preprocess, 87.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 113.6ms
Speed: 3.9ms preprocess, 113.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)
Processed 420 frames...

0: 384x640 (no detections), 83.8ms
Speed: 2.8ms preprocess, 83.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 1 J, 88.1ms
Speed: 2.8ms preprocess, 88.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 86.1ms
Speed: 2.7ms preprocess, 86.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 89.1ms
Speed: 2.9ms preprocess, 89.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 103.6ms
Speed: 2.8ms preprocess, 103.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 92.3ms
Speed: 3.5ms preprocess, 92.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 82.3ms
Speed: 2.7ms preprocess, 82.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)

0: 384x640 (no detections), 109.4ms
Speed: 3.0ms preprocess, 109.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)

============================================================
SIDE-BY-SIDE COMPARISON RESULTS
============================================================
Ground Truth (from video name): &#39;FOREST&#39;
Output video: video_results\Forest_comparison.mp4
Total frames: 428

YOLOv8n:
  Frames with detections: 301
  Reconstructed sequence: &#39;FFFCOURRMMEMMMMM&#39;
  Sequence length: 16 letters
  Character Accuracy: 25.0%
  Edit Distance: 12 operations

YOLOv8s:
  Frames with detections: 351
  Reconstructed sequence: &#39;FCORMMEMMT&#39;
  Sequence length: 10 letters
  Character Accuracy: 50.0%
  Edit Distance: 5 operations

Sequences match: False
✓ YOLOv8s outperforms YOLOv8n by 25.0 percentage points

YOLOv8n detection frequency:
  M: 139 frames (32.5%)
  R: 41 frames (9.6%)
  E: 34 frames (7.9%)
  F: 33 frames (7.7%)
  O: 26 frames (6.1%)

YOLOv8s detection frequency:
  T: 98 frames (22.9%)
  M: 79 frames (18.5%)
  F: 58 frames (13.6%)
  R: 52 frames (12.1%)
  O: 36 frames (8.4%)
============================================================
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Detailed evaluation report</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="s2">&quot;=&quot;</span><span class="o">*</span><span class="mi">60</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;DETAILED EVALUATION REPORT&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span><span class="o">*</span><span class="mi">60</span><span class="p">)</span>

<span class="n">evaluate_prediction</span><span class="p">(</span><span class="n">seq_n</span><span class="p">,</span> <span class="n">ground_truth</span><span class="p">,</span> <span class="s2">&quot;YOLOv8n&quot;</span><span class="p">)</span>
<span class="n">evaluate_prediction</span><span class="p">(</span><span class="n">seq_s</span><span class="p">,</span> <span class="n">ground_truth</span><span class="p">,</span> <span class="s2">&quot;YOLOv8s&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>============================================================
DETAILED EVALUATION REPORT
============================================================

============================================================
YOLOv8n EVALUATION
============================================================
Ground Truth:  &#39;FOREST&#39;
Predicted:     &#39;FFFCOURRMMEMMMMM&#39;

Metrics:
  Exact Match:           ✗ NO
  Edit Distance:         12 operations
  Character Accuracy:    25.0%
  Character Error Rate:  200.0%
  Word Error Rate:       200.0%
  Subsequence Accuracy:  66.7%
============================================================

============================================================
YOLOv8s EVALUATION
============================================================
Ground Truth:  &#39;FOREST&#39;
Predicted:     &#39;FCORMMEMMT&#39;

Metrics:
  Exact Match:           ✗ NO
  Edit Distance:         5 operations
  Character Accuracy:    50.0%
  Character Error Rate:  83.3%
  Word Error Rate:       83.3%
  Subsequence Accuracy:  66.7%
============================================================
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;exact_match&#39;: False,
 &#39;edit_distance&#39;: 5,
 &#39;character_accuracy&#39;: 50.0,
 &#39;wer&#39;: 83.33333333333334,
 &#39;cer&#39;: 83.33333333333334,
 &#39;subsequence_accuracy&#39;: 66.66666666666666}
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Final comparison summary</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="si">{</span><span class="s1">&#39;=&#39;</span><span class="o">*</span><span class="mi">60</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;FINAL MODEL COMPARISON&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="s1">&#39;=&#39;</span><span class="o">*</span><span class="mi">60</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Ground Truth: &#39;</span><span class="si">{</span><span class="n">ground_truth</span><span class="si">}</span><span class="s2">&#39;&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">YOLOv8n: &#39;</span><span class="si">{</span><span class="n">seq_n</span><span class="si">}</span><span class="s2">&#39; - Character Accuracy: </span><span class="si">{</span><span class="n">metrics_n</span><span class="p">[</span><span class="s1">&#39;character_accuracy&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;YOLOv8s: &#39;</span><span class="si">{</span><span class="n">seq_s</span><span class="si">}</span><span class="s2">&#39; - Character Accuracy: </span><span class="si">{</span><span class="n">metrics_s</span><span class="p">[</span><span class="s1">&#39;character_accuracy&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>

<span class="k">if</span> <span class="n">metrics_s</span><span class="p">[</span><span class="s1">&#39;character_accuracy&#39;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">metrics_n</span><span class="p">[</span><span class="s1">&#39;character_accuracy&#39;</span><span class="p">]:</span>
    <span class="n">improvement</span> <span class="o">=</span> <span class="n">metrics_s</span><span class="p">[</span><span class="s1">&#39;character_accuracy&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">metrics_n</span><span class="p">[</span><span class="s1">&#39;character_accuracy&#39;</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">✓ YOLOv8s is the better model with </span><span class="si">{</span><span class="n">improvement</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2"> percentage point improvement&quot;</span><span class="p">)</span>
<span class="k">elif</span> <span class="n">metrics_n</span><span class="p">[</span><span class="s1">&#39;character_accuracy&#39;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">metrics_s</span><span class="p">[</span><span class="s1">&#39;character_accuracy&#39;</span><span class="p">]:</span>
    <span class="n">difference</span> <span class="o">=</span> <span class="n">metrics_n</span><span class="p">[</span><span class="s1">&#39;character_accuracy&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">metrics_s</span><span class="p">[</span><span class="s1">&#39;character_accuracy&#39;</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">✓ YOLOv8n is the better model with </span><span class="si">{</span><span class="n">difference</span><span class="si">:</span><span class="s2">.1f</span><span class="si">}</span><span class="s2"> percentage point improvement&quot;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">= Both models perform equally&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="s1">&#39;=&#39;</span><span class="o">*</span><span class="mi">60</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>============================================================
FINAL MODEL COMPARISON
============================================================
Ground Truth: &#39;FOREST&#39;

YOLOv8n: &#39;FFFCOURRMMEMMMMM&#39; - Character Accuracy: 25.0%
YOLOv8s: &#39;FCORMMEMMT&#39; - Character Accuracy: 50.0%

✓ YOLOv8s is the better model with 25.0 percentage point improvement
============================================================
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">create_gradcam_video</span><span class="p">(</span><span class="n">model_s</span><span class="p">,</span> <span class="n">video_path</span><span class="p">,</span> <span class="n">output_dir</span><span class="p">,</span> <span class="n">vid_name</span><span class="p">,</span> <span class="n">use_simple</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Video rotation metadata: 0.0 degrees
Creating attention visualization...
Processed 30 frames...
Processed 60 frames...
Processed 90 frames...
Processed 120 frames...
Processed 150 frames...
Processed 180 frames...
Processed 210 frames...
Processed 240 frames...
Processed 270 frames...
Processed 300 frames...
Processed 330 frames...
Processed 360 frames...
Processed 390 frames...
Processed 420 frames...

Grad-CAM visualization saved to: video_results\Forest_gradcam.mp4
Total frames: 428
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./Code_Implementation"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../Week_5/final_report.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Automated ASL Fingerspelling Recognition for Educational Platforms Using YOLOv8 Frame Classification and Letter Sequence Reconstruction</p>
      </div>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Random Sample Images of Dataset</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#modeling">Modeling</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#yolov8">YOLOv8</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#yolov8-n-nano">YOLOv8-n (Nano)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#yolov8-s-small">YOLOv8-s (Small)</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#results">Results</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">YOLOv8-n (Nano)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#id2">YOLOv8-s (Small)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#yolov8-model-performance-comparison">YOLOv8 Model Performance Comparison</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#video-testing">Video Testing</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#functions">Functions</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#testing">Testing</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dog">Dog</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#hello">Hello</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#camera">Camera</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#travel">Travel</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#forest">Forest</a></li>
</ul>
</li>
</ul>
</li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Abainza, Casino, Culanggo, dela Cruz
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>